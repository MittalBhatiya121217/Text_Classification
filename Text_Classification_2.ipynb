{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n",
        "**Instructions**:\n",
        "1. Wherever you are asked to code, insert a text block below your code block and explain what you have coded as per your own understanding.\n",
        "2. If the code is provided by us, execute it, and add below a text block and provide your explanation in your own words.\n",
        "3. Submit both the .ipynb and pdf files to canvas.\n",
        "4. **The similarity score should be less than 15%.**"
      ],
      "metadata": {
        "id": "ez6hsEhxTlE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task-1(10 points)\n",
        "##What are some common applications of text classification?What are some common machine learning algorithms used for text classification?"
      ],
      "metadata": {
        "id": "JF-InUBLjUP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer here\n",
        "**Text classification:** text classification called as a text categorization and the process of the categorize text into the group of the words using the natural language processing. text classification is defined the text and intialize the pre defined labels and categorized baesd on the previous words of the sentences or text.\n",
        "\n",
        "**Text classification using the machine learning:**\n",
        "Text classification is the machine learning techniques which initialize the tags and categoried to the documents. talking about the text classification using the natural language processing its basically analyze the text of the documents and after that its sort the text in different categories such as sentiment, topic of the documents and what is the intent behind the words is it positive or negative and also this will give the more accuracy result then humans.\n",
        "**Application for text classification:**\n",
        "There are lot of different application available for text classification. here.we are talking about some of them.Now, focusing on the common application in machine learning which is used for text classification :\n",
        "\n",
        "**Spam filtering :** this is detect and filter the unrelevent to the person or unwanted  and unrequested mails,messages or comments, is they are positive or not.\n",
        "\n",
        "**Sentiment analysis :** this will detect the data based on the emotions or sentiment in the text and identify is it positive,negative and neutral.\n",
        "\n",
        "**Topic classification :** this will detect the topic of the document based on the data provided for instance is it related to sports, medical or crime.\n",
        "\n",
        "**Intent classification :** this is basically to detect the purpose of the text such as whether user wants to buy product or needs the customer service.\n",
        "\n",
        "**Language identification :** this will use for detect the language of the provided text such as english, spanish, french etc.\n",
        "**Machine learning algorithms which are used for text classification:**\n",
        "\n",
        "**1. Naive Bayes Algorithm**\n",
        "This is the most popular algorithm used in the machine learning for text classification.this is the probabilistic algorithm which is use the bayes theor, and its assume that the particular class feature is present in independent of the presence of the other features.\n",
        "\n",
        "For text classification, naive bayes is mostly used to check the probability of the text that is belongs to that particular class. its aalyze thr word frequency of the word or features in the documents and that labeled with corresponding classes.this can handle large number of features and computationally efficient, its most popular for large scaled applications.on top of that, its required less data to trained and its main goal is to get the good performace and its easily take it from the classes or domains.\n",
        "\n",
        "\n",
        "**2. Support Vector Machine**\n",
        "Support vector machine is the one type of the machine learning algorithm that is used for text classification. its find the hyperplane which is maximum seprates the two classes of the data points in the high dimensional spaces.In the text classification svm is use for learn decision boundry that make different pairs of the different classes of the documents based on the features.Here the features we are addressing is bag-of-words representations, TF-IDF weights, or more sophisticated representations like words embedding.Its useful with high dimensional data,where the features are represent commonly using the nlp. svm also work good with unbalanced datasets, for text classification, where the number of example in each class different significantly.Additionally, svm is able to get the highest accuracy in text classification and its mostly used in applications such as sentiment analysis, spam detection and topic based classification.\n",
        "\n",
        "All in all, svm is the powerful machine learning techniques which can handle high dimensional data as well as the unbalanced data.\n",
        "\n",
        "\n",
        "**3. Deep Learning**\n",
        "Deep learning is the sunset of the machine learning which is used for text classification. basically, talking about the text classification is the process of the initialize one or  more labels to given documents based on the context of the documents. this learning model is effective in text classification because it use complex pattern and relationship in the text. this is using the multiple neurons to get the higher level features from the text.this is model is trained with large dataset so it can handle easily capture pattern and relationship.\n",
        "Talking about the techniques by deep learning which is used for text clssifications are neural network as convolutional neural network(CNN), recurrent neural network(RNN), and long short-term memory(LSTM) network. this models take the text as a input and then classify the text into different categories.\n",
        "\n",
        "All in all deep learning is the powerful for text classification, its able to achieve the goal for better accuracy on many dataset.its useful with different kind of applications which are sentiment analysis, spam detection and topic modeling.\n",
        "\n",
        "\n",
        "**4. Decision Trees:** This algorithm is use the tree structure for taking the model decisions where based on the features its create the tree and nodes for getting the better accuracy this is mostly use for multi class classifications.\n",
        "\n",
        "**5. Random Forests:**  This is work with decision trees and its basically improve the accuracy of the model and stable the predictions.\n",
        "\n",
        "\n",
        "**6. Neural Networks:** this algorithm is based on the structure and function of the human brain and are useful for text classifications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iYe3GCYTjgPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to avoid NumPy's truncation of outputs when certain code blocks are generated\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "LH_1iW_WQvUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are using numpy when the truncate the output when the particulary type of code blocks generated.\n",
        "\n",
        "here, first import the sys which used for getting functions and variables for run time environment and numpy which is here used for performing the mathematical operations.at the last numpy.set_printoptions) this is the function where numpy is set the printing options for arrays. and also passing the parameter for threshold = sys.m,axsize which is the maximum value of the variable type in the current system.and its represent the whole array print no matter the size of the array.\n"
      ],
      "metadata": {
        "id": "YQ7dGrIyPYwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(Tutorial) Performing Naive Bayes Classification using Scikit-Learn**(5 points)"
      ],
      "metadata": {
        "id": "OlrH4JEE5tVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bag-of-Words (BoW)**\n",
        "\n",
        "***Bag-of-Words*** is one of the many approaches to extract features (inputs to the learning algorithm) from the text data. Depending on the basis of measure used, a Bag-of-Words representation of text contains information about the occurrence of words in the underlying text.\n",
        "\n",
        "Of the various measures, one of them is to create a Bag-of-Words representation using the ***information about the presence/absence of words in the text***. **0** indicates the word is absent while **1** indicates the word is present."
      ],
      "metadata": {
        "id": "iwO9JpREQQqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 'binary' parameter set to True indicates the encoding measure is the presence/absence of words\n",
        "vectorizer1 = CountVectorizer(binary=True)\n",
        "\n",
        "# super small corpus\n",
        "corpus = [\n",
        "     'This is the first Document.',\n",
        "     'This is the second second document.',\n",
        "     'And the third one.',\n",
        "     'Is this the first document?',\n",
        "]\n",
        "\n",
        "# fit the vectorizer on the corpus and then encode the data\n",
        "data = vectorizer1.fit_transform(corpus)\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJbzU85rQS-d",
        "outputId": "47a6f09a-4413-4757-db49-f4117d7f08b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 19 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are vectorizing the sentences and then encoding them in to the one variable.and we are counting the vector class and convert that text into the numeric data using the  machine learning model.\n",
        "\n",
        "Here, first we are importing the countvectorize from scikit learn. this is use for convert collection of the text into the matrix of the word counts. after that the object of the countvectorize created with parameter binary is true which means that the encoding measures is the absence of the words in the text, instead of the frewuency of the word.now we are taking the small corpus with 4 lines.after that we are using the fit_transform function with parameter as a corpus and with instace of the countvectorize and store that inot the data name variable.this method first fits he vectorizer to the corpus text and analyze them and after that it built the vocabulary of the unique words. now its convert the corpus into matrics of the words counts. and the final result is stored in the data variable."
      ],
      "metadata": {
        "id": "_wla3q6JSs3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer1.vocabulary_.keys())    # returns the features extracted from the text (vocabulary)\n",
        "\n",
        "data.toarray()    # returns encoded representations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtwDpJIuakQL",
        "outputId": "10136d93-c581-4418-8397-d7130dcf3192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['this', 'is', 'the', 'first', 'document', 'second', 'and', 'third', 'one'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are printing the vectorize vocabulary keys and matrix of the array counting. fisrt we are printing the vocabs from the word and after that printing the array of the matrix of this words.\n",
        " here, the vectorize1 is returns the features of the extracted from the corpus.which is the vocab of the words.this vocab is have all the unique words and tokens of the words which is available in the corpus.\n",
        "\n",
        "now we are using the data.toarray method which returns the encoded representations of the text as the numpy array. this is row represent the text,\n",
        "and the columns represent the frequency of the particular words.\n",
        "\n",
        "overall, here we are exctracting the features from the corpus, encoding them into the numerix representation using the bag of word and returning the encoded representation as the numpy array for analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ll4Ks5Q08w5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'binary' parameter when not set indicates the encoding measure is term frequency\n",
        "vectorizer2 = CountVectorizer()\n",
        "\n",
        "# again, an example corpus\n",
        "corpus = [\n",
        "     'This is the first Document.',\n",
        "     'This is the second second document.',\n",
        "     'And the third one is the document.',\n",
        "     'Is this the first document document document?',\n",
        "]\n",
        "\n",
        "# same as before...\n",
        "data = vectorizer2.fit_transform(corpus)\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iOzfKh8U0Sw",
        "outputId": "796b6ca3-b330-4b01-ddfd-8d51d6ef6138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 21 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, we are creating the counter vector for extracting the features from the corpus. here its transform the corpus text into the matrix of the numerical values. here the binary parameter is not set, the encoding measure used in the term frequency. here, the corpus is the list of the four documents and its fit in to the fit_transform() method which is use for create sparse matrix of the text term frequency. each row is the documents and each columns is the corpus. the value in the matrix are the number of times each terms available in the each documents.\n",
        "\n",
        "the matrix use as a input to machine learning model for tasks such as text classification and clustering.\n",
        "\n"
      ],
      "metadata": {
        "id": "CN-tgHyiGGX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 'binary' parameter when not set indicates the encoding measure is term frequency\n",
        "vectorizer2 = CountVectorizer()\n",
        "\n",
        "# again, an example corpus\n",
        "corpus = [\n",
        "     'This is the first Document.',\n",
        "     'This is the second second document.',\n",
        "     'And the third one is the document.',\n",
        "     'Is this the first document document document?',\n",
        "]\n",
        "\n",
        "# same as before...\n",
        "data = vectorizer2.fit_transform(corpus)\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EsQS9GoU5JD",
        "outputId": "27ccfddf-beb9-441c-aab6-2e24e3feee75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 21 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here its creating the bag of words reperesentation of the corpus using the countvectorizer class from the scikit-learn. this corpus is the list of the four documents, and the countervectorize is use to convert the text into the matrix where each row is the document and column is the unique word of the corpus.\n",
        "\n",
        "the fit_transform() method is use the countvectorize in the corpus, which first fit the corpus and then transform into the matrix of the word counts. this is stored in the data variable."
      ],
      "metadata": {
        "id": "q_tKrdywGHGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using Naive Bayes in scikit-learn**"
      ],
      "metadata": {
        "id": "qPmCUfdwU-w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1. Create/Collect the Data**"
      ],
      "metadata": {
        "id": "dfCkvAfrVBn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing an existing dataset from scikit-learn for demonstrating use of Naive Bayes\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups()\n",
        "\n",
        "\n",
        "# scikit-learn provides helpful utilities for out-of-the-box datasets\n",
        "# what are the various categories of documents in the above dataset?\n",
        "dataset.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGDtvTNNVD9d",
        "outputId": "7a773fca-e881-4048-8444-22d1f18acdb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are first importing the dataset from scikit-learn existing dataset name \"fetch_20newsgroups\". this dataset is the collection of the news documents from 20 different kind of categories.\n",
        "\n",
        "after fetching the dataset now we are providing the traget_name attribute which is use for retrieve the name of the categories.its return the list of the strings, where each string represent the name of the 20 different categories one by one in the dataset.\n",
        "\n",
        "In summarize, here we are retrieving the list of the categories from the 20 news groups dataset from scikit-learn,  this is useful feature its understand the nature of the data and the classification problem which is we are tring to solve here.\n"
      ],
      "metadata": {
        "id": "MTNqX87qMnBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the inputs/attributes in the above dataset?\n",
        "dataset.data      # returns a list\n",
        "\n",
        "print(f\"Number of articles (inputs): {len(dataset.data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxtSGXcvVJoo",
        "outputId": "626f74f1-d585-4594-f283-996ea8818005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of articles (inputs): 11314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are accesing the dataset data from the fetched 20 newsgroups. this is contain the word of the list which is present in the dataset.\n",
        "\n",
        "here, afer that we are printing the number of articles present in the dataset by calculating the length of the data attribute. this will return the number of documents present in the dataset.\n",
        "\n",
        "All in all, here we are accesing the data from the 20 newsgroups dataset, which is containing the text of all the documents. after that its print the number of documents in the dataset.\n"
      ],
      "metadata": {
        "id": "jI8LZNDWSn1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the corresponding outputs/targets in the above dataset?\n",
        "dataset.target      # returns a n-dimensional NumPy array\n",
        "\n",
        "print(f\"Number of targets (outputs): {dataset.target.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaYY7CBoVL2P",
        "outputId": "78b56f7c-abf4-4ff6-d8c9-54063ece120e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of targets (outputs): (11314,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, its accessing the target attrubute of the fetched 20 news groups dataset.target is the n-dimensional array which is containing the integer labels for all the documents available in the dataset.\n",
        "\n",
        "here, wach integer label represent the index of the category which documents is belongs to. target_name is use for getting the list of the category names.after that it print the shape of the target array using the dataset. and its return the dimension of the numpy array, which is the number of labels available in the dataset for particular data.\n",
        "\n",
        "In summarize, here, we are using the 20 newsgrups dataset, which is containing the interger labels represent the category for each documents belongs to. now its print the number of labels available in the dataset.\n"
      ],
      "metadata": {
        "id": "bMAOHRrxUslv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the demonstration, let's use only a small subset from the 20 categories\n",
        "categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']\n",
        "\n",
        "# get the training and testing data and have them ready to use later\n",
        "train_data = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test_data = fetch_20newsgroups(subset='test', categories=categories)\n",
        "print(train_data.data[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAqn-KJ0VNt6",
        "outputId": "e51ae78c-4102-4ff0-b139-1d4dba7468ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: dmcgee@uluhe.soest.hawaii.edu (Don McGee)\n",
            "Subject: Federal Hearing\n",
            "Originator: dmcgee@uluhe\n",
            "Organization: School of Ocean and Earth Science and Technology\n",
            "Distribution: usa\n",
            "Lines: 10\n",
            "\n",
            "\n",
            "Fact or rumor....?  Madalyn Murray O'Hare an atheist who eliminated the\n",
            "use of the bible reading and prayer in public schools 15 years ago is now\n",
            "going to appear before the FCC with a petition to stop the reading of the\n",
            "Gospel on the airways of America.  And she is also campaigning to remove\n",
            "Christmas programs, songs, etc from the public schools.  If it is true\n",
            "then mail to Federal Communications Commission 1919 H Street Washington DC\n",
            "20054 expressing your opposition to her request.  Reference Petition number\n",
            "\n",
            "2493.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, we are using the small dataset of 20 newsgropus data. and here we are selecting the categories such as 'talk.religion.misc', 'soc.religion.christian', 'sci.space', and 'comp.graphics'.\n",
        "\n",
        "now, fetch 20 news groups function is called again with the parameter set to train to fetch the training data and also with the parameter set as test to fetch the testing data.here the category parameter is set to filter the dataset and only include the documents which is belongs to that category.\n",
        "\n",
        "After gettung the training data, here its use the index operator to access the text of the sixth document using the train data.data[5]. the text of this documents is printed.at\n",
        "\n",
        "In conculsion, we are selecting the small amount of the data from the 20 newsgroups dataset and fetch the training data for this categories. at the last we are printing text of the sixth document in the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "FFHrufEyfqEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2(a): Prepare the inputs for modeling**"
      ],
      "metadata": {
        "id": "5XKotWTmVQYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create BoW representations for the training data (excluding targets); aka feature extraction\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_vectorizer = CountVectorizer()\n",
        "\n",
        "# first, build the training vocabulary, fit()\n",
        "# then, use the vocabulary to transform the training data into a document-term matrix, transform()\n",
        "# results in a document-term matrix structure\n",
        "X_train = bow_vectorizer.fit_transform(train_data.data)\n",
        "\n",
        "# let's check the document-term matrix\n",
        "X_train\n",
        "\n",
        "# convert sparse matrix to dense matrix\n",
        "# X_train.to_array()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZipfySLLVVxv",
        "outputId": "7256825e-ccfb-42ff-cfd8-853ed0876020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2153x35329 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 352179 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, first we are importing the countvectorize for extracting the features form the documents.here we are using the x_train.to_array to convert the sparse matrix X_train into a dense matrix. sparse matrix is where the  is having elements are zero while dense matrix is where almost all of the elements are non zero. here we are using the toarray method which is use for convert the sparse matrix to a dense matrix  create array with the same shape uisng the sparse matrix its fill the non-zero elements.\n",
        "\n",
        "All in all, the X_train.to_array() is convert the sparse matrix intot he normal matrix and its display easily and manipulated.\n"
      ],
      "metadata": {
        "id": "EBFyElWuuV-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2(b): Prepare the outputs for modeling**"
      ],
      "metadata": {
        "id": "b3k9hdOXWL-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store the outputs (corresponding to the news articles in the training set) for easy access\n",
        "y_train = train_data.target     # returns a n-dimensional NumPy array\n",
        "y_train\n",
        "\n",
        "# print(f\"y_train array size: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsbt4xg5WOQ3",
        "outputId": "6461a6be-2712-4c70-eb6d-7c600a1d30b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 2, 0, 3, 1, 0, 3, 3, 2, 0, 1, 2, 3, 2, 2, 0, 1, 0, 1, 0,\n",
              "       1, 2, 2, 0, 0, 1, 3, 3, 1, 1, 2, 1, 1, 1, 0, 2, 0, 3, 2, 1, 2, 2,\n",
              "       2, 1, 1, 1, 1, 2, 3, 3, 1, 0, 1, 2, 3, 2, 2, 2, 0, 3, 1, 1, 2, 3,\n",
              "       0, 2, 0, 0, 1, 0, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 2, 0, 2,\n",
              "       0, 2, 0, 2, 1, 1, 3, 0, 1, 1, 0, 1, 0, 3, 0, 2, 3, 0, 2, 2, 3, 3,\n",
              "       1, 3, 2, 1, 0, 2, 0, 1, 2, 0, 2, 3, 0, 1, 2, 2, 1, 2, 2, 1, 3, 2,\n",
              "       1, 0, 2, 1, 0, 0, 2, 1, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2,\n",
              "       2, 3, 2, 0, 1, 0, 0, 1, 3, 2, 2, 1, 2, 2, 0, 3, 2, 0, 2, 0, 0, 0,\n",
              "       2, 0, 0, 2, 0, 2, 3, 2, 2, 0, 3, 1, 1, 1, 1, 1, 1, 3, 1, 0, 2, 3,\n",
              "       2, 3, 3, 2, 1, 0, 1, 3, 1, 3, 2, 0, 2, 1, 1, 3, 0, 1, 1, 2, 1, 2,\n",
              "       2, 3, 0, 1, 1, 1, 3, 0, 3, 0, 2, 1, 0, 0, 0, 1, 0, 2, 2, 1, 2, 1,\n",
              "       2, 0, 3, 1, 1, 1, 1, 1, 2, 2, 3, 3, 2, 1, 0, 2, 0, 0, 2, 3, 0, 2,\n",
              "       0, 2, 1, 3, 3, 3, 1, 0, 2, 1, 3, 0, 2, 2, 3, 2, 0, 0, 2, 2, 1, 1,\n",
              "       0, 0, 2, 2, 0, 1, 1, 2, 0, 0, 0, 1, 3, 2, 1, 0, 3, 2, 0, 1, 0, 2,\n",
              "       0, 0, 1, 2, 3, 3, 1, 2, 0, 1, 3, 2, 2, 0, 0, 1, 3, 2, 2, 2, 0, 0,\n",
              "       1, 3, 3, 2, 2, 3, 3, 3, 0, 1, 0, 0, 0, 2, 1, 2, 1, 1, 3, 2, 3, 1,\n",
              "       2, 3, 2, 2, 3, 0, 2, 1, 2, 0, 2, 2, 1, 1, 1, 2, 2, 2, 1, 3, 0, 0,\n",
              "       1, 1, 2, 1, 3, 1, 1, 2, 0, 0, 0, 3, 2, 3, 1, 3, 3, 3, 0, 2, 2, 0,\n",
              "       2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 3, 3, 0, 1, 2, 2, 0, 1, 3, 1, 3,\n",
              "       3, 1, 2, 0, 2, 0, 1, 2, 3, 1, 2, 2, 3, 3, 3, 0, 2, 3, 1, 1, 1, 2,\n",
              "       1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 2, 0, 3, 1, 0, 3, 3, 2, 3, 2, 1, 2,\n",
              "       0, 2, 0, 3, 1, 0, 0, 1, 3, 1, 1, 2, 1, 3, 0, 3, 3, 2, 0, 0, 1, 0,\n",
              "       1, 2, 2, 0, 0, 1, 2, 2, 1, 1, 2, 3, 1, 1, 0, 2, 3, 2, 0, 2, 0, 1,\n",
              "       1, 1, 1, 2, 2, 1, 2, 0, 0, 2, 0, 3, 2, 2, 0, 3, 3, 2, 1, 2, 2, 1,\n",
              "       1, 2, 0, 1, 2, 0, 0, 2, 1, 0, 2, 3, 2, 0, 2, 0, 2, 1, 2, 1, 0, 2,\n",
              "       0, 2, 2, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 3, 0, 0, 2, 1, 2, 3, 0,\n",
              "       0, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 3, 2, 2, 0,\n",
              "       1, 0, 1, 2, 0, 0, 0, 0, 1, 3, 2, 3, 0, 0, 3, 2, 2, 1, 2, 2, 0, 2,\n",
              "       2, 3, 1, 0, 1, 0, 1, 0, 2, 1, 0, 0, 2, 3, 1, 3, 2, 1, 0, 2, 0, 1,\n",
              "       2, 0, 1, 2, 3, 1, 1, 2, 2, 2, 3, 2, 1, 1, 1, 0, 3, 0, 0, 0, 1, 3,\n",
              "       2, 0, 2, 1, 3, 0, 0, 0, 1, 1, 1, 3, 1, 0, 2, 0, 1, 0, 1, 3, 2, 3,\n",
              "       3, 2, 0, 2, 2, 2, 1, 0, 1, 1, 2, 3, 1, 2, 2, 2, 0, 0, 1, 3, 2, 0,\n",
              "       3, 1, 1, 2, 1, 1, 3, 3, 3, 1, 2, 0, 1, 0, 1, 1, 1, 0, 3, 1, 3, 0,\n",
              "       2, 1, 0, 0, 3, 3, 3, 0, 2, 0, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 3, 0,\n",
              "       3, 1, 2, 3, 3, 0, 3, 0, 0, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 0, 3, 0,\n",
              "       0, 3, 3, 2, 1, 0, 3, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 2, 2, 2, 1,\n",
              "       2, 3, 0, 2, 1, 2, 1, 2, 2, 2, 3, 0, 0, 0, 2, 3, 0, 2, 0, 1, 2, 2,\n",
              "       1, 1, 0, 0, 0, 3, 2, 2, 2, 0, 3, 0, 2, 2, 2, 1, 0, 2, 0, 3, 2, 1,\n",
              "       1, 1, 1, 0, 1, 3, 1, 0, 0, 0, 0, 1, 3, 2, 0, 0, 0, 2, 2, 2, 1, 3,\n",
              "       3, 2, 0, 2, 1, 3, 3, 3, 3, 1, 1, 1, 2, 1, 0, 0, 0, 0, 2, 2, 0, 3,\n",
              "       3, 0, 2, 1, 3, 1, 0, 0, 1, 1, 3, 3, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       2, 2, 2, 0, 0, 2, 3, 2, 1, 1, 3, 2, 1, 0, 2, 1, 1, 2, 0, 0, 0, 1,\n",
              "       1, 3, 0, 2, 2, 2, 2, 2, 2, 1, 3, 0, 1, 2, 1, 0, 1, 3, 3, 2, 1, 1,\n",
              "       0, 0, 1, 0, 2, 2, 1, 3, 3, 0, 0, 2, 1, 2, 0, 2, 0, 2, 0, 1, 3, 1,\n",
              "       0, 0, 0, 1, 3, 3, 0, 2, 1, 2, 3, 1, 0, 2, 2, 0, 0, 3, 0, 2, 2, 3,\n",
              "       1, 3, 1, 3, 2, 1, 1, 0, 0, 1, 0, 3, 3, 1, 2, 3, 0, 2, 2, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 3, 0, 1, 2, 1, 1, 2, 1, 3, 2, 2,\n",
              "       0, 0, 1, 0, 0, 1, 0, 3, 0, 2, 0, 1, 2, 2, 1, 2, 0, 0, 1, 0, 3, 2,\n",
              "       1, 0, 1, 1, 3, 2, 1, 0, 1, 1, 2, 0, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2,\n",
              "       2, 0, 1, 2, 1, 2, 0, 0, 1, 3, 1, 2, 0, 0, 1, 3, 2, 2, 0, 3, 3, 1,\n",
              "       1, 1, 3, 1, 3, 1, 1, 0, 1, 1, 0, 2, 1, 1, 0, 0, 1, 2, 1, 0, 2, 3,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 2, 0, 3, 2, 1, 2, 3, 3, 0, 1, 3, 1, 3, 3,\n",
              "       0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 3, 0, 3, 1, 0,\n",
              "       1, 0, 0, 2, 3, 3, 3, 3, 0, 2, 0, 2, 3, 2, 0, 1, 3, 1, 1, 2, 0, 1,\n",
              "       1, 0, 3, 0, 0, 0, 0, 2, 1, 1, 1, 0, 2, 3, 1, 2, 2, 3, 1, 2, 0, 0,\n",
              "       0, 0, 2, 1, 3, 1, 2, 0, 1, 1, 2, 2, 1, 0, 2, 3, 2, 0, 0, 2, 3, 2,\n",
              "       2, 0, 2, 1, 2, 3, 1, 3, 1, 1, 0, 0, 1, 2, 3, 2, 2, 2, 0, 0, 0, 3,\n",
              "       1, 3, 2, 0, 0, 2, 2, 2, 1, 3, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 1, 0,\n",
              "       1, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 1, 3, 0, 1, 0, 0, 2, 3, 1, 2,\n",
              "       1, 1, 1, 1, 1, 3, 1, 0, 3, 2, 0, 2, 2, 0, 1, 2, 2, 3, 0, 2, 1, 0,\n",
              "       3, 1, 1, 0, 3, 0, 1, 3, 1, 3, 1, 1, 1, 3, 2, 2, 1, 1, 0, 3, 0, 2,\n",
              "       1, 0, 3, 2, 1, 1, 3, 2, 3, 2, 0, 0, 0, 3, 3, 0, 3, 2, 2, 0, 0, 1,\n",
              "       2, 1, 1, 2, 2, 1, 2, 1, 3, 3, 1, 0, 3, 0, 2, 3, 0, 3, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 2, 3, 2, 1, 2, 1, 3, 2, 2, 1, 2, 2, 0, 3, 2, 0, 2, 0,\n",
              "       1, 0, 1, 0, 0, 2, 1, 2, 1, 3, 2, 2, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0,\n",
              "       3, 3, 3, 1, 0, 1, 1, 3, 0, 3, 3, 3, 2, 0, 2, 2, 3, 3, 1, 0, 3, 3,\n",
              "       0, 3, 0, 1, 1, 3, 2, 0, 2, 0, 2, 1, 0, 0, 1, 3, 1, 3, 0, 0, 0, 1,\n",
              "       1, 0, 3, 0, 2, 0, 2, 2, 3, 3, 2, 1, 2, 2, 3, 2, 3, 1, 3, 0, 0, 1,\n",
              "       2, 2, 1, 2, 2, 2, 3, 2, 3, 0, 0, 0, 3, 1, 3, 3, 1, 0, 2, 2, 2, 2,\n",
              "       2, 3, 1, 3, 1, 0, 2, 2, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1,\n",
              "       3, 1, 1, 3, 2, 2, 1, 2, 0, 2, 1, 3, 2, 2, 1, 3, 2, 0, 2, 2, 1, 1,\n",
              "       3, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 0, 3, 0, 0, 3, 2, 1, 0, 3, 2, 0,\n",
              "       3, 3, 2, 2, 1, 2, 0, 2, 0, 3, 0, 2, 2, 0, 2, 2, 2, 1, 3, 3, 3, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 3, 0, 2, 1, 2, 2, 1, 0, 3, 3, 2, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 3, 0, 3, 0, 2, 1, 2, 2, 0, 3,\n",
              "       3, 0, 3, 3, 2, 1, 3, 0, 2, 1, 0, 2, 0, 2, 0, 0, 3, 1, 1, 2, 0, 2,\n",
              "       3, 1, 2, 0, 2, 3, 3, 3, 1, 3, 3, 2, 0, 3, 2, 1, 3, 3, 1, 1, 3, 3,\n",
              "       2, 0, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 0, 1,\n",
              "       2, 3, 3, 0, 2, 2, 1, 1, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1,\n",
              "       1, 0, 3, 2, 0, 1, 0, 0, 0, 2, 3, 3, 0, 0, 0, 3, 0, 2, 0, 1, 3, 3,\n",
              "       0, 0, 3, 3, 1, 0, 0, 1, 3, 2, 2, 2, 0, 0, 2, 0, 1, 0, 2, 2, 2, 1,\n",
              "       1, 3, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 3, 1, 2, 3, 2, 0, 1, 1, 0, 2,\n",
              "       0, 2, 1, 1, 0, 3, 3, 3, 1, 3, 1, 2, 2, 1, 1, 2, 1, 3, 1, 3, 2, 0,\n",
              "       2, 2, 3, 1, 3, 0, 0, 1, 0, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 2, 1, 1,\n",
              "       1, 0, 0, 2, 0, 3, 3, 2, 1, 3, 2, 3, 0, 3, 1, 0, 0, 2, 2, 2, 3, 2,\n",
              "       3, 0, 1, 3, 2, 1, 0, 0, 1, 2, 0, 2, 2, 2, 3, 0, 3, 1, 0, 2, 1, 2,\n",
              "       2, 3, 2, 3, 3, 2, 1, 1, 2, 1, 0, 0, 2, 1, 3, 0, 1, 0, 0, 0, 2, 2,\n",
              "       0, 2, 2, 3, 3, 0, 3, 0, 2, 2, 2, 0, 0, 3, 3, 1, 0, 3, 1, 3, 2, 1,\n",
              "       2, 1, 2, 2, 1, 1, 0, 0, 0, 2, 2, 0, 2, 2, 3, 0, 2, 1, 1, 2, 1, 1,\n",
              "       3, 0, 2, 1, 0, 0, 1, 2, 1, 0, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 3, 0,\n",
              "       1, 1, 0, 0, 1, 0, 2, 3, 0, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 3, 2, 2,\n",
              "       0, 2, 2, 3, 0, 2, 2, 1, 3, 0, 0, 0, 1, 0, 2, 0, 3, 2, 3, 0, 1, 1,\n",
              "       0, 2, 3, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 3, 2,\n",
              "       1, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 1, 3, 2, 1, 1, 1, 0, 0, 1, 2, 0,\n",
              "       3, 3, 2, 3, 0, 1, 1, 0, 2, 0, 3, 3, 3, 2, 0, 2, 2, 0, 2, 0, 0, 0,\n",
              "       2, 1, 2, 1, 1, 0, 1, 1, 3, 2, 0, 0, 2, 2, 3, 2, 3, 1, 1, 2, 2, 3,\n",
              "       0, 0, 1, 2, 1, 1, 0, 2, 0, 3, 2, 3, 1, 1, 1, 2, 2, 1, 0, 2, 3, 2,\n",
              "       1, 2, 1, 0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 1, 2, 3, 2, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, we are storing the largest values of the news in the training set in to the numpy array y_train. here target value is present the categories or labels for the news.\n",
        "\n",
        "talking about the machine learning, we are spliting the data intot he training and testing sets. where we use the training set to train the model while testing data will use to evaluate or testing the model and check how model is performing with unseen data.\n",
        "\n",
        "here, y_train has a shape n where n is the numeber of news articles in the training data. the shape represent that here the array is one dimensional. here we print the array, which is the number of the elements in the array.\n"
      ],
      "metadata": {
        "id": "PFVbYrehzawV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Transforming the outputs for a supervised learning task**\n",
        "\n",
        "**PLEASE READ:** Depending on the dataset you are working with, there could be datasets that contain non-numerical labels corresponding to the targets (outputs for a supervised learning problem). scikit-learn also includes utilities that you could use to convert (transform) your non-numeric labels to numeric ones."
      ],
      "metadata": {
        "id": "HU-bGhHtVihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "tgt_enc = preprocessing.LabelEncoder()\n",
        "\n",
        "# assume the following is the list of unique classes in your data\n",
        "some_data_targets = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\", \"paris\", \"tokyo\", \"tokyo\", \"tokyo\", \"amsterdam\", \"england\"]\n",
        "\n",
        "# fit your targets of the training data to the LabelEncoder instance\n",
        "tgt_enc.fit(some_data_targets)\n",
        "\n",
        "# get the set of unique classes\n",
        "print(f\"Unique categories: {list(tgt_enc.classes_)}\")\n",
        "\n",
        "# encode the targets as numerical labels\n",
        "encoded_tgts = tgt_enc.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
        "print(f\"Encoded labels: {encoded_tgts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfNDMLmYWT5z",
        "outputId": "75622cb3-f40d-403b-dda1-c34650c066eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories: ['amsterdam', 'england', 'paris', 'tokyo']\n",
            "Encoded labels: [3 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are using the labelencoder class from the sklearn. here we are preprocessing module in python to encode categorical target values into the numeric labels.Here we are importing the labelencoder class and instance of the class or say object of the class created.\n",
        "\n",
        "after that we are defining the list of the target data name as some_data_targets. here we are fiting the targets data from the training set into the labelencoder objects and for fit the data fit() method is used.\n",
        "\n",
        "after that class attribute tgt_enc is use to get the unique classes. this procedure will be done by classes_attribute and convert this into the list.\n",
        "\n",
        "at the last we are using the transform method which encode the new categorical data into the numerical labels.here three cities tokyo,tokyo,paris will be encoded into the numeric form using the transform() method. at the last we are sorting the results and print them using the encoded_tgts.\n"
      ],
      "metadata": {
        "id": "lrAk3CbAB2qM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Building a Learning Model Using Naive Bayes Algorithm**\n",
        "\n",
        "** **IMPORTANT!** ** - Regardless of the task, when building a learning model, always make sure ONLY the data from training set is used to train the model. ***Testing set MUST NEVER to be used to train/build the model***. Testing set is used only to report the results of your model, which is the last step of the process (after the model is trained and you have found a best model).\n",
        "\n",
        "**Note:** Building the model is also referred to as training the model."
      ],
      "metadata": {
        "id": "ScuTLK3BVoBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "tgt_enc = preprocessing.LabelEncoder()\n",
        "\n",
        "# assume the following is the list of unique classes in your data\n",
        "some_data_targets = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\", \"paris\", \"tokyo\", \"tokyo\", \"tokyo\", \"amsterdam\", \"england\"]\n",
        "\n",
        "# fit your targets of the training data to the LabelEncoder instance\n",
        "tgt_enc.fit(some_data_targets)\n",
        "\n",
        "# get the set of unique classes\n",
        "print(f\"Unique categories: {list(tgt_enc.classes_)}\")\n",
        "\n",
        "# encode the targets as numerical labels\n",
        "encoded_tgts = tgt_enc.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
        "print(f\"Encoded labels: {encoded_tgts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lM9ejB1VlH_",
        "outputId": "60572058-2040-4594-ed32-04612a09d4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories: ['amsterdam', 'england', 'paris', 'tokyo']\n",
            "Encoded labels: [3 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are using the labelencoder class from the sklearn. and its use for convert the categorical data into the numerical labels. the labelencoder is use for encoding the categorical features as an integer array.\n",
        "\n",
        "first, we create the instance of the labelencoder class, then we are fiting the encoded training data by calling fit() method on the object of the encoder using the some_data_target_list. here trains the encoder to identify the unique classes of the data.\n",
        "after that class_attribute we are using to retrieve the unique classes which is recognize during the training time of the model. its return the sorted list of the unique classes.\n",
        "\n",
        "At the last, we are using the method transform() which is encode object use to convert categorical data into the numberical data. here encoder convert the\"tokyo\",\"tokyo\",\"paris\" into the numerical lebels. here the output is store in the variable encoded_tgts and print them.\n",
        "\n",
        "overall, here we are using the labelencoder to process the categorical data for machine learning models.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CD8gxc7AZalS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Building a Learning Model Using Naive Bayes Algorithm**\n",
        "\n",
        "** **IMPORTANT!** ** - Regardless of the task, when building a learning model, always make sure ONLY the data from training set is used to train the model. ***Testing set MUST NEVER to be used to train/build the model***. Testing set is used only to report the results of your model, which is the last step of the process (after the model is trained and you have found a best model).\n",
        "\n",
        "**Note:** Building the model is also referred to as training the model."
      ],
      "metadata": {
        "id": "AksopSI4Vumf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb_model = MultinomialNB()\n",
        "mnb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "zwE4o7njVsZW",
        "outputId": "7030a4c1-f243-4216-c734-b40e21ed8d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here. we are first importing the sklearn library for implementing the naive bayes algorithm, specially, multinomial naive bayes  to train the machine learning model on  the labeled data.\n",
        "\n",
        "after that we are creating the instance of the multinomialNB , which is use to fit the model in the training data.here we are using the fit() method to used to train the multinomialNB model using the training data. X_train present the traing data of the model, while Y_train data is the test data which is used for evaluate or train the model.\n",
        "\n",
        "all in all. here we are fiting the multinomialNB naive bayes model train using the training data, once the model is trained, its use for prediction for the unseen data as well as the new data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V6W9StnCNZHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4(a): Make Predictions Using the Trained Model**\n",
        "**Note:** We are assuming that the above model trained is the best model for the data under consideration. *In reality, decision about the best model is based on performing hyperparameter tuning on a tuning/validation data set*. While hyperparameter tuning is out of scope for this notebook, you can always lookup articles, blog posts about this topic on the World Wide Web."
      ],
      "metadata": {
        "id": "7_8TaR4sVcsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# before testing the model, ensure your test data, both inputs and outputs, is ready for use:\n",
        "\n",
        "# 1. preprocess your testing data into a document-term matrix (using the training vocabulary)\n",
        "X_test = bow_vectorizer.transform(test_data.data)\n",
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv4aJyUcW0kM",
        "outputId": "4f85d475-a5a9-4301-9921-ebfff6a11f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1432x35329 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 230051 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are preparing the testing data for the machine learning model and its trained on the bag-of-words present the training data.\n",
        "\n",
        "here. we are uses the bow vectorizer object which was previously created and fit the traing data which transform the test data into the text matrix. this is represent the frequency of the occurance of the each word in the test documents,here its use the same vocab as the training data.\n",
        "\n",
        "transformation is use for test data in the same format as the training data and its use as the input of the machine learning model it was trained using the bow representations.\n"
      ],
      "metadata": {
        "id": "DwKNFlE3Y7gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. store the known outputs corresponding to the articles in the test set\n",
        "y_test = test_data.target\n",
        "\n",
        "print(f\"y_test array size: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7JhDpFhW2mr",
        "outputId": "6a0018b4-9fad-436d-8b3a-a209ff34363e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test array size: (1432,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here. we are using the test data for the dataset and split the test set for evaluating the model.\n",
        "\n",
        "and y_test= test_data.target is use for assign the variable. for instance, the ouput or label. here y_test is one dimensional array which contains the output of the corresponding documents in the test data.\n",
        "\n",
        "after that we are printing the y_test array size using the shape which is the number of the elements of the array. here its shows that how many articles in the test data where the how many known outputs are available for evaluating the perfomance of the model.\n"
      ],
      "metadata": {
        "id": "DCGOeauwd2sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, apply the model on the test set to make predictions\n",
        "# in this case, predictions are classification labels\n",
        "predictions = mnb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "RiFNP1EUW4eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, we are predicting the training model to the test set and here we are making the prediction of the target variables.for instace, we are classifying the articles in to the different categories.\n",
        "\n",
        "here we are using the mnb_model for trained the naive bayer model and we are fitting the model using the training data and after that we are using the predict() method for the naive bayes model that takes input as the X_train and return the prediction values which is the predicted classification label for each documents.\n",
        "\n",
        "we are using the prediction , which is one dimensional array which is containg the predicted label of the each documents for test set. predicted labels will be compared to the known outputs to y_tests for evaluating the performance of the model for test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "dx7Lc4wud3b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using the same model but predictions are probabilities\n",
        "y_pred_prob = mnb_model.predict_proba(X_test)\n",
        "print(y_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T5N_IhlW6RL",
        "outputId": "16a01b6e-b198-432a-bd6b-c64d93a83639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.75544189e-101 1.35696571e-093 9.04229140e-034 1.00000000e+000]\n",
            " [1.00000000e+000 8.11913323e-031 5.82342828e-045 1.00498728e-040]\n",
            " [7.23391406e-081 1.00000000e+000 6.57667626e-091 2.33963648e-074]\n",
            " [1.00000000e+000 2.06238640e-062 6.13232665e-085 3.97450971e-090]\n",
            " [4.78607486e-029 9.99999460e-001 5.40232163e-007 7.64770874e-016]\n",
            " [1.97449728e-016 3.80488166e-013 1.00000000e+000 1.31095855e-013]\n",
            " [1.00746827e-222 1.00000000e+000 1.75010680e-256 2.36523385e-255]\n",
            " [1.24078514e-069 1.00000000e+000 1.14014415e-084 1.21604211e-078]\n",
            " [1.00000000e+000 3.13263274e-015 1.72011457e-017 6.44230160e-014]\n",
            " [3.39809835e-025 1.00000000e+000 2.57276712e-039 1.83202609e-037]\n",
            " [9.21847391e-033 3.74504638e-027 2.58294255e-015 1.00000000e+000]\n",
            " [4.44624717e-012 8.12823934e-012 9.99999268e-001 7.32111989e-007]\n",
            " [1.15879118e-054 1.88240173e-035 1.20272394e-031 1.00000000e+000]\n",
            " [2.98126336e-165 2.98083778e-158 5.95385832e-006 9.99994046e-001]\n",
            " [6.53315939e-051 1.25933135e-047 9.99999955e-001 4.51282503e-008]\n",
            " [5.66212504e-021 1.00000000e+000 9.05439968e-023 1.93775582e-021]\n",
            " [1.00000000e+000 2.23236780e-044 4.95381750e-075 7.12858071e-073]\n",
            " [9.75186862e-001 3.27525705e-005 2.47803857e-002 7.23241461e-012]\n",
            " [1.11373994e-037 1.00000000e+000 1.84530082e-046 4.34929249e-050]\n",
            " [3.19332875e-088 1.56137462e-077 9.08025579e-002 9.09197442e-001]\n",
            " [1.00000000e+000 1.08059447e-026 4.04373005e-039 2.10881396e-037]\n",
            " [1.00000000e+000 2.93308156e-041 8.90719504e-037 3.85279492e-046]\n",
            " [9.05386193e-212 1.63182102e-159 1.00000000e+000 1.45406465e-033]\n",
            " [3.10939472e-073 1.00000000e+000 2.99110142e-086 1.41174770e-090]\n",
            " [3.38990786e-046 3.87197643e-030 1.00000000e+000 9.11246778e-018]\n",
            " [1.15807390e-070 3.04175617e-061 2.96692707e-046 1.00000000e+000]\n",
            " [9.99999999e-001 5.06136259e-010 1.18483110e-024 7.21499377e-017]\n",
            " [2.47109768e-105 1.85976090e-100 5.04491303e-006 9.99994955e-001]\n",
            " [1.32529131e-048 1.00000000e+000 3.24845254e-048 4.36482174e-048]\n",
            " [7.81814655e-025 1.00000000e+000 6.97737026e-020 5.67858460e-015]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.39561971e-114]\n",
            " [2.07824693e-094 1.96471867e-062 4.28721121e-037 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 2.19323005e-136]\n",
            " [9.97910410e-125 1.08810962e-084 1.00000000e+000 8.29965708e-025]\n",
            " [1.00000000e+000 3.45760039e-013 1.95660706e-019 4.44315210e-017]\n",
            " [5.07647616e-032 1.00000000e+000 2.72140502e-041 5.78896495e-026]\n",
            " [1.00000000e+000 4.61372229e-010 1.21008765e-019 5.63023707e-017]\n",
            " [2.16704540e-122 4.10504364e-097 1.00000000e+000 1.84493490e-026]\n",
            " [1.40769036e-092 7.93900595e-080 1.00000000e+000 1.94169393e-031]\n",
            " [8.20695134e-025 1.00000000e+000 2.08769068e-021 4.72489168e-010]\n",
            " [3.60286378e-007 9.99999640e-001 6.83841819e-014 2.36770293e-012]\n",
            " [3.39576328e-001 6.60423672e-001 2.01429385e-022 5.20571468e-017]\n",
            " [9.98663733e-001 1.33593749e-003 3.62569800e-008 2.93041491e-007]\n",
            " [1.00000000e+000 2.10434154e-049 6.35577195e-089 2.41050117e-094]\n",
            " [1.38139565e-029 1.90535723e-024 1.00000000e+000 1.64644376e-016]\n",
            " [1.00000000e+000 1.38777108e-017 2.05624187e-027 4.27391997e-030]\n",
            " [5.68556299e-008 9.99999942e-001 7.24457306e-010 1.67480492e-012]\n",
            " [1.40058187e-057 1.00000000e+000 7.92542346e-090 4.98214053e-085]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.00000000e+000 3.49816337e-024 3.04072881e-039 9.89422349e-039]\n",
            " [1.96733199e-069 1.67095958e-060 1.00000000e+000 4.85553092e-025]\n",
            " [1.00000000e+000 1.00967240e-010 7.47699617e-012 1.78883339e-012]\n",
            " [1.00000000e+000 4.51181503e-025 4.25665909e-038 4.39956534e-038]\n",
            " [2.88889414e-024 4.16182455e-025 2.19136941e-023 1.00000000e+000]\n",
            " [9.99984701e-001 3.60561541e-038 1.52985785e-005 4.98671621e-013]\n",
            " [8.28913417e-067 7.51071689e-057 1.00000000e+000 4.50793034e-044]\n",
            " [1.00000000e+000 1.63219708e-054 1.79325179e-054 2.65272335e-056]\n",
            " [6.66384901e-002 2.88674777e-001 3.06041660e-004 6.44380692e-001]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [4.89012219e-048 1.58831579e-042 1.74473129e-020 1.00000000e+000]\n",
            " [1.00000000e+000 6.22340505e-070 7.47064589e-106 1.81903342e-100]\n",
            " [1.78632700e-008 9.98119976e-001 2.52150855e-008 1.87998137e-003]\n",
            " [9.02719646e-242 2.04793210e-175 9.99713359e-001 2.86641175e-004]\n",
            " [2.26258116e-053 1.00000000e+000 2.08697072e-033 4.90716897e-029]\n",
            " [5.79944899e-085 5.85487044e-076 1.00000000e+000 1.96997886e-033]\n",
            " [1.00570040e-072 1.00000000e+000 2.14246719e-089 6.30286606e-090]\n",
            " [1.00000000e+000 1.80045692e-053 2.24264565e-075 3.54888952e-076]\n",
            " [1.84384066e-054 1.51777121e-043 1.00000000e+000 1.98345468e-020]\n",
            " [1.35408580e-016 9.99999376e-001 6.23781180e-007 2.48719469e-014]\n",
            " [5.80593608e-019 5.66570907e-001 3.75532287e-018 4.33429093e-001]\n",
            " [4.32399962e-170 2.34058119e-115 1.00000000e+000 1.35193006e-059]\n",
            " [2.48295155e-134 1.52358529e-117 1.00000000e+000 1.36746424e-015]\n",
            " [4.06000638e-150 4.25668076e-106 4.26612703e-056 1.00000000e+000]\n",
            " [2.63917744e-046 1.73017527e-043 1.00000000e+000 8.20311833e-031]\n",
            " [1.00000000e+000 6.77046258e-026 3.19233575e-048 2.13718384e-034]\n",
            " [1.00000000e+000 2.66248167e-024 7.58489115e-046 1.10775959e-045]\n",
            " [1.16080838e-053 1.00000000e+000 1.71125837e-068 1.29416014e-071]\n",
            " [1.49487651e-003 3.04024068e-004 3.58542356e-002 9.62346864e-001]\n",
            " [1.64917569e-101 9.66715452e-080 1.32645579e-017 1.00000000e+000]\n",
            " [4.71345001e-027 1.00000000e+000 6.45682508e-032 3.07347558e-036]\n",
            " [4.46127896e-078 2.00972755e-066 1.00000000e+000 3.29469778e-057]\n",
            " [1.00000000e+000 1.02982859e-092 7.64916800e-123 1.39334968e-113]\n",
            " [1.52367324e-031 1.00000000e+000 6.44312866e-031 4.30087613e-014]\n",
            " [4.45680431e-048 1.00000000e+000 1.99160372e-050 2.07811786e-034]\n",
            " [6.93342708e-013 3.63193488e-016 2.08534154e-017 1.00000000e+000]\n",
            " [1.00000000e+000 1.51081289e-075 2.86147526e-092 4.97164179e-082]\n",
            " [1.00000000e+000 7.50048447e-016 2.88900275e-023 1.32316515e-020]\n",
            " [3.55341307e-180 2.17008658e-142 1.00000000e+000 3.46560086e-017]\n",
            " [2.85341106e-050 1.00000000e+000 2.56088729e-068 4.69893598e-057]\n",
            " [1.15490111e-034 1.00000000e+000 1.00637216e-028 1.77504285e-041]\n",
            " [1.00000000e+000 4.49787613e-056 4.29677056e-077 3.64045735e-075]\n",
            " [2.17709808e-078 1.48008260e-070 1.00000000e+000 2.98039710e-039]\n",
            " [1.00000000e+000 6.44627126e-108 4.81414794e-131 5.63078813e-139]\n",
            " [9.97355006e-049 3.63299413e-035 8.16621655e-001 1.83378345e-001]\n",
            " [1.00000000e+000 6.79959596e-069 6.71436270e-082 8.55348120e-084]\n",
            " [7.59721867e-023 1.00000000e+000 9.98844452e-011 3.15927606e-014]\n",
            " [5.98512070e-055 1.43126299e-037 1.00000000e+000 2.90796844e-024]\n",
            " [1.00000000e+000 1.41108125e-020 4.51008510e-029 2.83557411e-032]\n",
            " [1.43054937e-018 1.00000000e+000 2.78329998e-029 9.36794419e-036]\n",
            " [3.58226361e-189 7.63204949e-135 1.00000000e+000 1.34999486e-013]\n",
            " [1.45217826e-100 1.59891404e-075 1.00000000e+000 1.05834774e-021]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.59892600e-099]\n",
            " [4.11882414e-012 7.94666543e-016 1.00000000e+000 1.55246755e-019]\n",
            " [8.03038723e-232 2.31537708e-180 1.00000000e+000 5.96987330e-056]\n",
            " [9.63254841e-079 5.97304138e-029 9.99957188e-001 4.28121592e-005]\n",
            " [2.17873064e-034 1.14553614e-017 3.26340167e-005 9.99967366e-001]\n",
            " [2.47891995e-063 1.57835359e-060 2.71708557e-043 1.00000000e+000]\n",
            " [8.91000062e-095 3.38548500e-082 1.00000000e+000 6.54719600e-014]\n",
            " [2.32627475e-107 6.29094479e-088 1.00000000e+000 2.00006714e-024]\n",
            " [8.56117013e-128 7.82456541e-104 1.00000000e+000 3.06657855e-030]\n",
            " [1.94413972e-118 3.24100861e-093 1.00000000e+000 2.82938550e-055]\n",
            " [9.51672300e-222 4.34545199e-194 1.00000000e+000 8.47579213e-061]\n",
            " [1.27943440e-102 1.00000000e+000 1.08472462e-062 3.86558767e-060]\n",
            " [6.58643356e-029 1.00000000e+000 1.91382395e-033 8.85201360e-041]\n",
            " [1.68974424e-149 7.92574248e-101 1.00000000e+000 3.25098027e-031]\n",
            " [3.07583055e-002 9.69241695e-001 1.14722746e-020 7.42066749e-015]\n",
            " [1.49822304e-078 2.99148675e-058 1.00000000e+000 1.59417726e-012]\n",
            " [2.01040299e-021 4.79598608e-019 1.00000000e+000 2.32663369e-021]\n",
            " [5.80165183e-246 2.16162890e-201 1.00000000e+000 5.81768988e-056]\n",
            " [4.30007278e-018 1.00000000e+000 4.72717775e-029 3.58858995e-028]\n",
            " [2.09147931e-044 9.99999973e-001 2.69046112e-008 2.57834414e-012]\n",
            " [1.16680017e-027 1.00000000e+000 1.88975821e-018 1.21248345e-023]\n",
            " [4.93037763e-017 2.57784825e-014 9.99974496e-001 2.55043326e-005]\n",
            " [4.87150973e-049 1.00000000e+000 9.38493449e-060 4.22391059e-044]\n",
            " [1.46994518e-026 1.11400216e-017 1.11003673e-013 1.00000000e+000]\n",
            " [4.12378971e-202 4.36370690e-158 1.00000000e+000 3.80500782e-051]\n",
            " [1.00000000e+000 1.05094014e-023 3.91837288e-041 6.39025689e-055]\n",
            " [4.12853194e-030 1.00000000e+000 2.55103881e-025 4.20069459e-018]\n",
            " [8.83905135e-065 1.00000000e+000 3.31007457e-076 5.11749640e-068]\n",
            " [1.00000000e+000 1.88712618e-018 1.22555564e-027 5.60400020e-031]\n",
            " [6.00417783e-078 8.05938427e-078 1.00000000e+000 4.09433113e-041]\n",
            " [9.14790241e-111 1.00000000e+000 3.00737069e-112 2.24905820e-112]\n",
            " [1.00000000e+000 1.22711604e-030 1.03115758e-037 2.79182768e-034]\n",
            " [3.02943065e-002 9.69705694e-001 1.92778814e-016 3.60670379e-019]\n",
            " [8.20594517e-049 1.00000000e+000 2.09408414e-043 3.47433578e-042]\n",
            " [3.52956550e-179 1.00000000e+000 1.35212003e-171 6.09388793e-176]\n",
            " [1.00000000e+000 4.46843735e-011 1.85967907e-025 8.11531812e-020]\n",
            " [2.54168711e-012 1.00000000e+000 2.40974274e-024 5.43017322e-016]\n",
            " [1.44847995e-010 4.90344678e-001 1.02524835e-001 4.07130487e-001]\n",
            " [4.22116310e-018 1.00000000e+000 6.78230092e-028 4.75295279e-029]\n",
            " [5.10125547e-140 2.49559521e-111 1.00000000e+000 2.63089660e-036]\n",
            " [1.35220602e-133 6.59843626e-116 1.00000000e+000 5.47865374e-034]\n",
            " [1.35496698e-058 7.59650934e-048 1.00000000e+000 1.13246071e-025]\n",
            " [5.68407595e-178 5.39217197e-142 1.00000000e+000 4.66792254e-042]\n",
            " [1.00000000e+000 6.40841586e-026 1.41716311e-031 2.55655718e-035]\n",
            " [4.85036731e-064 6.14430545e-059 1.00000000e+000 9.52068467e-013]\n",
            " [8.94099241e-035 1.85421440e-029 3.34464670e-024 1.00000000e+000]\n",
            " [4.82153223e-240 4.44361861e-218 1.00000000e+000 8.47627375e-059]\n",
            " [1.94481843e-017 1.00000000e+000 1.83294378e-036 4.54401272e-032]\n",
            " [9.99999961e-001 3.86900751e-008 6.18251644e-022 5.50856454e-018]\n",
            " [8.35484971e-014 1.00000000e+000 5.79667563e-026 1.74409000e-014]\n",
            " [2.66343643e-022 1.00000000e+000 2.98011718e-015 1.57601693e-013]\n",
            " [1.17854088e-091 1.00000000e+000 2.54883053e-099 3.42861708e-103]\n",
            " [2.95911200e-043 1.00000000e+000 2.91557352e-031 5.90114143e-032]\n",
            " [1.00000000e+000 3.85215877e-023 6.88573695e-037 3.62817037e-034]\n",
            " [3.90444901e-068 2.45187086e-058 1.00000000e+000 1.76613772e-023]\n",
            " [1.00000000e+000 5.40845648e-036 1.50362478e-044 1.26300987e-045]\n",
            " [1.00000000e+000 1.31747885e-065 1.59575450e-084 7.38236161e-079]\n",
            " [2.96846305e-005 9.99970303e-001 5.83016479e-012 1.25560769e-008]\n",
            " [4.83686856e-011 1.23128630e-008 3.63824378e-001 6.36175610e-001]\n",
            " [4.56098024e-113 2.50332160e-098 1.00000000e+000 1.71427578e-018]\n",
            " [7.48353676e-181 3.84810886e-159 1.00000000e+000 6.71556753e-048]\n",
            " [1.00000000e+000 3.84287577e-011 6.05817495e-021 1.14910980e-015]\n",
            " [1.32323902e-004 9.99867676e-001 1.27726384e-014 1.14494001e-014]\n",
            " [1.37105110e-036 8.79358753e-032 7.66957469e-013 1.00000000e+000]\n",
            " [3.66599484e-100 1.00006704e-093 1.00000000e+000 5.96694390e-030]\n",
            " [9.31498144e-130 2.77176451e-117 7.36817051e-056 1.00000000e+000]\n",
            " [2.32717151e-257 2.04917412e-179 1.00000000e+000 2.02463968e-050]\n",
            " [1.00000000e+000 9.39277332e-027 2.31634249e-038 6.28725729e-021]\n",
            " [9.99993223e-001 6.75699838e-006 2.85047501e-009 1.76374486e-008]\n",
            " [4.45078340e-036 8.79844748e-034 1.00000000e+000 9.41618498e-027]\n",
            " [2.49688209e-041 1.03483355e-039 1.00000000e+000 4.79374449e-022]\n",
            " [7.63180916e-034 1.00000000e+000 3.48747813e-051 7.30648272e-044]\n",
            " [1.70000446e-010 1.77447908e-008 9.99996101e-001 3.88068944e-006]\n",
            " [7.07599026e-152 1.00000000e+000 1.28580323e-247 1.24213070e-225]\n",
            " [7.46296051e-009 9.99999993e-001 3.41517113e-028 1.06798378e-025]\n",
            " [1.00000000e+000 4.95248795e-023 4.92280504e-030 5.93212243e-035]\n",
            " [1.08751552e-055 1.15114497e-049 1.00000000e+000 5.17206881e-012]\n",
            " [2.09161074e-118 1.46815817e-087 1.00000000e+000 7.47020774e-038]\n",
            " [2.75245653e-049 1.00000000e+000 1.32680911e-018 1.21230949e-013]\n",
            " [1.00000000e+000 2.65674654e-035 6.18640664e-050 6.95303975e-037]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [5.94802906e-034 1.00000000e+000 6.12210578e-047 1.51324414e-054]\n",
            " [3.18204150e-037 1.00000000e+000 4.19178271e-034 7.24844547e-035]\n",
            " [2.71364424e-038 5.07206808e-033 1.00000000e+000 6.28792608e-016]\n",
            " [1.05213375e-034 1.62049359e-020 3.03337888e-002 9.69666211e-001]\n",
            " [1.00508135e-174 4.49966742e-156 1.00000000e+000 2.69652550e-087]\n",
            " [4.02071399e-136 1.08813163e-109 9.99239104e-001 7.60895673e-004]\n",
            " [3.52566454e-057 1.00000000e+000 2.33089863e-050 1.80802775e-055]\n",
            " [1.06443390e-073 3.91217914e-055 4.14769629e-016 1.00000000e+000]\n",
            " [1.55089968e-199 7.60891768e-176 1.00000000e+000 3.55853571e-051]\n",
            " [9.99999987e-001 1.31339236e-008 1.08057195e-025 7.25071551e-020]\n",
            " [3.46856751e-015 1.00000000e+000 6.48370441e-031 2.23573181e-017]\n",
            " [1.06266385e-052 2.58491458e-049 4.58595357e-008 9.99999954e-001]\n",
            " [9.39945760e-038 6.28877274e-040 1.00000000e+000 5.37173929e-017]\n",
            " [1.00000000e+000 4.08537375e-032 1.32847682e-082 2.19360992e-079]\n",
            " [1.00000000e+000 1.90937727e-044 7.00745747e-046 6.01951748e-042]\n",
            " [1.37676512e-094 2.68089714e-061 1.00000000e+000 1.34638145e-029]\n",
            " [2.81740052e-035 7.12293192e-024 1.00000000e+000 8.59785857e-014]\n",
            " [1.00000000e+000 2.32988326e-022 2.61432921e-036 5.65212171e-029]\n",
            " [5.25472089e-040 4.03427619e-009 3.28968208e-015 9.99999996e-001]\n",
            " [1.87421830e-027 1.00000000e+000 4.27398926e-032 1.61110501e-031]\n",
            " [1.00000000e+000 5.37288922e-015 3.72464357e-022 6.77436322e-021]\n",
            " [1.23218835e-001 8.76595657e-001 5.87069086e-009 1.85502527e-004]\n",
            " [1.00000000e+000 2.16079135e-045 1.27998472e-062 5.17657983e-068]\n",
            " [6.54767121e-162 1.28625969e-112 1.00000000e+000 3.12158100e-044]\n",
            " [1.57596940e-140 6.52464822e-120 1.69364169e-044 1.00000000e+000]\n",
            " [2.43393044e-059 8.82962186e-058 1.00000000e+000 2.36692588e-019]\n",
            " [9.13699693e-026 7.91057590e-026 2.59308314e-016 1.00000000e+000]\n",
            " [5.74753879e-023 1.85540833e-022 1.03710235e-016 1.00000000e+000]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.26606247e-054 4.25696917e-037 8.61806976e-008 9.99999914e-001]\n",
            " [1.00000000e+000 6.60079383e-021 2.44446548e-035 2.35339970e-021]\n",
            " [1.00000000e+000 4.96143088e-041 2.34932625e-105 4.68239226e-093]\n",
            " [1.89132408e-076 1.00000000e+000 1.31317212e-067 1.30886464e-075]\n",
            " [8.19588780e-047 3.43933377e-033 1.00000000e+000 1.11322068e-015]\n",
            " [1.00000000e+000 9.52954325e-022 9.42879185e-039 4.16247621e-034]\n",
            " [4.94407328e-055 1.00000000e+000 1.56379698e-013 6.83598963e-012]\n",
            " [6.82431056e-052 1.00000000e+000 2.98031663e-055 1.00266721e-048]\n",
            " [2.06180906e-075 1.31176759e-051 1.00000000e+000 2.91519803e-015]\n",
            " [1.00000000e+000 3.71264609e-025 2.45949332e-026 2.51369756e-025]\n",
            " [7.70999669e-100 2.60442111e-087 1.00000000e+000 1.87067975e-018]\n",
            " [1.00000000e+000 2.81789738e-018 6.86488612e-023 2.26353575e-018]\n",
            " [1.90028269e-046 1.14199505e-042 1.00000000e+000 5.22652875e-012]\n",
            " [4.96710285e-011 1.00000000e+000 2.63745652e-063 1.55003844e-066]\n",
            " [1.10382308e-030 1.00000000e+000 2.02882085e-041 2.30856906e-035]\n",
            " [1.91606189e-085 1.76090062e-070 1.00000000e+000 4.81312451e-037]\n",
            " [1.06494826e-013 6.98118569e-017 1.88463493e-021 1.00000000e+000]\n",
            " [1.00000000e+000 2.75279021e-037 3.92231987e-052 7.83128930e-053]\n",
            " [2.96167623e-059 1.00000000e+000 3.88660742e-076 1.02804689e-067]\n",
            " [1.97753472e-139 3.25572913e-119 1.00000000e+000 1.94998157e-040]\n",
            " [9.99999993e-001 7.32800135e-009 4.04436964e-016 3.20528839e-016]\n",
            " [1.43815745e-112 6.44626393e-097 2.12539193e-045 1.00000000e+000]\n",
            " [1.02215060e-127 4.39083116e-114 1.00000000e+000 6.55412252e-043]\n",
            " [4.51993327e-051 1.37803318e-043 1.00000000e+000 7.17122277e-018]\n",
            " [7.86056183e-145 3.05698998e-123 1.00000000e+000 1.09487093e-043]\n",
            " [3.31806139e-034 3.44467943e-036 1.00000000e+000 5.86739976e-014]\n",
            " [1.00000000e+000 1.19348709e-033 2.10185763e-049 2.31967696e-035]\n",
            " [4.30554865e-078 9.28258469e-068 3.72244202e-032 1.00000000e+000]\n",
            " [2.24151202e-031 9.51793503e-027 1.00000000e+000 4.10744654e-019]\n",
            " [4.82527841e-171 1.13468573e-129 1.00000000e+000 6.07163156e-053]\n",
            " [8.84762332e-024 1.64726724e-023 4.82892913e-014 1.00000000e+000]\n",
            " [1.06333749e-048 1.00000000e+000 4.78387207e-056 8.99013204e-054]\n",
            " [1.12456014e-026 1.00000000e+000 1.00762526e-027 7.13282123e-015]\n",
            " [1.57336934e-031 9.97061756e-001 6.01801970e-007 2.93764233e-003]\n",
            " [2.96596342e-027 9.27385390e-022 1.00000000e+000 8.14954561e-012]\n",
            " [1.00000000e+000 3.02117236e-015 2.92042050e-032 9.09787983e-029]\n",
            " [5.06462413e-189 1.73956227e-159 1.00000000e+000 2.58761216e-042]\n",
            " [2.21952003e-001 4.35997929e-001 2.95170750e-009 3.42050065e-001]\n",
            " [7.05173032e-229 7.18749424e-198 1.00000000e+000 9.72267439e-039]\n",
            " [1.35982656e-118 3.50730408e-100 3.09561347e-009 9.99999997e-001]\n",
            " [2.48919545e-235 9.20804174e-183 1.00000000e+000 3.66868707e-046]\n",
            " [2.83244313e-061 1.86122610e-054 1.00000000e+000 9.36663557e-029]\n",
            " [7.47856461e-073 3.70508058e-060 1.08782193e-025 1.00000000e+000]\n",
            " [1.00000000e+000 3.57054477e-020 1.82647419e-032 1.30134484e-036]\n",
            " [1.00083045e-109 1.00000000e+000 6.64323187e-113 2.30934134e-104]\n",
            " [9.99999866e-001 1.33558523e-007 1.56289974e-019 4.34383946e-020]\n",
            " [1.00000000e+000 1.80181354e-028 5.41088420e-032 1.06195083e-031]\n",
            " [7.67556311e-018 2.30980202e-015 9.99998530e-001 1.47016142e-006]\n",
            " [1.64781783e-042 1.97766539e-040 8.83622528e-001 1.16377472e-001]\n",
            " [3.44674686e-040 5.20722302e-034 1.00000000e+000 2.27194540e-018]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 0.00000000e+000]\n",
            " [5.64398807e-138 1.00185064e-118 1.00000000e+000 8.96473980e-047]\n",
            " [1.00033924e-009 9.99999999e-001 2.78288527e-018 1.04035247e-012]\n",
            " [1.04633288e-050 2.61186686e-025 1.98423797e-005 9.99980158e-001]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 5.06953041e-074]\n",
            " [2.86248969e-091 5.71347242e-079 1.00000000e+000 5.87410948e-026]\n",
            " [1.24463020e-037 5.45478446e-037 9.99999994e-001 6.48977987e-009]\n",
            " [6.38800489e-051 1.72517189e-033 9.99999987e-001 1.25317250e-008]\n",
            " [3.80915638e-090 1.15393498e-077 1.00000000e+000 9.93029740e-013]\n",
            " [0.00000000e+000 2.88099094e-279 1.00000000e+000 1.65662472e-092]\n",
            " [1.51387424e-043 3.81953779e-032 1.00000000e+000 8.53775445e-020]\n",
            " [6.59204611e-058 5.75411976e-058 2.43242876e-034 1.00000000e+000]\n",
            " [1.29367569e-107 2.55442037e-082 5.56749668e-013 1.00000000e+000]\n",
            " [1.98862001e-033 1.67079876e-029 1.00000000e+000 5.74921556e-014]\n",
            " [4.62363657e-121 3.54250402e-090 1.00000000e+000 1.19449204e-037]\n",
            " [1.73403583e-025 1.57750622e-021 1.49719803e-022 1.00000000e+000]\n",
            " [2.27367645e-029 5.28223829e-022 1.00000000e+000 9.80764997e-016]\n",
            " [5.78939779e-011 1.00000000e+000 4.25117736e-026 6.98314020e-024]\n",
            " [2.06276234e-020 1.00000000e+000 1.41063871e-036 1.50928457e-040]\n",
            " [1.00000000e+000 2.19709866e-023 2.62236161e-039 4.03466754e-032]\n",
            " [2.52150264e-070 7.80076600e-060 1.00000000e+000 2.84454773e-021]\n",
            " [1.00000000e+000 1.15838100e-025 4.18381317e-019 2.49247850e-028]\n",
            " [3.10084643e-029 3.59267178e-002 2.06606623e-003 9.62007216e-001]\n",
            " [6.21272673e-115 3.66894629e-005 8.23894433e-009 9.99963302e-001]\n",
            " [1.00000000e+000 8.36273311e-067 1.61151820e-103 3.35368410e-084]\n",
            " [1.00000000e+000 1.68870457e-067 8.50619119e-092 1.62420392e-077]\n",
            " [3.20047701e-009 9.99999997e-001 2.12231857e-035 4.05054781e-042]\n",
            " [1.00000000e+000 1.45737686e-015 1.48528479e-027 4.77477916e-024]\n",
            " [1.00000000e+000 4.06321998e-011 5.58916708e-015 8.29064355e-018]\n",
            " [5.84479233e-011 1.00000000e+000 4.44147620e-021 6.20176176e-015]\n",
            " [2.48289076e-029 1.00000000e+000 8.64099009e-029 1.74235660e-035]\n",
            " [6.03724553e-162 3.66639968e-134 1.30728726e-018 1.00000000e+000]\n",
            " [1.39377085e-182 8.22413523e-156 1.08358628e-016 1.00000000e+000]\n",
            " [2.03000687e-160 1.72107088e-143 1.00000000e+000 1.24815525e-037]\n",
            " [1.37249854e-004 7.44473488e-008 9.99861633e-001 1.04221132e-006]\n",
            " [1.38658534e-079 3.18329783e-053 3.43083669e-047 1.00000000e+000]\n",
            " [1.00000000e+000 8.04453115e-017 8.56344837e-047 1.13429670e-046]\n",
            " [3.51652147e-029 1.00000000e+000 1.44871776e-025 1.30617313e-026]\n",
            " [1.00000000e+000 5.53534738e-036 8.88798571e-058 4.28781995e-049]\n",
            " [1.00000000e+000 3.11595086e-028 8.12157540e-036 7.05940170e-031]\n",
            " [1.00000000e+000 3.20904529e-010 8.46296883e-019 6.01899088e-014]\n",
            " [3.15411683e-056 5.45929930e-046 1.00000000e+000 1.14962316e-012]\n",
            " [1.00000000e+000 6.21478132e-012 1.53637257e-018 6.41177051e-021]\n",
            " [1.00000000e+000 2.09439594e-035 6.13658938e-054 3.27554993e-045]\n",
            " [1.44043631e-061 1.46843107e-043 1.00000000e+000 9.15974606e-026]\n",
            " [5.26089336e-069 1.23574220e-062 1.00000000e+000 7.11858822e-016]\n",
            " [1.25040022e-052 1.11793122e-048 9.99999993e-001 6.83958189e-009]\n",
            " [1.00000000e+000 9.52143784e-029 2.40559313e-044 1.09560106e-044]\n",
            " [7.64464044e-053 1.61575365e-029 1.80234543e-019 1.00000000e+000]\n",
            " [1.00000000e+000 1.02536852e-030 6.10984131e-042 1.47656177e-034]\n",
            " [5.17040453e-012 3.68305303e-009 9.56050621e-001 4.39493758e-002]\n",
            " [4.12136251e-003 9.95878601e-001 2.81798055e-016 3.62560352e-008]\n",
            " [0.00000000e+000 0.00000000e+000 5.85650194e-067 1.00000000e+000]\n",
            " [1.00000000e+000 2.73155959e-021 1.51828653e-064 1.50369530e-061]\n",
            " [1.00000000e+000 8.30367541e-019 2.81806786e-032 4.57153369e-040]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [3.09048059e-067 3.93173078e-053 8.58013944e-031 1.00000000e+000]\n",
            " [1.59189625e-031 1.47723042e-024 1.00000000e+000 1.26830447e-012]\n",
            " [1.00000000e+000 3.22034807e-077 7.83693639e-152 1.04363996e-138]\n",
            " [6.08953328e-063 1.00000000e+000 5.84508478e-065 1.86545625e-067]\n",
            " [5.56391407e-004 1.14495774e-001 8.70153681e-001 1.47941539e-002]\n",
            " [1.00000000e+000 5.27181250e-019 4.10345189e-026 3.00961957e-021]\n",
            " [6.84653846e-042 2.32412008e-036 1.00000000e+000 2.87509170e-017]\n",
            " [1.60925767e-013 1.00000000e+000 8.94801740e-026 1.13122083e-017]\n",
            " [1.70789730e-118 5.99770143e-099 4.32755604e-011 1.00000000e+000]\n",
            " [5.41803906e-004 9.99458196e-001 8.82831166e-034 6.02552058e-031]\n",
            " [1.82868507e-036 1.98096171e-026 2.43578288e-024 1.00000000e+000]\n",
            " [1.00000000e+000 6.32197638e-055 4.86308874e-076 2.41047213e-072]\n",
            " [9.35941245e-030 1.00000000e+000 7.71321093e-035 7.64762103e-027]\n",
            " [2.09527844e-054 4.57441129e-039 1.00000000e+000 1.29465823e-017]\n",
            " [6.34010853e-030 1.00000000e+000 1.04915169e-029 1.99469542e-026]\n",
            " [1.00000000e+000 4.78049616e-021 7.13360011e-027 2.22926569e-028]\n",
            " [1.00000000e+000 1.25935371e-015 1.00408628e-020 5.43841500e-021]\n",
            " [1.39602590e-135 6.34232125e-089 1.00000000e+000 1.72204623e-033]\n",
            " [6.09465328e-090 1.00000000e+000 2.14199874e-103 1.19244087e-097]\n",
            " [2.25597277e-062 7.98769111e-070 1.00000000e+000 4.01873042e-036]\n",
            " [1.00000000e+000 2.68833937e-046 4.52164560e-069 3.35943677e-061]\n",
            " [8.99050166e-054 1.00000000e+000 2.76357951e-053 3.80921771e-045]\n",
            " [8.13570564e-054 1.26200655e-043 1.00000000e+000 1.01570349e-019]\n",
            " [1.56173932e-170 1.25254651e-115 1.00000000e+000 4.04213544e-059]\n",
            " [1.00000000e+000 5.73651622e-014 4.50522272e-017 7.62954864e-021]\n",
            " [9.99999985e-001 1.53497422e-008 8.52032133e-043 2.76096586e-046]\n",
            " [1.00000000e+000 1.29971846e-033 8.45317533e-053 7.71917339e-045]\n",
            " [5.22211416e-061 1.00000000e+000 1.70105166e-065 3.99571174e-063]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.31664348e-227]\n",
            " [1.63497625e-062 1.38664077e-046 7.00903285e-045 1.00000000e+000]\n",
            " [2.90960558e-070 1.00000000e+000 6.23376450e-098 4.59288333e-091]\n",
            " [1.00000000e+000 4.32540396e-023 2.00396183e-180 7.20022986e-216]\n",
            " [2.40890048e-053 1.00000000e+000 1.99104168e-044 1.56212566e-047]\n",
            " [3.56693186e-057 4.18454969e-045 5.05912141e-004 9.99494088e-001]\n",
            " [1.94562258e-033 3.84223158e-023 9.99998255e-001 1.74494714e-006]\n",
            " [1.04030860e-032 2.99146258e-038 3.43598639e-010 1.00000000e+000]\n",
            " [4.82883326e-096 3.03619330e-087 1.00000000e+000 2.77488223e-044]\n",
            " [9.38927702e-036 1.00000000e+000 2.22547814e-051 3.33397816e-036]\n",
            " [2.94039532e-092 1.10099576e-070 1.43557407e-061 1.00000000e+000]\n",
            " [1.00000000e+000 9.56801864e-025 4.69910842e-028 5.30681326e-023]\n",
            " [1.00000000e+000 8.79390515e-037 2.76103909e-055 1.49090662e-047]\n",
            " [2.14981545e-008 9.99999978e-001 1.09894040e-020 6.86377290e-010]\n",
            " [4.86283621e-096 4.38663184e-083 9.94155999e-040 1.00000000e+000]\n",
            " [1.00000000e+000 4.28374702e-020 1.20858645e-031 8.28164163e-029]\n",
            " [1.00000000e+000 6.50064367e-020 6.15150453e-059 4.73680195e-049]\n",
            " [5.43812371e-071 1.00000000e+000 2.46754883e-060 5.80192912e-062]\n",
            " [1.12641756e-056 2.42651387e-047 1.00000000e+000 9.39651481e-028]\n",
            " [2.30151909e-041 6.29812798e-039 9.99999992e-001 7.95175713e-009]\n",
            " [3.00647295e-027 1.00000000e+000 2.44453569e-035 5.92699156e-040]\n",
            " [6.01287104e-042 8.89893220e-041 1.00000000e+000 2.14885995e-030]\n",
            " [2.04296841e-009 5.78380153e-008 7.70729222e-008 9.99999863e-001]\n",
            " [7.83666159e-165 1.61431189e-139 1.00000000e+000 9.18774105e-050]\n",
            " [6.14113989e-010 9.99999068e-001 1.42766609e-010 9.30841174e-007]\n",
            " [9.99450831e-001 5.49169088e-004 4.19222587e-044 8.35268750e-050]\n",
            " [1.00000000e+000 1.88785342e-240 8.36852406e-219 1.70521842e-257]\n",
            " [1.00000000e+000 1.48836376e-038 2.71817665e-052 3.80585173e-044]\n",
            " [1.00000000e+000 5.33185883e-022 1.44840234e-030 1.35700436e-031]\n",
            " [6.35743807e-057 1.00000000e+000 1.10999604e-023 2.54205333e-037]\n",
            " [8.89181074e-134 4.25440950e-117 1.00000000e+000 1.26369569e-027]\n",
            " [2.19460213e-084 4.40123365e-076 4.92532606e-040 1.00000000e+000]\n",
            " [2.67061119e-013 1.00000000e+000 4.80751803e-028 4.49162078e-026]\n",
            " [1.00000000e+000 5.57217134e-074 3.05091585e-123 1.46848331e-132]\n",
            " [9.82125155e-015 9.41156850e-018 9.99999999e-001 8.80838230e-010]\n",
            " [5.67991218e-017 7.67874072e-013 1.04993531e-001 8.95006469e-001]\n",
            " [1.51035947e-060 1.00000000e+000 5.27816026e-052 3.42647907e-049]\n",
            " [5.85690054e-095 4.10146998e-078 1.00000000e+000 6.71737142e-016]\n",
            " [1.13749310e-072 4.14339956e-057 1.00000000e+000 3.28548712e-022]\n",
            " [1.51547342e-060 1.00000000e+000 1.09519820e-061 3.58544276e-057]\n",
            " [2.13636891e-004 9.99786363e-001 7.19810734e-025 7.30015388e-016]\n",
            " [1.00000000e+000 1.50701311e-034 2.20721029e-044 9.84634930e-035]\n",
            " [1.00000000e+000 2.90502219e-012 3.72054874e-024 1.11371242e-023]\n",
            " [6.52970005e-084 5.65630789e-031 1.00000000e+000 1.06558884e-022]\n",
            " [1.97536086e-009 4.81406666e-009 9.99999993e-001 2.27386324e-013]\n",
            " [9.99999958e-001 4.23363597e-008 5.88423906e-021 6.74333117e-018]\n",
            " [2.22812291e-093 3.22244430e-080 1.99753541e-053 1.00000000e+000]\n",
            " [7.03809011e-072 2.77782865e-054 5.40593135e-007 9.99999459e-001]\n",
            " [1.00000000e+000 5.87939534e-024 5.11655011e-031 4.85316775e-028]\n",
            " [3.92339702e-107 4.63747248e-110 1.28337157e-047 1.00000000e+000]\n",
            " [8.75944651e-023 1.00000000e+000 1.29460562e-024 1.30983252e-021]\n",
            " [1.01206721e-011 1.71017524e-010 9.99999722e-001 2.77894777e-007]\n",
            " [2.91384270e-018 3.81273931e-018 4.82060468e-018 1.00000000e+000]\n",
            " [1.88307230e-035 9.99999966e-001 2.76811607e-008 6.45691561e-009]\n",
            " [7.01367222e-097 2.55937719e-079 2.87194718e-035 1.00000000e+000]\n",
            " [3.97458284e-174 3.72838553e-129 1.00000000e+000 4.63352906e-056]\n",
            " [1.63128013e-054 4.82002488e-042 7.09094566e-037 1.00000000e+000]\n",
            " [8.41514815e-074 1.00000000e+000 8.54747603e-078 2.11964206e-072]\n",
            " [2.63896352e-031 1.00000000e+000 3.68443823e-038 2.19199720e-028]\n",
            " [4.24290546e-024 1.00000000e+000 4.22673819e-037 6.16100055e-034]\n",
            " [2.60576503e-133 1.52099197e-123 1.39892414e-052 1.00000000e+000]\n",
            " [1.36818726e-050 1.00000000e+000 4.55054357e-064 5.36200331e-056]\n",
            " [1.00000000e+000 1.76534324e-146 4.51881596e-291 2.59889267e-259]\n",
            " [1.00000000e+000 3.26825475e-016 3.66407813e-019 6.16774242e-018]\n",
            " [7.02241523e-023 2.16312410e-021 5.62348388e-006 9.99994377e-001]\n",
            " [9.99999999e-001 5.18905396e-010 2.23203803e-026 3.67900940e-019]\n",
            " [4.48734501e-165 1.01183330e-142 1.00000000e+000 3.55067369e-020]\n",
            " [3.03106820e-055 1.00000000e+000 2.85569949e-067 3.90233596e-056]\n",
            " [1.00000000e+000 1.81555093e-023 2.52326078e-038 9.04954205e-032]\n",
            " [4.75206594e-150 9.69606626e-137 1.00000000e+000 7.75342201e-072]\n",
            " [5.19057622e-034 9.94783172e-001 5.21563215e-003 1.19552736e-006]\n",
            " [3.14380902e-108 2.06114359e-081 8.74348517e-067 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 9.02640513e-268]\n",
            " [1.28194416e-181 5.33291734e-147 1.00000000e+000 1.18356886e-055]\n",
            " [6.38447810e-052 1.00000000e+000 1.10427314e-064 1.12106680e-054]\n",
            " [1.23311911e-242 3.94460886e-217 1.00000000e+000 1.66544940e-079]\n",
            " [1.00000000e+000 2.05034614e-098 1.15158604e-100 2.16510229e-121]\n",
            " [3.31990209e-129 1.46595465e-109 1.62076790e-034 1.00000000e+000]\n",
            " [8.47885926e-014 1.00000000e+000 1.33790031e-025 1.12367374e-020]\n",
            " [5.26401282e-068 5.61346607e-024 1.00000000e+000 1.38433278e-017]\n",
            " [1.14331989e-003 9.98856680e-001 7.65029858e-052 9.86519009e-037]\n",
            " [1.97529894e-055 6.40482149e-038 3.37394157e-002 9.66260584e-001]\n",
            " [2.26732997e-067 5.09533484e-069 1.00000000e+000 1.65965050e-046]\n",
            " [3.27630143e-044 1.00000000e+000 9.55317126e-054 3.59522200e-051]\n",
            " [1.87536673e-001 2.53458961e-003 8.09497149e-001 4.31588487e-004]\n",
            " [5.96325614e-049 1.00000000e+000 1.17050161e-055 2.65974162e-053]\n",
            " [9.07470792e-062 1.00000000e+000 1.67586978e-074 6.66127323e-057]\n",
            " [0.00000000e+000 0.00000000e+000 9.99999999e-001 5.09443533e-010]\n",
            " [1.00000000e+000 3.26633508e-025 6.08699107e-036 7.61231041e-035]\n",
            " [3.06501136e-064 2.18409348e-040 1.00000000e+000 8.41893591e-024]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.32460391e-104]\n",
            " [1.46589088e-046 1.00000000e+000 4.75979222e-062 2.25775722e-063]\n",
            " [1.67388558e-056 7.61855632e-048 1.00000000e+000 1.09913806e-013]\n",
            " [9.99999998e-001 2.48096601e-009 2.31043930e-021 2.13122673e-020]\n",
            " [1.00000000e+000 7.20170758e-014 1.67595274e-016 4.84092010e-018]\n",
            " [2.88144865e-054 1.15173179e-052 3.64054429e-021 1.00000000e+000]\n",
            " [1.00000000e+000 1.65910378e-018 3.78032197e-033 1.11318605e-024]\n",
            " [1.00000000e+000 2.61789435e-070 9.83741760e-074 1.61334492e-079]\n",
            " [1.00000000e+000 8.56874737e-015 3.76371502e-030 2.70177330e-024]\n",
            " [2.08889821e-012 2.58890146e-009 9.99999871e-001 1.26528915e-007]\n",
            " [1.00000000e+000 1.73384354e-020 4.01264920e-034 4.91204963e-035]\n",
            " [1.00000000e+000 1.65148272e-043 1.45848593e-059 2.14722040e-044]\n",
            " [3.82767700e-170 1.04847861e-139 1.00000000e+000 8.81312812e-049]\n",
            " [4.34614208e-059 1.60480763e-049 1.00000000e+000 1.37608750e-018]\n",
            " [1.24866616e-020 1.00000000e+000 2.04641909e-018 2.76955114e-016]\n",
            " [1.17463911e-013 7.44787427e-001 1.68564319e-018 2.55212573e-001]\n",
            " [4.40054861e-004 2.40196892e-004 9.99319748e-001 5.28977953e-020]\n",
            " [1.55353555e-017 1.00000000e+000 2.05925166e-030 4.59033836e-029]\n",
            " [1.74299293e-029 1.00000000e+000 2.65110255e-015 1.79269935e-018]\n",
            " [2.55838615e-239 1.21315304e-183 1.00000000e+000 3.17715233e-069]\n",
            " [1.00000000e+000 6.15854026e-047 2.64020889e-068 3.78416788e-061]\n",
            " [1.44470103e-039 1.16635875e-032 1.00000000e+000 4.98435554e-013]\n",
            " [9.83093162e-050 1.00000000e+000 5.89043624e-071 4.81955164e-059]\n",
            " [1.72791007e-013 1.00000000e+000 6.63435645e-017 7.21555305e-011]\n",
            " [4.48935984e-052 5.65637814e-058 8.74904697e-014 1.00000000e+000]\n",
            " [2.84978522e-090 1.00000000e+000 4.66048518e-076 8.81817117e-073]\n",
            " [2.41979939e-048 1.00000000e+000 5.14980751e-062 3.78895602e-066]\n",
            " [1.17405265e-120 1.90052853e-093 1.00000000e+000 9.64216734e-022]\n",
            " [3.43395534e-027 1.00000000e+000 7.33952307e-043 6.82590231e-038]\n",
            " [2.73433788e-022 4.21155711e-028 1.00000000e+000 2.86376825e-013]\n",
            " [6.34794883e-052 1.00000000e+000 2.64801661e-085 2.23872846e-081]\n",
            " [1.00000000e+000 5.00590503e-018 2.49917146e-029 4.97015391e-024]\n",
            " [1.52748127e-029 1.00000000e+000 6.19072276e-053 5.89301289e-057]\n",
            " [1.00000000e+000 2.18713825e-084 5.47327588e-178 1.78198568e-154]\n",
            " [1.91364708e-151 1.31519178e-094 9.98422683e-001 1.57731678e-003]\n",
            " [7.30531119e-273 3.75281589e-237 1.00000000e+000 1.70069875e-068]\n",
            " [1.00000000e+000 2.17635203e-022 1.47351156e-036 1.85986149e-038]\n",
            " [5.38920321e-121 3.76127703e-103 9.26638575e-003 9.90733614e-001]\n",
            " [7.21521209e-038 1.00000000e+000 5.12219053e-048 1.53614853e-044]\n",
            " [6.81852275e-136 2.83162115e-129 1.34766407e-037 1.00000000e+000]\n",
            " [1.00000000e+000 1.26676184e-086 7.25168281e-107 8.35672049e-111]\n",
            " [1.00000000e+000 8.18989986e-020 6.25325055e-032 5.06110731e-025]\n",
            " [1.56429377e-115 6.42020006e-097 1.00000000e+000 6.57811551e-015]\n",
            " [1.99970467e-047 1.00000000e+000 2.36910503e-064 7.03763899e-059]\n",
            " [9.02604639e-031 2.71767107e-029 8.87535738e-013 1.00000000e+000]\n",
            " [1.00000000e+000 9.50928571e-038 8.91802747e-178 7.46101485e-164]\n",
            " [6.35565133e-018 1.00000000e+000 1.50077875e-034 1.35268316e-025]\n",
            " [8.23051008e-023 1.18059145e-007 8.68620096e-010 9.99999881e-001]\n",
            " [1.00000000e+000 2.68300008e-025 1.47753337e-038 4.54107600e-028]\n",
            " [1.82195142e-095 7.62004137e-087 1.00000000e+000 1.25539122e-019]\n",
            " [1.00000000e+000 2.02916039e-016 5.26519073e-025 1.56713990e-022]\n",
            " [1.00000000e+000 1.54753840e-026 4.70177552e-022 3.22845090e-023]\n",
            " [1.00000000e+000 1.76387106e-056 1.97034829e-090 6.20820237e-092]\n",
            " [6.66243431e-032 1.78043857e-030 1.00000000e+000 2.54009056e-012]\n",
            " [1.00000000e+000 1.70876735e-019 6.41162612e-026 2.09926087e-027]\n",
            " [1.08388718e-091 9.51759337e-078 1.00000000e+000 6.52660070e-032]\n",
            " [3.63400517e-183 1.00000000e+000 1.51119846e-131 1.05863703e-152]\n",
            " [1.48483339e-044 1.00000000e+000 3.58649287e-069 7.79744919e-071]\n",
            " [9.99999982e-001 1.79684083e-008 2.00376970e-015 5.42305846e-013]\n",
            " [1.00000000e+000 2.08532179e-024 1.30064030e-047 6.82709883e-044]\n",
            " [3.32930612e-066 1.91852247e-056 1.00000000e+000 2.34334059e-024]\n",
            " [2.47450650e-048 1.00000000e+000 4.66731947e-048 1.10041346e-052]\n",
            " [1.52622628e-002 7.31651428e-001 2.53086306e-001 3.05396627e-009]\n",
            " [4.73244301e-012 4.51184880e-020 1.00000000e+000 1.88335038e-012]\n",
            " [9.23802330e-146 1.74807773e-128 1.00000000e+000 5.20581419e-035]\n",
            " [2.41878533e-009 9.99606694e-001 3.93263878e-004 3.94893777e-008]\n",
            " [2.16748091e-044 1.11094437e-041 1.00000000e+000 4.02723673e-018]\n",
            " [5.30533679e-062 1.00000000e+000 5.90029181e-060 1.86776859e-050]\n",
            " [1.34169763e-018 1.00000000e+000 1.63999700e-015 1.58417727e-021]\n",
            " [2.18576795e-080 1.77021824e-048 5.47281623e-005 9.99945272e-001]\n",
            " [1.00000000e+000 8.76948290e-019 3.66330302e-025 2.10681800e-031]\n",
            " [1.00000000e+000 4.22571504e-011 4.09323394e-023 6.80337321e-017]\n",
            " [1.00000000e+000 2.90322447e-013 3.11809553e-051 1.01612545e-056]\n",
            " [2.70871748e-010 1.00000000e+000 7.17781248e-030 9.51617030e-026]\n",
            " [2.98675849e-040 5.85680663e-041 2.21424792e-012 1.00000000e+000]\n",
            " [6.49954404e-316 3.47754042e-267 1.00000000e+000 1.71316343e-068]\n",
            " [3.90488506e-018 4.97368055e-017 2.44660484e-007 9.99999755e-001]\n",
            " [3.49144098e-099 1.00000000e+000 3.80028651e-103 4.05164660e-100]\n",
            " [2.35343641e-047 2.03846435e-036 1.00000000e+000 1.01110331e-014]\n",
            " [2.92264087e-061 2.07545845e-053 1.00000000e+000 1.72317027e-029]\n",
            " [1.14358768e-066 1.00000000e+000 3.64201778e-086 3.14015431e-090]\n",
            " [1.00000000e+000 1.92112306e-033 4.76772769e-044 1.31648306e-043]\n",
            " [1.00000000e+000 7.76908367e-056 4.43662018e-070 6.99961595e-058]\n",
            " [1.63152526e-089 3.10631955e-083 1.00000000e+000 9.36735639e-030]\n",
            " [1.10566537e-038 4.47287923e-015 1.85840872e-020 1.00000000e+000]\n",
            " [1.75298817e-058 5.77610693e-052 1.49794232e-003 9.98502058e-001]\n",
            " [3.50494624e-097 1.00000000e+000 6.80918245e-180 9.56707709e-167]\n",
            " [1.00000000e+000 3.38615381e-032 3.97759435e-046 1.35842016e-039]\n",
            " [1.68762895e-111 1.84986075e-085 3.61635623e-012 1.00000000e+000]\n",
            " [1.24870761e-090 1.00000000e+000 1.95983362e-065 9.77578218e-062]\n",
            " [5.50660999e-016 1.00000000e+000 1.14701145e-044 5.84332831e-032]\n",
            " [9.46600642e-069 1.27836883e-054 1.00000000e+000 1.71971616e-029]\n",
            " [1.00000000e+000 4.63371014e-071 3.89546797e-097 4.48706566e-102]\n",
            " [1.23799883e-130 7.35836685e-114 1.00000000e+000 2.40128731e-036]\n",
            " [2.06285346e-015 1.00000000e+000 4.28251054e-016 2.15642405e-016]\n",
            " [3.14202406e-094 1.00000000e+000 1.72547197e-095 1.62283978e-085]\n",
            " [3.67684788e-253 4.76837730e-208 1.00000000e+000 4.89987933e-045]\n",
            " [1.00000000e+000 6.75621860e-017 1.73988302e-029 3.58979269e-027]\n",
            " [1.67435713e-064 3.02628196e-060 2.95085027e-050 1.00000000e+000]\n",
            " [9.99989647e-001 1.03520096e-005 4.60536965e-013 9.46500853e-010]\n",
            " [1.05811759e-112 1.00000000e+000 2.27140812e-052 6.40317444e-068]\n",
            " [1.00000000e+000 3.60496292e-052 3.26266521e-062 2.79196757e-063]\n",
            " [1.00000000e+000 2.19431361e-159 2.35742867e-247 6.32918898e-217]\n",
            " [1.00000000e+000 1.96260186e-048 7.95089239e-062 7.06788183e-063]\n",
            " [3.66804834e-048 1.00000000e+000 1.18541162e-065 3.48430640e-062]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.48863746e-149]\n",
            " [5.49327184e-206 2.41041432e-168 1.00000000e+000 1.07232871e-041]\n",
            " [1.00000000e+000 1.58019084e-167 2.33271861e-193 6.06939171e-200]\n",
            " [1.28269783e-030 1.00000000e+000 1.27801041e-039 4.01707188e-041]\n",
            " [2.83929535e-145 1.57041660e-113 2.32672119e-029 1.00000000e+000]\n",
            " [9.77807805e-252 2.63974878e-201 1.00000000e+000 1.19592155e-062]\n",
            " [1.69494409e-002 6.42058426e-004 9.82408429e-001 7.12883217e-008]\n",
            " [1.37048198e-009 9.99999999e-001 5.49050810e-014 1.73699852e-015]\n",
            " [1.22618380e-012 1.00000000e+000 2.48302696e-016 4.45473201e-018]\n",
            " [1.59684925e-198 1.45130637e-167 1.00000000e+000 8.09895285e-034]\n",
            " [8.99581417e-265 5.78786391e-224 1.00000000e+000 1.38988704e-028]\n",
            " [2.69660351e-059 1.00000000e+000 1.24640311e-062 3.76043762e-068]\n",
            " [5.64568572e-043 1.00000000e+000 1.95063588e-056 1.33582711e-050]\n",
            " [9.70529101e-001 3.94324052e-007 4.50918818e-006 2.94659959e-002]\n",
            " [6.37767950e-088 6.68814073e-074 1.00000000e+000 7.26519554e-016]\n",
            " [2.08383278e-117 2.69522140e-083 1.00000000e+000 5.23244520e-046]\n",
            " [1.00000000e+000 1.53887653e-047 2.18697201e-046 4.19286809e-052]\n",
            " [0.00000000e+000 2.10850620e-249 1.00000000e+000 6.31986305e-078]\n",
            " [1.24233956e-128 9.90140613e-104 1.00000000e+000 4.87944854e-049]\n",
            " [1.00000000e+000 9.88083083e-063 9.41367650e-073 1.87444261e-069]\n",
            " [1.00000000e+000 1.29152647e-012 6.64102728e-022 2.72440442e-026]\n",
            " [1.00000000e+000 3.42955220e-012 1.34618032e-021 2.24270499e-015]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.26842750e-028]\n",
            " [1.00000000e+000 1.16756337e-026 3.48645759e-034 5.31507019e-031]\n",
            " [7.67205374e-021 8.16518444e-001 1.83481157e-001 3.99472064e-007]\n",
            " [1.72117356e-072 1.00000000e+000 1.24203869e-032 9.67196100e-042]\n",
            " [7.83716970e-001 2.16283030e-001 2.25064345e-030 1.48121902e-019]\n",
            " [1.00000000e+000 2.84343263e-078 7.24963541e-095 4.28463281e-103]\n",
            " [1.00000000e+000 1.43127816e-017 4.18471960e-036 5.93567313e-029]\n",
            " [1.00000000e+000 1.69164031e-023 4.75031450e-027 1.54750793e-034]\n",
            " [9.95940327e-001 4.01456976e-003 3.08524152e-005 1.42507558e-005]\n",
            " [7.64746084e-056 1.53404207e-052 1.00000000e+000 1.28704729e-011]\n",
            " [1.00000000e+000 3.22223956e-029 3.15096056e-034 2.67876883e-037]\n",
            " [6.53201632e-095 1.00000000e+000 4.92329164e-063 4.74672602e-063]\n",
            " [4.41386090e-015 1.00000000e+000 3.34800532e-020 1.88664739e-024]\n",
            " [5.46741774e-043 3.17433973e-033 1.00000000e+000 1.06233263e-011]\n",
            " [1.16237213e-045 2.02274091e-036 1.00000000e+000 1.76686681e-024]\n",
            " [1.98362246e-058 1.00000000e+000 2.12253067e-070 9.66019879e-060]\n",
            " [2.85354188e-068 6.06667164e-051 1.00000000e+000 2.54403943e-021]\n",
            " [1.58055891e-271 9.99209727e-243 1.00000000e+000 1.70493933e-058]\n",
            " [2.23871690e-016 1.00000000e+000 2.72639036e-031 8.10255332e-034]\n",
            " [9.18609862e-001 2.72540695e-005 8.13622257e-002 6.57882281e-007]\n",
            " [1.31031281e-051 1.92316759e-046 1.00000000e+000 5.20575450e-018]\n",
            " [5.47200692e-085 1.00000000e+000 7.13306011e-122 3.38977712e-113]\n",
            " [3.25212031e-113 3.27281997e-099 1.00000000e+000 1.86759401e-035]\n",
            " [7.95597536e-123 4.67288298e-103 1.00000000e+000 1.39583915e-039]\n",
            " [7.71347473e-045 1.00000000e+000 3.21167387e-058 1.67660090e-042]\n",
            " [1.63890634e-058 1.00000000e+000 6.17950272e-055 1.89620048e-056]\n",
            " [4.98919312e-041 1.00000000e+000 1.10495884e-110 3.43239262e-094]\n",
            " [1.37241298e-018 1.00000000e+000 1.39080794e-030 9.58589128e-018]\n",
            " [1.00000000e+000 2.71207578e-058 4.99591979e-076 4.03970778e-064]\n",
            " [5.48923849e-037 4.20601923e-031 1.00000000e+000 6.04936161e-016]\n",
            " [2.90832936e-041 1.00000000e+000 5.98547453e-057 3.38915784e-049]\n",
            " [1.00000000e+000 4.08143117e-028 9.05099758e-026 1.81641363e-032]\n",
            " [1.00000000e+000 7.82715041e-082 9.20124639e-160 2.63546741e-167]\n",
            " [6.95702796e-059 1.00000000e+000 1.03758992e-069 4.91479039e-065]\n",
            " [3.38088917e-031 1.19850238e-040 1.00000000e+000 4.08261176e-019]\n",
            " [5.77846596e-035 5.99190332e-034 9.99999360e-001 6.40148890e-007]\n",
            " [8.86490341e-006 9.99991135e-001 8.90609022e-022 1.07823695e-013]\n",
            " [1.85811152e-047 7.56963874e-048 1.00000000e+000 3.13210499e-017]\n",
            " [3.72039168e-096 1.11158436e-083 3.59972618e-039 1.00000000e+000]\n",
            " [9.25170747e-038 1.81211653e-027 9.99999995e-001 4.71724113e-009]\n",
            " [1.00000000e+000 3.62049991e-045 1.01828388e-141 6.18284303e-131]\n",
            " [7.85256613e-030 1.51759567e-017 7.26348649e-014 1.00000000e+000]\n",
            " [1.00000000e+000 1.90128634e-027 1.71177671e-036 3.70630262e-036]\n",
            " [1.00000000e+000 1.77459067e-015 8.45423590e-022 1.89547825e-023]\n",
            " [8.16320701e-226 1.87514423e-183 5.19099115e-038 1.00000000e+000]\n",
            " [1.21820181e-144 5.53330972e-125 1.00000000e+000 6.37646008e-038]\n",
            " [4.91335166e-075 4.14425740e-058 1.00000000e+000 4.96336234e-026]\n",
            " [2.32143489e-086 1.00000000e+000 2.44210205e-104 1.00534731e-084]\n",
            " [2.16978281e-007 9.99999783e-001 2.15215925e-018 9.27594806e-013]\n",
            " [1.23596747e-029 1.00000000e+000 9.54356707e-056 1.26769565e-056]\n",
            " [1.39460247e-002 9.86053975e-001 8.55895200e-046 3.51869105e-043]\n",
            " [1.00000000e+000 3.78821372e-047 2.37018908e-062 1.63844942e-053]\n",
            " [5.61218143e-090 2.35274081e-086 2.48367206e-038 1.00000000e+000]\n",
            " [1.03229811e-005 1.14696186e-007 9.99960055e-001 2.95072697e-005]\n",
            " [1.92168578e-055 1.00000000e+000 1.11925781e-065 4.54027561e-073]\n",
            " [1.00000000e+000 1.34516398e-036 1.39636210e-036 2.27518964e-038]\n",
            " [1.52625623e-136 1.00000000e+000 1.92847897e-140 3.23989865e-137]\n",
            " [1.49439997e-085 1.00000000e+000 1.42996215e-119 4.07203246e-115]\n",
            " [9.99999959e-001 4.06437238e-008 2.15093067e-033 9.40101622e-021]\n",
            " [3.62581609e-079 1.00000000e+000 4.40006735e-111 1.66431699e-103]\n",
            " [9.68781111e-170 3.38875739e-113 1.00000000e+000 1.11457929e-059]\n",
            " [9.88844049e-001 2.04644857e-005 5.87918374e-013 1.11354869e-002]\n",
            " [1.00000000e+000 8.14235312e-036 4.00909763e-053 1.49855384e-048]\n",
            " [1.00000000e+000 1.06070650e-026 8.61402532e-042 1.54497414e-040]\n",
            " [1.00000000e+000 3.74383114e-014 9.47402543e-037 2.09360486e-031]\n",
            " [1.55887723e-039 1.00000000e+000 1.46905707e-060 1.90702048e-047]\n",
            " [1.26043780e-228 6.94579877e-188 1.00000000e+000 1.93617492e-066]\n",
            " [1.74851031e-199 1.10964891e-156 1.00000000e+000 1.95216934e-043]\n",
            " [7.46200902e-031 1.00000000e+000 5.83343523e-031 5.27838301e-029]\n",
            " [1.00000000e+000 2.41367172e-015 1.59786624e-019 1.32437990e-017]\n",
            " [1.47617768e-033 5.08929471e-025 1.00000000e+000 4.54064659e-013]\n",
            " [1.19629593e-012 1.68148579e-006 9.99998319e-001 3.82325436e-012]\n",
            " [1.92652595e-011 1.00000000e+000 6.57611381e-019 5.60845769e-018]\n",
            " [8.02905458e-052 1.43216029e-040 1.07363896e-037 1.00000000e+000]\n",
            " [9.97615661e-015 1.00000000e+000 8.82918237e-025 1.03426586e-012]\n",
            " [2.86247239e-106 4.73123260e-071 5.08621820e-025 1.00000000e+000]\n",
            " [1.00000000e+000 1.29322771e-013 9.13365531e-018 2.88170535e-015]\n",
            " [5.24951610e-077 8.88318853e-067 1.01755011e-017 1.00000000e+000]\n",
            " [8.77859745e-185 5.25013023e-155 1.00000000e+000 8.16887473e-023]\n",
            " [1.63126093e-001 8.36841005e-001 2.83872777e-005 4.51445282e-006]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 6.60745463e-146]\n",
            " [5.53593145e-036 1.00000000e+000 1.20868419e-036 2.53236572e-037]\n",
            " [0.00000000e+000 1.88808865e-211 1.00000000e+000 1.38717350e-063]\n",
            " [8.68181199e-042 9.90313512e-041 7.40528342e-033 1.00000000e+000]\n",
            " [2.48221447e-072 1.00000000e+000 8.31668749e-075 2.17379588e-070]\n",
            " [3.99117200e-068 1.91568187e-068 1.00000000e+000 3.53183825e-012]\n",
            " [1.96883345e-051 8.82425423e-046 1.00000000e+000 8.83869751e-024]\n",
            " [1.66462126e-241 1.33155125e-207 1.00000000e+000 5.86084347e-017]\n",
            " [1.73208614e-074 1.00000000e+000 5.84618800e-082 1.68716347e-086]\n",
            " [1.21849838e-017 4.44278402e-015 9.99835583e-001 1.64416717e-004]\n",
            " [9.99965605e-001 3.43947933e-005 4.57760878e-015 9.48154524e-016]\n",
            " [5.33331689e-056 2.58921523e-035 9.97618114e-001 2.38188619e-003]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 4.53889650e-144]\n",
            " [5.48221060e-055 1.29587899e-045 1.00000000e+000 8.27605980e-028]\n",
            " [1.00000000e+000 2.03257824e-013 9.99255569e-014 2.22686318e-016]\n",
            " [1.87464329e-017 2.02270035e-020 2.77009542e-018 1.00000000e+000]\n",
            " [1.00000000e+000 1.66523565e-023 8.61392931e-038 2.10040447e-027]\n",
            " [3.02732543e-080 1.01637839e-070 1.00000000e+000 3.35348164e-049]\n",
            " [2.52881927e-051 1.00000000e+000 4.63165799e-019 4.23466931e-014]\n",
            " [5.23643568e-042 4.41032174e-036 9.99999652e-001 3.48283633e-007]\n",
            " [1.00000000e+000 5.94114735e-060 1.11541178e-077 4.39185928e-065]\n",
            " [1.74395798e-062 1.57054057e-042 2.07345183e-021 1.00000000e+000]\n",
            " [1.67742961e-221 1.14385744e-143 1.00000000e+000 1.44533737e-060]\n",
            " [3.12658923e-067 1.00000000e+000 1.33798194e-086 3.96515949e-070]\n",
            " [1.50328950e-052 1.05516344e-053 9.99999872e-001 1.27700102e-007]\n",
            " [2.63713146e-020 2.60398232e-022 5.97215427e-019 1.00000000e+000]\n",
            " [4.04674902e-010 1.50709414e-008 1.43897189e-006 9.99998546e-001]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.27674322e-076]\n",
            " [1.37831471e-018 1.00000000e+000 1.44873705e-045 6.47876320e-052]\n",
            " [5.69998403e-071 1.68976734e-062 1.00000000e+000 1.74157352e-030]\n",
            " [1.00000000e+000 3.60732107e-041 1.70142360e-047 2.92578212e-056]\n",
            " [9.99997600e-001 2.40025902e-006 1.12466052e-014 6.17506597e-019]\n",
            " [1.79465661e-130 1.00000000e+000 2.47019397e-044 8.23146287e-052]\n",
            " [1.00000000e+000 9.71258826e-041 4.63701916e-058 4.29096753e-043]\n",
            " [3.05138113e-172 9.89283620e-137 1.00000000e+000 5.89732442e-050]\n",
            " [9.99930475e-001 6.95251275e-005 4.25960385e-054 8.23047468e-052]\n",
            " [1.00000000e+000 3.39740033e-010 2.72546841e-023 6.98662317e-020]\n",
            " [1.00000000e+000 2.15946021e-015 6.02013410e-023 1.04301987e-021]\n",
            " [7.77669599e-118 2.78603376e-091 1.00000000e+000 2.62258076e-015]\n",
            " [6.88297229e-035 1.00000000e+000 6.39713699e-065 1.53687579e-056]\n",
            " [1.00000000e+000 4.42946684e-083 2.65015253e-109 4.75958365e-119]\n",
            " [5.45928809e-088 2.78291957e-068 1.00000000e+000 2.74647443e-029]\n",
            " [7.71437331e-026 1.00000000e+000 1.32150044e-033 3.40997011e-028]\n",
            " [1.31459957e-015 1.98764691e-014 9.99993896e-001 6.10416148e-006]\n",
            " [1.28581281e-025 1.00000000e+000 1.07078381e-014 1.38564999e-015]\n",
            " [1.00000000e+000 2.87755981e-027 1.60758644e-034 1.97947077e-037]\n",
            " [2.28688702e-060 2.08884004e-057 1.00000000e+000 4.45761365e-039]\n",
            " [1.27472361e-073 1.00000000e+000 3.20064908e-031 1.47442476e-070]\n",
            " [1.00000000e+000 2.21128954e-020 1.34849986e-029 2.32924602e-027]\n",
            " [1.95633369e-074 1.00000000e+000 7.44826425e-089 1.83405169e-084]\n",
            " [2.86468086e-043 1.00000000e+000 2.10653863e-034 2.32223588e-031]\n",
            " [1.00000000e+000 2.19434106e-017 4.59991983e-013 7.33314838e-018]\n",
            " [3.51347145e-041 1.00000000e+000 2.56199954e-053 5.39498328e-034]\n",
            " [1.00000000e+000 4.68401725e-021 1.19040864e-031 5.17563831e-031]\n",
            " [1.35696670e-161 1.16803288e-108 1.00000000e+000 2.20116118e-023]\n",
            " [1.00000000e+000 1.53467096e-028 4.08780798e-042 5.17563646e-033]\n",
            " [5.02016184e-040 1.00000000e+000 9.90511250e-051 4.59430127e-044]\n",
            " [2.19749834e-123 1.00000000e+000 1.75904477e-165 2.17955530e-161]\n",
            " [1.02402354e-121 1.89696834e-100 1.00000000e+000 1.30282780e-047]\n",
            " [1.00000000e+000 1.20770705e-023 1.68507037e-046 3.20137567e-037]\n",
            " [7.63486311e-175 4.13872079e-141 1.00000000e+000 1.35781398e-034]\n",
            " [1.00000000e+000 3.87332168e-035 3.39143609e-052 1.12447328e-041]\n",
            " [5.94820040e-024 7.01169782e-016 1.54754849e-012 1.00000000e+000]\n",
            " [1.20812922e-016 1.00000000e+000 2.74153951e-034 3.35858083e-036]\n",
            " [9.87513274e-121 7.48152264e-095 1.00000000e+000 1.86273075e-056]\n",
            " [2.34242709e-084 5.89001165e-064 1.00000000e+000 1.15239099e-019]\n",
            " [8.92060068e-052 1.00000000e+000 2.48567688e-047 1.70670587e-046]\n",
            " [1.00000000e+000 1.53062863e-056 1.05836822e-075 7.54855554e-080]\n",
            " [1.00000000e+000 9.87926821e-046 2.13344688e-070 1.19632307e-061]\n",
            " [1.53272238e-017 5.93505855e-018 9.99999981e-001 1.94536616e-008]\n",
            " [1.00000000e+000 4.83261938e-010 1.01047861e-032 5.07663392e-025]\n",
            " [1.93187962e-016 1.00000000e+000 5.66301978e-029 7.99968819e-027]\n",
            " [1.12705841e-160 1.00000000e+000 1.64370778e-138 5.32746401e-146]\n",
            " [1.72025343e-035 2.54538165e-029 2.29767219e-013 1.00000000e+000]\n",
            " [3.33348639e-033 1.00000000e+000 1.58928638e-049 8.20235499e-036]\n",
            " [1.00000000e+000 9.88730102e-023 4.01542430e-034 1.25190563e-024]\n",
            " [1.00000000e+000 1.13182122e-020 6.17603386e-044 2.49621509e-036]\n",
            " [3.86164573e-033 3.30580910e-022 1.00000000e+000 6.87149028e-017]\n",
            " [1.00000000e+000 3.06452211e-020 2.61361545e-032 6.21637204e-034]\n",
            " [1.00000000e+000 2.27034322e-070 2.36693755e-185 7.50163962e-164]\n",
            " [1.64605855e-069 8.70113911e-057 9.99999999e-001 5.99535814e-010]\n",
            " [4.04176452e-049 1.00000000e+000 3.56088637e-041 1.69843013e-047]\n",
            " [9.14585865e-001 4.73831239e-005 8.53660492e-002 7.02959907e-007]\n",
            " [1.76558591e-079 6.34568227e-053 4.19389428e-022 1.00000000e+000]\n",
            " [6.75713287e-038 1.00000000e+000 1.16730722e-039 1.27849963e-038]\n",
            " [3.03128195e-043 9.99984165e-001 1.58346312e-005 2.30491550e-010]\n",
            " [1.00000000e+000 1.95748124e-033 1.14804496e-075 7.64877371e-074]\n",
            " [9.99999617e-001 3.37341190e-007 3.62759132e-009 4.20601078e-008]\n",
            " [9.57377623e-056 3.62712444e-040 1.26280585e-001 8.73719415e-001]\n",
            " [8.38718764e-079 1.00000000e+000 8.56221126e-071 6.87617155e-076]\n",
            " [6.19833323e-004 9.99380167e-001 3.55993811e-042 4.00280981e-040]\n",
            " [2.39247984e-015 1.00000000e+000 4.40691486e-013 9.58141101e-017]\n",
            " [0.00000000e+000 5.65348883e-289 1.00000000e+000 2.39329436e-072]\n",
            " [1.85204382e-047 5.34289809e-030 2.06842792e-005 9.99979316e-001]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.61660789e-097]\n",
            " [1.00000000e+000 3.63032568e-030 1.81280918e-047 1.37549119e-047]\n",
            " [1.84866125e-038 1.00000000e+000 3.17668068e-038 7.11123567e-041]\n",
            " [2.19906880e-081 3.55157636e-057 1.62861498e-002 9.83713850e-001]\n",
            " [1.00000000e+000 8.74034946e-012 1.93315953e-031 2.82207961e-031]\n",
            " [3.05026138e-120 3.58890985e-098 1.00000000e+000 7.58778113e-022]\n",
            " [3.33697619e-081 4.73609613e-076 9.99999993e-001 7.20470161e-009]\n",
            " [3.20846230e-320 4.35893384e-236 1.00000000e+000 4.57151871e-106]\n",
            " [1.02650523e-051 1.00000000e+000 1.04524761e-064 3.66786522e-055]\n",
            " [3.95816811e-111 5.99820148e-095 9.71564557e-001 2.84354435e-002]\n",
            " [2.19729685e-028 1.00000000e+000 1.94214525e-066 7.87784322e-061]\n",
            " [2.59100295e-029 3.25615714e-022 1.00000000e+000 3.86360463e-015]\n",
            " [1.00000000e+000 1.36179795e-050 7.21223951e-074 1.30176223e-065]\n",
            " [1.00000000e+000 1.88032318e-014 6.22007645e-071 2.15933846e-076]\n",
            " [6.23601570e-091 1.00000000e+000 8.54668859e-100 3.37136892e-093]\n",
            " [1.80342236e-072 5.46284946e-050 1.00000000e+000 2.04220166e-039]\n",
            " [8.48591540e-029 2.36464138e-031 6.48090530e-020 1.00000000e+000]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [8.51815170e-030 2.62080850e-022 1.00000000e+000 3.93968435e-011]\n",
            " [1.00000000e+000 2.53125404e-066 3.90678399e-081 7.70235926e-083]\n",
            " [1.00000000e+000 1.66023579e-041 1.26231894e-062 1.19626319e-047]\n",
            " [1.00000000e+000 3.04078314e-027 1.32878997e-040 1.67471716e-044]\n",
            " [6.57245537e-057 1.61577822e-047 1.70186151e-013 1.00000000e+000]\n",
            " [1.15922258e-176 7.23552541e-152 1.00000000e+000 1.81166778e-044]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 4.35259083e-171]\n",
            " [1.89854896e-032 1.53874434e-013 2.91789560e-033 1.00000000e+000]\n",
            " [4.23824589e-040 1.00000000e+000 2.98027483e-036 2.88199612e-040]\n",
            " [5.03721489e-043 1.00000000e+000 3.48850453e-056 9.42432621e-053]\n",
            " [2.53813405e-054 1.00000000e+000 1.74460752e-049 1.24503388e-041]\n",
            " [6.18100702e-060 9.89763806e-052 1.00000000e+000 6.55249029e-020]\n",
            " [1.00000000e+000 1.57614958e-026 7.90871108e-036 1.89538907e-033]\n",
            " [5.45651488e-180 1.38623428e-135 1.00000000e+000 7.02599216e-047]\n",
            " [1.00000000e+000 1.26803339e-079 8.73573948e-113 1.06024153e-109]\n",
            " [1.31581770e-060 1.00000000e+000 5.37737405e-079 2.60825091e-074]\n",
            " [2.63932015e-103 8.94934303e-086 1.00000000e+000 3.29514968e-018]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.46414941e-156]\n",
            " [4.24986653e-018 2.28458763e-024 1.00000000e+000 5.68024627e-012]\n",
            " [1.00000000e+000 1.51742234e-038 2.35027169e-061 9.46109698e-056]\n",
            " [4.27716076e-027 1.00000000e+000 8.36002601e-042 7.76610709e-040]\n",
            " [1.00000000e+000 1.14238256e-052 1.68061403e-063 4.78069836e-069]\n",
            " [9.77411296e-001 1.72239137e-004 2.24164528e-002 1.23283485e-008]\n",
            " [4.49071073e-175 1.08792260e-143 1.36015539e-048 1.00000000e+000]\n",
            " [9.08596001e-001 5.31891604e-012 9.14039990e-002 4.96064876e-011]\n",
            " [2.77749317e-064 1.33803179e-056 1.00000000e+000 1.48860832e-023]\n",
            " [9.44964806e-026 3.30434240e-032 4.97318197e-040 1.00000000e+000]\n",
            " [5.04374298e-026 4.56899167e-020 9.97043878e-001 2.95612236e-003]\n",
            " [1.00000000e+000 5.78440905e-052 1.91631059e-088 2.50729025e-082]\n",
            " [2.39104084e-118 1.00000000e+000 2.89480921e-104 5.11360890e-108]\n",
            " [1.49549607e-047 1.00000000e+000 1.15758858e-051 8.90280125e-059]\n",
            " [1.00000000e+000 1.87174279e-019 8.63600391e-028 8.35610412e-019]\n",
            " [9.99994275e-001 3.29338394e-010 6.42664354e-011 5.72487729e-006]\n",
            " [5.39584738e-080 4.18531565e-069 1.00000000e+000 1.33190534e-017]\n",
            " [4.75285792e-032 5.93734927e-014 9.99999997e-001 2.84518372e-009]\n",
            " [9.99852212e-001 1.47787569e-004 2.34516529e-012 1.85084955e-016]\n",
            " [8.53331268e-050 1.00000000e+000 9.64751843e-047 3.95885946e-036]\n",
            " [2.19432264e-142 2.03517173e-122 1.00000000e+000 1.80286916e-045]\n",
            " [1.00000000e+000 1.11235103e-022 7.07574822e-037 7.37232817e-027]\n",
            " [2.18224983e-028 1.36623705e-026 1.00000000e+000 1.44116351e-012]\n",
            " [1.47806076e-069 5.43954322e-063 1.90619180e-047 1.00000000e+000]\n",
            " [4.79270990e-106 1.00000000e+000 1.73486739e-139 2.40443787e-137]\n",
            " [1.05167844e-137 1.47865833e-111 1.00000000e+000 3.30438658e-045]\n",
            " [2.70114000e-177 9.06322100e-143 1.00000000e+000 8.10435528e-048]\n",
            " [1.41242862e-051 2.40700839e-042 2.22601514e-030 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 4.60240628e-157]\n",
            " [3.48349377e-020 9.99999423e-001 5.77301901e-007 2.06976579e-021]\n",
            " [3.06103853e-018 1.00000000e+000 1.22614199e-062 1.79295257e-053]\n",
            " [3.42011436e-088 1.00000000e+000 3.98931611e-093 1.69975505e-088]\n",
            " [3.56275567e-024 1.76163676e-024 9.99998511e-001 1.48868961e-006]\n",
            " [2.23224798e-051 8.40565549e-047 1.00000000e+000 2.65987057e-022]\n",
            " [1.07177962e-008 1.51862969e-008 8.11009058e-009 9.99999966e-001]\n",
            " [1.00000000e+000 6.47837207e-058 7.50421768e-137 3.66018114e-144]\n",
            " [3.25093551e-160 1.34182899e-135 1.00000000e+000 2.29989835e-032]\n",
            " [1.00000000e+000 2.08563168e-016 1.61737481e-076 7.30343892e-088]\n",
            " [2.10809294e-166 1.08493821e-125 1.00000000e+000 3.04262837e-037]\n",
            " [1.00000000e+000 3.82116371e-032 9.75602622e-038 7.00456867e-028]\n",
            " [1.00000000e+000 1.49876536e-019 1.39699425e-028 2.16098216e-025]\n",
            " [2.81601935e-154 9.30408273e-116 1.00000000e+000 2.65499376e-041]\n",
            " [9.99999147e-001 3.72799628e-007 9.46843290e-009 4.70296281e-007]\n",
            " [1.00000000e+000 4.23724454e-024 1.16201886e-036 7.49789886e-025]\n",
            " [5.96846504e-029 8.98559649e-029 1.45887049e-008 9.99999985e-001]\n",
            " [2.79021173e-002 9.70226009e-001 2.94295388e-007 1.87157982e-003]\n",
            " [1.01081641e-076 6.33229947e-064 1.00000000e+000 1.06330600e-036]\n",
            " [2.72294636e-267 1.46204670e-250 1.00000000e+000 1.80922494e-057]\n",
            " [9.99997246e-001 2.32049079e-006 4.33734503e-007 2.60865228e-012]\n",
            " [3.74927989e-044 1.00000000e+000 4.28834494e-031 6.11548970e-038]\n",
            " [1.82307528e-183 8.16695562e-158 1.00000000e+000 5.00297669e-025]\n",
            " [2.17772014e-015 1.00000000e+000 2.54793338e-025 1.09886531e-017]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [7.93550402e-010 9.96444907e-009 9.99962543e-001 3.74465333e-005]\n",
            " [2.17178513e-052 1.00000000e+000 2.79983422e-239 8.71896114e-228]\n",
            " [1.00000000e+000 1.05734819e-013 4.71702648e-015 1.39589139e-010]\n",
            " [4.87812829e-045 2.31308974e-031 2.16639457e-021 1.00000000e+000]\n",
            " [2.61111221e-046 1.00000000e+000 5.03209882e-058 8.21940575e-043]\n",
            " [4.21317263e-057 1.86250442e-057 1.00000000e+000 1.32796374e-028]\n",
            " [1.12144388e-039 5.53691109e-029 5.19897578e-030 1.00000000e+000]\n",
            " [8.78999068e-018 1.00000000e+000 3.78166334e-017 5.22934708e-016]\n",
            " [4.26082696e-062 1.00000000e+000 7.17350120e-076 1.74863765e-082]\n",
            " [9.99999999e-001 9.31138207e-010 1.88836027e-030 8.59305869e-025]\n",
            " [1.57763395e-024 1.36962281e-030 1.36739491e-022 1.00000000e+000]\n",
            " [4.03189685e-076 7.28823807e-071 1.00000000e+000 1.12318114e-043]\n",
            " [1.00000000e+000 1.06564306e-043 8.69824925e-291 2.08752955e-253]\n",
            " [8.92950005e-082 1.00000000e+000 1.10955025e-091 5.01070319e-086]\n",
            " [2.24275614e-094 1.00000000e+000 1.16227479e-126 3.72261987e-127]\n",
            " [2.46726788e-061 4.94239386e-047 1.00000000e+000 1.61786722e-022]\n",
            " [3.17573784e-040 1.94837585e-035 1.00000000e+000 2.51860785e-022]\n",
            " [4.20197859e-067 1.00000000e+000 9.70368990e-063 1.83547098e-061]\n",
            " [2.65802794e-010 1.00000000e+000 4.65123370e-014 2.58046804e-013]\n",
            " [1.37580823e-081 1.75001269e-068 1.00000000e+000 3.03274242e-053]\n",
            " [1.00000000e+000 9.05879910e-052 4.93737724e-083 5.02665201e-075]\n",
            " [1.52307435e-124 5.33532982e-094 1.00000000e+000 3.65010050e-023]\n",
            " [1.93044388e-120 7.96436543e-086 1.00000000e+000 6.12941958e-038]\n",
            " [1.25771383e-023 1.52715742e-021 9.99999992e-001 8.15925292e-009]\n",
            " [3.31000248e-011 2.96075308e-010 9.99999327e-001 6.73131151e-007]\n",
            " [0.00000000e+000 1.85740546e-294 9.99572747e-001 4.27252700e-004]\n",
            " [1.00000000e+000 4.71438778e-038 1.55015147e-065 1.22545187e-052]\n",
            " [5.95491103e-015 1.66765770e-012 9.99999940e-001 6.03070032e-008]\n",
            " [3.98161931e-093 3.70475197e-068 1.00000000e+000 5.94357897e-035]\n",
            " [1.45455130e-028 1.00000000e+000 5.56432160e-028 4.12520668e-026]\n",
            " [2.47470634e-086 5.38867974e-061 1.00000000e+000 8.35902486e-035]\n",
            " [1.34952792e-029 1.00000000e+000 3.80120147e-038 1.35072568e-035]\n",
            " [2.77228208e-090 4.72912224e-066 1.00000000e+000 2.70918230e-032]\n",
            " [1.00336634e-069 1.70854657e-056 9.02363834e-049 1.00000000e+000]\n",
            " [1.00000000e+000 9.69931270e-025 1.96380833e-041 4.36782757e-042]\n",
            " [8.21508077e-004 9.99178492e-001 1.57498025e-039 4.67717909e-036]\n",
            " [1.49426846e-121 4.35960687e-108 1.00000000e+000 7.44874314e-022]\n",
            " [1.00000000e+000 1.19704251e-054 2.40075862e-047 1.18276529e-054]\n",
            " [2.17661985e-037 1.00000000e+000 3.14518492e-046 1.76876557e-033]\n",
            " [1.71092309e-042 1.00000000e+000 1.40971011e-044 1.80817251e-038]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.67252024e-039 8.24801670e-039 1.00000000e+000 2.34764847e-022]\n",
            " [4.38225743e-038 1.00000000e+000 4.61733222e-108 1.36663638e-092]\n",
            " [1.00000000e+000 1.23457961e-012 1.90397076e-023 7.70262101e-027]\n",
            " [1.60753630e-040 1.00000000e+000 1.83266574e-049 1.08793216e-040]\n",
            " [1.06482957e-135 2.55919775e-104 1.00000000e+000 1.84555139e-032]\n",
            " [1.47356277e-028 1.00000000e+000 8.72085331e-013 8.94250756e-019]\n",
            " [1.59932766e-037 1.41708517e-042 1.86703873e-035 1.00000000e+000]\n",
            " [1.41741048e-025 1.00000000e+000 1.23909234e-040 3.25843094e-029]\n",
            " [2.19966038e-180 3.19158154e-150 1.00000000e+000 3.70889542e-052]\n",
            " [4.98281565e-298 1.53353017e-232 1.00000000e+000 1.52314640e-085]\n",
            " [5.27126704e-024 1.00000000e+000 6.99850828e-037 3.36425409e-032]\n",
            " [9.99999986e-001 1.36356054e-008 1.66593350e-013 3.66836336e-010]\n",
            " [1.78641207e-031 1.29624632e-006 6.41257150e-018 9.99998704e-001]\n",
            " [1.00000000e+000 1.11256084e-020 3.66818243e-036 1.18145969e-030]\n",
            " [1.00000000e+000 9.59911774e-096 7.79538819e-136 3.73418388e-138]\n",
            " [1.17533219e-040 1.00000000e+000 7.37172304e-062 7.36878989e-046]\n",
            " [7.80433877e-047 2.34181871e-039 1.00000000e+000 2.95728504e-029]\n",
            " [9.88139984e-084 1.53940470e-067 1.00000000e+000 2.72972388e-028]\n",
            " [3.26658908e-119 3.78825156e-091 1.00000000e+000 1.19588252e-056]\n",
            " [9.99999998e-001 1.60773392e-009 1.72323615e-018 3.94865868e-018]\n",
            " [1.33960161e-133 1.54469959e-077 1.03441635e-034 1.00000000e+000]\n",
            " [2.26134722e-084 1.00000000e+000 5.18286338e-122 6.30562184e-116]\n",
            " [1.49024135e-024 1.22162629e-025 1.14377193e-018 1.00000000e+000]\n",
            " [2.76886682e-020 1.35693898e-011 1.44933843e-029 1.00000000e+000]\n",
            " [1.00000000e+000 1.03698870e-044 7.93923440e-072 3.06864960e-052]\n",
            " [3.70031964e-015 1.95164757e-015 9.99999650e-001 3.50250581e-007]\n",
            " [4.11262050e-016 1.00000000e+000 1.34315594e-032 1.10688117e-019]\n",
            " [4.78009009e-063 1.36210020e-039 5.98935672e-031 1.00000000e+000]\n",
            " [6.10747700e-052 9.83627082e-042 1.82370879e-010 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.61732651e-141]\n",
            " [7.42223840e-001 2.57776149e-001 2.86667516e-012 1.05639427e-008]\n",
            " [1.00000000e+000 3.81231862e-272 0.00000000e+000 0.00000000e+000]\n",
            " [5.11651772e-015 2.76674234e-014 9.99999864e-001 1.36015605e-007]\n",
            " [1.00000000e+000 2.52745438e-013 2.73329468e-019 9.66666866e-017]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 6.45322032e-079]\n",
            " [1.57985756e-032 1.00000000e+000 7.89082145e-059 9.02489327e-058]\n",
            " [3.75464160e-306 1.82361114e-240 1.00000000e+000 8.17148490e-042]\n",
            " [1.63734313e-021 4.02799893e-018 9.99999991e-001 8.96089868e-009]\n",
            " [1.16287521e-061 4.13865153e-059 1.71591090e-042 1.00000000e+000]\n",
            " [8.81390343e-047 1.00000000e+000 3.25369982e-053 1.80355269e-061]\n",
            " [1.00000000e+000 1.15949651e-054 1.70855647e-066 2.25607079e-070]\n",
            " [1.00000000e+000 1.43368483e-015 4.79386120e-027 2.66837729e-019]\n",
            " [1.12815708e-040 7.39965412e-033 9.94052492e-001 5.94750764e-003]\n",
            " [9.95533370e-046 1.00000000e+000 8.71306188e-053 1.14847213e-050]\n",
            " [8.96309644e-001 3.10255664e-004 4.92537989e-006 1.03375175e-001]\n",
            " [3.34953753e-173 2.07030467e-117 1.00000000e+000 3.37811656e-014]\n",
            " [2.79806422e-067 2.91647877e-074 1.00000000e+000 1.44438012e-033]\n",
            " [2.26220370e-050 9.77532822e-045 2.17508708e-019 1.00000000e+000]\n",
            " [4.50888430e-028 1.00000000e+000 3.68211874e-022 1.10807696e-019]\n",
            " [1.06395543e-051 1.00000000e+000 8.24788542e-053 1.43861350e-054]\n",
            " [1.00000000e+000 8.60187751e-043 1.73248509e-049 1.75501087e-041]\n",
            " [5.92995833e-111 1.00000000e+000 5.77303835e-112 3.47641509e-104]\n",
            " [2.28000533e-071 3.44925224e-053 1.00000000e+000 7.56190975e-024]\n",
            " [1.89608629e-114 3.84935382e-109 6.20657958e-081 1.00000000e+000]\n",
            " [7.82120253e-129 1.00000000e+000 1.07757994e-155 8.93474576e-170]\n",
            " [3.12079769e-009 9.99999997e-001 1.61095926e-020 2.14742703e-014]\n",
            " [1.00000000e+000 1.36685608e-023 1.87946694e-033 1.03060312e-029]\n",
            " [1.00000000e+000 2.42874143e-043 2.25661554e-049 1.06075478e-053]\n",
            " [1.00000000e+000 2.73103103e-021 1.45857652e-032 1.51593392e-026]\n",
            " [9.99999999e-001 8.00897018e-010 2.75225020e-010 4.70783977e-011]\n",
            " [1.00000000e+000 1.04290388e-014 9.16303917e-038 6.48724205e-038]\n",
            " [2.10533521e-077 4.63542566e-061 1.00000000e+000 1.42019784e-025]\n",
            " [5.23435103e-108 4.64555413e-088 1.08275131e-001 8.91724869e-001]\n",
            " [0.00000000e+000 2.50061922e-307 1.00000000e+000 8.12936434e-048]\n",
            " [3.26521941e-066 1.13201690e-066 1.00000000e+000 2.64282948e-018]\n",
            " [9.98586016e-053 1.00000000e+000 2.47338324e-038 2.39819762e-036]\n",
            " [1.00000000e+000 2.91334774e-018 1.23225812e-019 2.99063531e-021]\n",
            " [9.04113909e-188 2.03346024e-140 1.00000000e+000 1.48988803e-047]\n",
            " [1.00000000e+000 3.81118781e-022 3.33567180e-030 1.90919524e-026]\n",
            " [1.61058269e-086 7.30806729e-081 1.00000000e+000 9.95344907e-025]\n",
            " [1.00000000e+000 4.38825679e-012 5.67001141e-013 2.84399917e-017]\n",
            " [1.54166984e-061 1.00000000e+000 2.34788116e-077 2.41342702e-077]\n",
            " [2.26143859e-021 9.28228761e-020 2.48657196e-035 1.00000000e+000]\n",
            " [2.53252273e-015 1.00000000e+000 1.26241894e-022 7.96351432e-017]\n",
            " [1.69359174e-026 8.55535328e-002 1.74996793e-009 9.14446465e-001]\n",
            " [4.03752797e-062 1.00000000e+000 1.56062984e-052 8.86901257e-050]\n",
            " [1.87929849e-075 1.00000000e+000 2.01515865e-164 1.90431695e-154]\n",
            " [9.99999999e-001 6.38639409e-010 3.73992142e-012 3.24512239e-010]\n",
            " [5.52804952e-063 1.00000000e+000 3.84318334e-088 2.12355875e-078]\n",
            " [1.00000000e+000 2.29189449e-086 5.83334069e-101 1.61659733e-114]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 9.44797847e-161]\n",
            " [4.40265650e-087 1.00000000e+000 2.06069477e-071 9.94739063e-084]\n",
            " [5.63099849e-087 9.98593797e-077 1.00000000e+000 2.60793374e-029]\n",
            " [1.03351619e-049 3.10100113e-045 1.00000000e+000 1.14428801e-010]\n",
            " [1.29389927e-038 1.00000000e+000 6.24976456e-054 1.98526668e-038]\n",
            " [4.87005846e-109 8.00334334e-092 1.00000000e+000 2.14937793e-030]\n",
            " [4.00343333e-133 8.12937632e-111 1.00000000e+000 4.83121556e-030]\n",
            " [3.25793880e-013 1.98787437e-011 9.99999972e-001 2.84339177e-008]\n",
            " [2.70078566e-064 1.00000000e+000 2.24641733e-074 5.30263398e-078]\n",
            " [2.76935848e-073 1.00000000e+000 5.95579557e-069 5.22790147e-043]\n",
            " [6.64368455e-188 1.59437690e-154 1.00000000e+000 1.29513608e-070]\n",
            " [1.29458062e-075 4.51772255e-060 1.00000000e+000 3.47825269e-029]\n",
            " [3.60108959e-037 1.00000000e+000 1.42098182e-037 1.39983498e-034]\n",
            " [1.20386427e-225 2.06823493e-180 1.00000000e+000 1.04120190e-074]\n",
            " [2.26810372e-038 2.51286048e-013 1.00000000e+000 1.60340894e-021]\n",
            " [4.65239494e-051 1.00000000e+000 8.43911535e-083 7.76219817e-078]\n",
            " [1.00000000e+000 7.01008754e-214 0.00000000e+000 0.00000000e+000]\n",
            " [1.00000000e+000 3.48367832e-036 1.04027216e-059 4.35389182e-048]\n",
            " [1.85957652e-042 6.44296734e-038 5.72626803e-002 9.42737320e-001]\n",
            " [2.96622205e-066 5.31774847e-059 1.91775418e-044 1.00000000e+000]\n",
            " [2.88617301e-019 1.00000000e+000 5.86261481e-037 8.85853120e-031]\n",
            " [1.00000000e+000 1.65122380e-023 6.78018549e-032 3.89010087e-027]\n",
            " [6.80242986e-052 1.00000000e+000 8.42179088e-052 1.76794014e-056]\n",
            " [1.44208632e-100 1.27905725e-081 3.62981227e-055 1.00000000e+000]\n",
            " [1.00000000e+000 3.00299002e-021 6.90382375e-032 1.20240909e-029]\n",
            " [6.91847908e-103 1.00000000e+000 1.71536505e-041 9.90812307e-044]\n",
            " [1.00000000e+000 9.09590839e-027 7.08437371e-030 9.49210620e-033]\n",
            " [2.72603344e-023 1.00000000e+000 2.90460140e-051 1.16486726e-031]\n",
            " [1.00000000e+000 5.16529944e-021 4.08180082e-014 1.92724077e-029]\n",
            " [1.15964468e-014 1.29349520e-012 9.99999922e-001 7.80096866e-008]\n",
            " [1.02477714e-077 1.51458077e-067 6.19747764e-037 1.00000000e+000]\n",
            " [6.07095035e-015 5.40852338e-015 9.74397504e-001 2.56024957e-002]\n",
            " [0.00000000e+000 3.06918014e-258 1.12974256e-006 9.99998870e-001]\n",
            " [3.27520518e-037 1.00000000e+000 2.88437005e-022 1.78479090e-023]\n",
            " [1.00000000e+000 7.11359722e-024 1.07843871e-049 6.51630303e-053]\n",
            " [2.13084940e-045 1.40757946e-043 3.94467243e-015 1.00000000e+000]\n",
            " [3.62911410e-006 9.99996371e-001 4.04200632e-015 6.82432656e-011]\n",
            " [1.38066763e-043 3.97598923e-051 9.99999977e-001 2.26595759e-008]\n",
            " [2.51853757e-046 1.00000000e+000 4.50197780e-020 2.84882848e-019]\n",
            " [1.38261232e-132 1.00000000e+000 5.90944267e-092 4.68910638e-107]\n",
            " [1.00000000e+000 5.41731929e-015 1.07603663e-027 4.67104610e-021]\n",
            " [6.97262834e-072 1.00000000e+000 5.42092375e-077 4.74877475e-073]\n",
            " [1.18463663e-011 1.00000000e+000 3.70579810e-121 8.14901175e-125]\n",
            " [1.00000000e+000 1.61000391e-061 1.09333673e-072 3.25842716e-072]\n",
            " [1.13591998e-080 2.78741935e-068 1.00000000e+000 1.20920002e-038]\n",
            " [1.00000000e+000 1.49822644e-027 6.02280473e-037 4.79025375e-040]\n",
            " [4.91294040e-265 1.34825050e-212 1.00000000e+000 1.69182016e-057]\n",
            " [1.00000000e+000 7.34377867e-024 1.30482863e-029 1.62263394e-031]\n",
            " [1.00000000e+000 1.00590810e-074 1.36978945e-140 2.18616072e-129]\n",
            " [1.20350708e-009 9.99999999e-001 1.55120385e-015 3.07685822e-016]\n",
            " [1.07078134e-022 9.99999994e-001 6.26803616e-009 4.67919182e-013]\n",
            " [0.00000000e+000 1.70431599e-289 1.00000000e+000 3.82566972e-131]\n",
            " [1.00000000e+000 9.05877651e-020 7.96507495e-040 5.18745994e-041]\n",
            " [1.00000000e+000 4.63544934e-043 1.85474918e-041 1.27152849e-043]\n",
            " [7.87884688e-022 1.00000000e+000 7.01843875e-040 1.74191510e-027]\n",
            " [1.00000000e+000 9.85938901e-017 7.50979991e-033 9.39797825e-025]\n",
            " [6.87463372e-085 1.00000000e+000 3.12189111e-075 4.37975303e-078]\n",
            " [9.88306773e-034 1.00000000e+000 1.23456127e-053 1.32556582e-052]\n",
            " [1.99485290e-268 2.17034130e-210 1.00000000e+000 4.56640203e-027]\n",
            " [6.42009345e-026 1.00000000e+000 3.22220608e-054 9.08045696e-052]\n",
            " [1.32004776e-034 1.00000000e+000 1.43242188e-081 1.73759896e-075]\n",
            " [1.70297101e-040 1.00000000e+000 1.68980944e-041 2.02182101e-031]\n",
            " [1.18698815e-024 7.22951309e-019 1.00000000e+000 5.86240701e-038]\n",
            " [5.07759934e-074 1.00000000e+000 2.26596081e-080 5.13834378e-073]\n",
            " [8.04701408e-007 9.99999195e-001 1.87272075e-028 8.81985793e-020]\n",
            " [5.79932452e-092 3.92630568e-061 1.00000000e+000 1.35349617e-027]\n",
            " [1.89339235e-051 9.39549573e-041 1.00000000e+000 1.40997139e-020]\n",
            " [4.91654868e-085 1.00000000e+000 2.19502692e-046 6.37480358e-043]\n",
            " [1.00000000e+000 5.02276816e-023 4.59468289e-040 2.79245764e-032]\n",
            " [4.70096481e-076 2.80149351e-065 1.08245171e-015 1.00000000e+000]\n",
            " [5.06033047e-033 2.81765689e-039 2.97977851e-008 9.99999970e-001]\n",
            " [9.99999370e-001 9.06288951e-009 6.78875750e-014 6.20474185e-007]\n",
            " [2.82981240e-052 3.37706784e-048 1.00000000e+000 1.29590563e-011]\n",
            " [3.74708905e-268 2.03318760e-238 1.00000000e+000 2.26366907e-094]\n",
            " [2.68587946e-002 9.73141205e-001 2.36033547e-036 9.01622939e-036]\n",
            " [4.03998890e-066 1.00000000e+000 8.28654042e-067 4.07880515e-076]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.00000000e+000 2.60779138e-028 5.21307307e-063 1.81042347e-063]\n",
            " [1.00000000e+000 8.85957502e-017 8.56662846e-011 8.51521207e-012]\n",
            " [1.00000000e+000 1.32770282e-032 1.34204475e-043 5.39395459e-056]\n",
            " [7.77265873e-049 3.29227578e-042 2.79810196e-025 1.00000000e+000]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [3.23968317e-008 3.87481289e-005 5.19159855e-003 9.94769621e-001]\n",
            " [3.38530079e-073 1.79196309e-066 3.21486618e-062 1.00000000e+000]\n",
            " [5.97788149e-054 1.25660939e-046 3.62956642e-063 1.00000000e+000]\n",
            " [5.69735305e-086 2.67220747e-078 1.00000000e+000 2.14064717e-011]\n",
            " [2.23873156e-129 2.14732909e-106 1.00000000e+000 1.08997495e-039]\n",
            " [1.21965757e-056 7.34535592e-044 1.00000000e+000 3.87892557e-037]\n",
            " [0.00000000e+000 1.80032005e-274 1.00000000e+000 3.77449037e-090]\n",
            " [9.98263029e-001 2.21063755e-021 1.73697059e-003 4.72266255e-026]\n",
            " [1.80710178e-051 7.60803937e-052 1.80272838e-031 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.09667513e-130]\n",
            " [1.20277010e-030 6.39481948e-031 1.00000000e+000 1.93293117e-012]\n",
            " [2.17766155e-020 9.81883160e-022 6.67878685e-021 1.00000000e+000]\n",
            " [1.00000000e+000 4.79154058e-025 4.21815269e-039 1.38403195e-032]\n",
            " [1.00000000e+000 3.92032162e-018 3.45109691e-019 4.22822132e-022]\n",
            " [6.18249090e-017 1.00000000e+000 1.09362142e-025 1.78853823e-025]\n",
            " [3.01613518e-095 1.04769976e-089 1.00000000e+000 7.60188758e-031]\n",
            " [9.99994367e-001 5.40513821e-006 2.27163927e-007 4.01652449e-010]\n",
            " [7.35918913e-096 1.73897310e-059 2.30610357e-009 9.99999998e-001]\n",
            " [1.22096836e-103 1.55994858e-085 1.00000000e+000 8.70181060e-016]\n",
            " [2.08217538e-066 3.15392412e-055 5.78679433e-020 1.00000000e+000]\n",
            " [1.80590327e-101 5.16151134e-081 1.00000000e+000 1.66065669e-053]\n",
            " [6.38043581e-085 1.00000000e+000 2.53512852e-066 2.14817303e-069]\n",
            " [1.00000000e+000 1.03141147e-028 9.12920251e-043 1.88560535e-039]\n",
            " [9.99999999e-001 9.15948548e-010 8.54909910e-021 4.76373325e-016]\n",
            " [1.00000000e+000 3.74096773e-025 6.68629454e-039 1.89246817e-025]\n",
            " [1.00000000e+000 6.39169149e-039 9.84639214e-038 7.68336718e-045]\n",
            " [4.08491958e-067 1.36152768e-042 2.61183193e-050 1.00000000e+000]\n",
            " [8.84359426e-054 1.00000000e+000 9.92469462e-040 2.59534445e-038]\n",
            " [1.00000000e+000 1.55414041e-031 2.12593139e-049 5.48130966e-041]\n",
            " [6.34152606e-046 1.96537919e-041 2.04348145e-011 1.00000000e+000]\n",
            " [2.38076831e-096 2.41859215e-092 9.99999998e-001 1.86407267e-009]\n",
            " [4.77157697e-051 2.16459103e-047 1.00000000e+000 2.11228952e-016]\n",
            " [1.38502809e-008 7.84448388e-012 4.26258458e-006 9.99995724e-001]\n",
            " [1.00000000e+000 3.20864086e-014 9.68386631e-032 2.27898980e-022]\n",
            " [7.41152642e-030 1.00000000e+000 1.40926277e-059 1.41630105e-057]\n",
            " [0.00000000e+000 2.26612744e-265 1.00000000e+000 1.77410223e-078]\n",
            " [1.00000000e+000 1.30908853e-049 3.25647392e-059 1.94435842e-055]\n",
            " [5.78633375e-039 1.69163801e-038 1.00000000e+000 2.97425222e-020]\n",
            " [1.00000000e+000 2.43203900e-010 6.29481126e-022 1.72940682e-012]\n",
            " [1.19765352e-007 9.99999880e-001 1.17094394e-028 5.61149101e-024]\n",
            " [3.93389209e-088 3.87449521e-058 1.00000000e+000 4.09653067e-018]\n",
            " [1.00000000e+000 6.84453889e-015 1.86849604e-015 5.94593948e-025]\n",
            " [9.99898499e-001 1.01349158e-004 2.37046121e-012 1.51439583e-007]\n",
            " [1.00000000e+000 1.15706057e-026 3.80542216e-032 2.26085712e-031]\n",
            " [1.35370832e-258 1.24835241e-231 1.00000000e+000 1.03210173e-096]\n",
            " [1.73949235e-038 1.07779378e-034 9.41645937e-022 1.00000000e+000]\n",
            " [1.39415812e-086 5.33140926e-076 1.00000000e+000 2.48837356e-034]\n",
            " [9.99999999e-001 7.87732593e-010 1.13101328e-018 1.46527398e-011]\n",
            " [2.35641974e-058 1.00000000e+000 1.42638194e-067 8.56631060e-053]\n",
            " [1.00000000e+000 1.22520673e-023 1.03542563e-031 2.82632927e-035]\n",
            " [1.00000000e+000 2.19721817e-030 4.67367561e-061 1.97965370e-062]\n",
            " [6.48660172e-183 2.68465603e-159 1.00000000e+000 4.77463679e-045]\n",
            " [1.00000000e+000 2.63978419e-024 1.40229391e-050 1.71158631e-036]\n",
            " [1.33834509e-160 5.18872391e-141 1.00000000e+000 7.98744543e-011]\n",
            " [1.02828011e-275 2.05552639e-212 1.00384156e-023 1.00000000e+000]\n",
            " [1.00000000e+000 6.64394869e-014 8.64107946e-018 3.57556783e-013]\n",
            " [4.50051023e-027 1.00000000e+000 1.33602533e-034 7.89829577e-033]\n",
            " [2.72682271e-042 2.51233141e-040 1.00000000e+000 1.90076772e-025]\n",
            " [1.26739956e-026 1.00000000e+000 2.01220007e-032 1.23048147e-035]\n",
            " [1.74521822e-231 1.08399602e-182 1.63693141e-049 1.00000000e+000]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [9.62815942e-047 1.00000000e+000 8.29679360e-058 4.05127333e-046]\n",
            " [1.00000000e+000 4.40036288e-144 9.88937636e-240 2.44008256e-218]\n",
            " [4.09731127e-042 1.00000000e+000 1.27961055e-057 7.49128495e-048]\n",
            " [9.51985788e-078 1.00000000e+000 6.74422845e-093 3.73489917e-091]\n",
            " [1.00000000e+000 1.84366381e-024 3.19390151e-049 4.65910385e-027]\n",
            " [1.15526393e-056 1.00000000e+000 2.33761022e-055 4.18560084e-052]\n",
            " [1.16060314e-044 9.98004792e-039 1.00000000e+000 4.06982031e-026]\n",
            " [4.07576110e-038 7.46310117e-038 1.00000000e+000 5.47639331e-013]\n",
            " [1.00000000e+000 1.39218720e-015 5.87814370e-018 3.17377154e-018]\n",
            " [4.81132502e-049 1.00000000e+000 3.11101175e-048 1.54988540e-044]\n",
            " [3.98255328e-045 1.00000000e+000 1.81156808e-025 1.46414370e-037]\n",
            " [1.00000000e+000 3.20719629e-027 9.38909045e-030 7.95906710e-029]\n",
            " [1.00000000e+000 3.49078361e-026 7.55179349e-046 8.40357630e-035]\n",
            " [3.86602882e-040 2.95509634e-039 1.00000000e+000 1.02627287e-012]\n",
            " [1.19272437e-135 3.42399711e-115 1.00000000e+000 2.31642049e-057]\n",
            " [9.99999996e-001 4.15159721e-009 1.64570946e-027 2.54296315e-019]\n",
            " [1.00000000e+000 5.41092830e-019 1.66460885e-037 5.14810383e-035]\n",
            " [1.73640052e-075 1.00000000e+000 2.91778362e-062 4.96578209e-071]\n",
            " [4.42797220e-087 1.00000000e+000 1.41551663e-061 2.23970902e-062]\n",
            " [3.88412863e-057 1.00000000e+000 2.20707940e-085 3.53540527e-083]\n",
            " [5.40654350e-097 3.51313867e-078 7.35966394e-018 1.00000000e+000]\n",
            " [1.00000000e+000 3.82859547e-021 3.60001821e-068 2.79546972e-063]\n",
            " [5.83989063e-091 4.31649777e-086 1.00000000e+000 4.19435536e-047]\n",
            " [9.63133135e-042 1.00000000e+000 1.43195340e-041 9.94445207e-038]\n",
            " [0.00000000e+000 1.48931404e-213 1.00000000e+000 1.42243466e-025]\n",
            " [1.00000000e+000 9.06226957e-021 4.25815471e-029 1.97557947e-029]\n",
            " [6.42620272e-140 2.25941703e-139 1.00000000e+000 2.21836958e-055]\n",
            " [5.29365828e-015 9.99882103e-001 1.17896978e-004 3.77325216e-036]\n",
            " [1.00000000e+000 1.70134054e-026 2.72200162e-031 8.37710955e-032]\n",
            " [6.51481234e-053 1.00000000e+000 3.34552325e-058 1.11976113e-053]\n",
            " [9.60653684e-192 2.96632772e-178 1.00000000e+000 4.01665413e-054]\n",
            " [2.76184610e-054 1.00000000e+000 1.28670347e-064 2.76442313e-066]\n",
            " [2.72845070e-172 3.22278516e-137 1.00000000e+000 8.04407386e-041]\n",
            " [2.15225674e-036 2.04443547e-033 2.50579994e-002 9.74942001e-001]\n",
            " [2.31569673e-027 3.30074451e-003 1.81903310e-016 9.96699255e-001]\n",
            " [9.99999997e-001 2.86848098e-009 9.88063276e-027 1.46063959e-024]\n",
            " [1.00000000e+000 4.30647220e-039 2.52260294e-237 8.41673429e-179]\n",
            " [4.86334762e-116 7.02984856e-091 1.00000000e+000 1.54048299e-029]\n",
            " [4.06960556e-147 1.86165244e-130 1.00000000e+000 1.73250705e-029]\n",
            " [1.17037164e-027 1.44302938e-022 9.99999992e-001 8.44566578e-009]\n",
            " [1.00000000e+000 1.26948596e-076 0.00000000e+000 0.00000000e+000]\n",
            " [1.07845326e-055 9.46206083e-040 1.41819371e-009 9.99999999e-001]\n",
            " [2.20701655e-080 2.09996771e-062 1.66096293e-012 1.00000000e+000]\n",
            " [3.18717675e-065 1.00000000e+000 5.60028654e-052 5.43398232e-050]\n",
            " [0.00000000e+000 3.25173802e-294 1.00000000e+000 9.84255909e-011]\n",
            " [2.89079000e-223 2.20266469e-179 1.00000000e+000 1.32180956e-066]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.16326322e-066]\n",
            " [2.36979091e-081 1.00000000e+000 2.99988768e-047 2.71574248e-046]\n",
            " [6.04555773e-025 1.67135660e-023 1.00000000e+000 1.15244473e-013]\n",
            " [1.00000000e+000 2.12942489e-022 4.07506909e-030 3.81492799e-026]\n",
            " [2.93286605e-052 4.02850501e-051 1.00000000e+000 4.69337082e-019]\n",
            " [2.48546025e-013 2.71226605e-025 1.98666763e-003 9.98013332e-001]\n",
            " [1.00000000e+000 1.29755449e-027 1.22131029e-037 4.15220197e-028]\n",
            " [3.96338304e-017 9.10824343e-001 8.91756086e-002 4.87926999e-008]\n",
            " [2.11103911e-023 1.00000000e+000 4.66104301e-022 2.77165468e-022]\n",
            " [1.30909471e-043 2.06170628e-040 1.00000000e+000 7.46077942e-011]\n",
            " [3.79756869e-161 1.62547364e-154 3.03389708e-071 1.00000000e+000]\n",
            " [3.86785078e-062 9.07984049e-056 1.00000000e+000 1.65045980e-039]\n",
            " [5.45153464e-081 6.08604460e-075 1.00000000e+000 2.12483255e-029]\n",
            " [8.84788513e-008 9.99999912e-001 4.39430667e-023 6.64820840e-017]\n",
            " [4.21868725e-087 5.75571702e-061 1.00000000e+000 1.27954720e-027]\n",
            " [3.85414480e-054 1.00000000e+000 1.17162023e-040 3.82158078e-044]\n",
            " [1.23619330e-050 9.89530581e-057 1.00000000e+000 3.92265161e-035]\n",
            " [6.94954640e-068 1.00000000e+000 3.62687743e-083 1.07187096e-065]\n",
            " [1.00000000e+000 4.28660936e-014 6.07516743e-028 3.75475696e-031]\n",
            " [3.44784784e-048 1.00000000e+000 2.68962321e-058 1.50958534e-051]\n",
            " [9.99999991e-001 8.75789008e-009 6.15906393e-026 2.94614015e-019]\n",
            " [8.40527261e-018 1.00000000e+000 6.02243293e-028 5.73087956e-024]\n",
            " [1.00000000e+000 3.92816136e-014 1.06458851e-027 1.22388782e-027]\n",
            " [1.22622293e-057 7.02845120e-055 1.00000000e+000 9.32047997e-028]\n",
            " [3.98661763e-163 1.00000000e+000 7.01527210e-168 5.37868395e-170]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.92057867e-022 1.00000000e+000 7.32243274e-029 1.09643442e-030]\n",
            " [1.00000000e+000 2.74871467e-016 4.42306652e-022 4.80641400e-013]\n",
            " [1.00000000e+000 7.22633365e-011 2.12757624e-031 1.47641271e-023]\n",
            " [1.24925695e-050 1.55034640e-047 1.00000000e+000 2.98385399e-027]\n",
            " [1.00000000e+000 1.11623043e-026 1.91624446e-042 2.13473383e-032]\n",
            " [2.74095260e-079 1.00000000e+000 3.20892716e-114 1.06041983e-106]\n",
            " [9.99999986e-001 1.39999842e-008 2.63846790e-019 1.48760248e-012]\n",
            " [1.00000000e+000 8.68006339e-029 5.65193543e-036 1.57290991e-031]\n",
            " [2.42601378e-155 1.00000000e+000 7.36884795e-172 7.79624615e-157]\n",
            " [9.74555993e-042 1.00000000e+000 4.91497895e-019 1.89585142e-015]\n",
            " [1.38165248e-022 1.00000000e+000 7.54216377e-026 3.80837274e-017]\n",
            " [2.10418887e-272 1.90449248e-236 1.00000000e+000 1.14013881e-054]\n",
            " [9.99901567e-001 9.28147786e-005 5.50583025e-006 1.12536539e-007]\n",
            " [1.90618012e-028 1.04129776e-030 5.62843153e-019 1.00000000e+000]\n",
            " [1.18432964e-070 1.00000000e+000 1.03024560e-099 5.66142087e-101]\n",
            " [1.00000000e+000 2.28166431e-013 1.63254877e-092 3.40084220e-071]\n",
            " [3.95706380e-077 6.01030202e-064 1.00000000e+000 7.58026236e-012]\n",
            " [1.90035707e-031 1.14968927e-023 1.37194097e-020 1.00000000e+000]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.73611758e-185]\n",
            " [5.89293249e-066 1.00000000e+000 2.99072104e-094 1.19061842e-082]\n",
            " [3.82036811e-007 7.92991464e-014 5.73959744e-008 9.99999561e-001]\n",
            " [5.99341710e-050 7.27267094e-012 1.00000000e+000 1.10817517e-011]\n",
            " [3.22582755e-173 8.27203082e-142 1.00000000e+000 5.92620961e-057]\n",
            " [4.07168894e-060 1.00000000e+000 4.48064693e-019 9.00062394e-046]\n",
            " [3.26747275e-005 2.33696090e-003 8.35863581e-002 9.14044006e-001]\n",
            " [1.02568614e-047 1.00000000e+000 2.70113856e-067 1.58031795e-065]\n",
            " [5.50441928e-007 9.99999447e-001 7.45032118e-010 1.69909236e-009]\n",
            " [1.78981379e-163 1.00000000e+000 6.50401452e-140 8.63520581e-136]\n",
            " [3.36132768e-122 7.80069320e-092 3.16331631e-017 1.00000000e+000]\n",
            " [1.44457956e-154 4.20629052e-116 1.00000000e+000 1.01696921e-036]\n",
            " [9.99999971e-001 2.93620413e-008 2.19891623e-013 6.84576446e-016]\n",
            " [4.66711932e-028 1.00000000e+000 9.61399785e-033 1.61260109e-025]\n",
            " [2.14187148e-023 1.00000000e+000 1.82186415e-013 1.87745917e-016]\n",
            " [2.01407611e-191 4.38724318e-161 1.00000000e+000 2.03197014e-071]\n",
            " [1.14028832e-005 9.86708213e-001 7.18775302e-003 6.09263076e-003]\n",
            " [2.38066777e-081 2.26993590e-072 1.00000000e+000 2.02134543e-021]\n",
            " [3.41839740e-015 2.34768747e-017 9.98205833e-001 1.79416683e-003]\n",
            " [1.00000000e+000 1.99149812e-020 8.26186436e-030 2.18936712e-023]\n",
            " [3.74362696e-040 1.00000000e+000 1.26149948e-050 4.46005691e-038]\n",
            " [1.27053666e-173 4.75430316e-095 1.04782628e-024 1.00000000e+000]\n",
            " [9.75642303e-013 1.00000000e+000 2.60468359e-023 5.69181834e-020]\n",
            " [8.05314796e-064 5.38453373e-051 1.00000000e+000 1.26140147e-038]\n",
            " [1.26576129e-071 1.22856021e-059 3.89474013e-043 1.00000000e+000]\n",
            " [4.07821415e-055 1.00000000e+000 1.05429039e-078 1.20498951e-072]\n",
            " [1.00000000e+000 8.30152252e-044 1.78245801e-074 1.65397835e-063]\n",
            " [1.92210850e-057 9.99999986e-001 1.35393602e-008 3.14906990e-022]\n",
            " [2.55093552e-042 1.00000000e+000 1.83545304e-047 3.36235387e-048]\n",
            " [1.00000000e+000 6.11730823e-019 7.70614205e-026 1.48126615e-030]\n",
            " [1.00000000e+000 3.43650694e-044 1.47501732e-064 9.53607019e-064]\n",
            " [2.41984201e-028 3.88471493e-028 1.30206376e-018 1.00000000e+000]\n",
            " [1.12323749e-060 1.00000000e+000 4.83775866e-058 9.66427522e-051]\n",
            " [1.82172014e-037 1.00000000e+000 1.85590945e-034 2.23406662e-033]\n",
            " [5.67206205e-052 5.66684838e-043 4.33909963e-012 1.00000000e+000]\n",
            " [1.94736517e-050 7.71182141e-039 1.00000000e+000 3.62653442e-027]\n",
            " [6.52344240e-021 1.00000000e+000 4.51661743e-019 6.37519377e-016]\n",
            " [1.70389854e-038 1.00000000e+000 2.01260360e-110 1.87555739e-093]\n",
            " [1.00000000e+000 9.74882102e-015 7.87419812e-030 9.20048458e-022]\n",
            " [8.89502164e-068 1.26145863e-054 1.00000000e+000 3.00897603e-017]\n",
            " [1.26573663e-244 3.22178006e-211 1.00000000e+000 8.20065018e-048]\n",
            " [7.91663333e-016 1.20897593e-004 5.19799856e-013 9.99879102e-001]\n",
            " [1.00000000e+000 1.18260043e-018 1.20328905e-023 1.86524372e-023]\n",
            " [1.00000000e+000 3.99278389e-016 9.54833127e-019 1.19847868e-014]\n",
            " [1.71643883e-017 1.00000000e+000 1.83512140e-021 6.06411201e-011]\n",
            " [1.00000000e+000 1.59717346e-020 2.42741426e-027 6.42164513e-032]\n",
            " [5.60460735e-036 1.00000000e+000 4.01688978e-042 1.90247309e-047]\n",
            " [8.39606514e-115 1.00000000e+000 2.01277872e-053 1.74802738e-049]\n",
            " [4.03346201e-021 3.53178496e-024 9.99999971e-001 2.85786169e-008]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 1.00851654e-026]\n",
            " [1.40901974e-052 1.30513382e-049 1.00000000e+000 2.12471173e-017]\n",
            " [1.00000000e+000 2.40409055e-020 4.64073497e-042 4.73248879e-035]\n",
            " [7.19913843e-212 7.64085490e-196 1.00000000e+000 1.83129247e-062]\n",
            " [2.97976176e-185 1.00000000e+000 5.24288342e-143 2.79373744e-165]\n",
            " [1.83176524e-020 1.00000000e+000 1.01043664e-033 5.20910670e-029]\n",
            " [1.00000000e+000 3.68340388e-018 3.33451983e-037 5.23594499e-043]\n",
            " [8.48380528e-049 1.00000000e+000 2.05019393e-056 2.93005119e-049]\n",
            " [2.29152873e-035 3.65082752e-029 1.32359383e-009 9.99999999e-001]\n",
            " [1.00000000e+000 6.31876372e-043 1.38896905e-065 4.04210242e-058]\n",
            " [6.04961233e-014 5.18240368e-016 1.77660747e-021 1.00000000e+000]\n",
            " [6.96939460e-082 4.22769502e-071 1.14737207e-036 1.00000000e+000]\n",
            " [1.00000000e+000 1.60050051e-015 2.67811627e-025 1.13759764e-013]\n",
            " [1.78857628e-008 3.98135703e-010 1.35772693e-005 9.99986404e-001]\n",
            " [1.00000000e+000 1.45938479e-018 8.71569138e-024 2.99174668e-022]\n",
            " [5.60889648e-006 9.99994385e-001 1.59703352e-010 5.54526431e-009]\n",
            " [3.91974691e-185 3.10057230e-164 1.00000000e+000 3.15659805e-070]\n",
            " [5.95634356e-068 3.95160809e-037 2.57279360e-031 1.00000000e+000]\n",
            " [7.46554908e-019 1.00000000e+000 4.05923756e-018 1.09047420e-025]\n",
            " [5.54268029e-016 1.00000000e+000 1.26004173e-016 9.43441920e-015]\n",
            " [6.49772477e-050 7.81979456e-040 1.00051135e-027 1.00000000e+000]\n",
            " [3.73008464e-103 4.51573703e-088 1.00000000e+000 2.71955825e-032]\n",
            " [2.21012010e-067 1.00000000e+000 6.54164186e-073 8.24528090e-079]\n",
            " [1.00000000e+000 1.65554600e-026 1.62407762e-045 6.51315933e-024]\n",
            " [1.00000000e+000 5.51889762e-036 1.44213930e-053 1.11370155e-051]\n",
            " [1.00000000e+000 1.29695370e-029 2.40190842e-038 1.75679988e-037]\n",
            " [1.09365108e-074 1.90185218e-054 1.00000000e+000 6.55332322e-032]\n",
            " [7.43039006e-048 1.00000000e+000 3.64183985e-055 1.37698552e-053]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 2.25578794e-046]\n",
            " [2.97801282e-064 1.15299779e-046 1.00000000e+000 7.18627381e-022]\n",
            " [1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [2.33821066e-076 1.00000000e+000 2.31379803e-114 1.48787620e-106]\n",
            " [1.47545750e-053 7.77598158e-049 1.61105010e-024 1.00000000e+000]\n",
            " [5.49747929e-026 4.22558446e-030 1.00000000e+000 2.25949641e-022]\n",
            " [9.99999999e-001 7.47998163e-010 1.36225493e-015 2.74608080e-017]\n",
            " [1.28721911e-036 1.00000000e+000 1.42792903e-061 1.05525372e-052]\n",
            " [1.19270997e-097 1.00000000e+000 1.25702185e-028 1.07359846e-043]\n",
            " [1.00000000e+000 3.33110241e-030 1.46361948e-038 2.72686558e-027]\n",
            " [9.99999987e-001 1.30412935e-008 4.00458469e-010 2.00843114e-015]\n",
            " [6.42309296e-247 1.77122394e-204 1.00000000e+000 2.17749391e-055]\n",
            " [8.60616341e-128 5.40515680e-115 1.00000000e+000 1.81482983e-047]\n",
            " [1.09856430e-066 2.21597047e-045 1.00000000e+000 6.38755534e-019]\n",
            " [1.36611349e-026 1.43253678e-018 5.78172956e-007 9.99999422e-001]\n",
            " [3.81202902e-034 1.00000000e+000 1.88108328e-038 7.87239603e-038]\n",
            " [1.00000000e+000 3.64588559e-029 1.08331514e-041 3.09815317e-030]\n",
            " [0.00000000e+000 1.00000000e+000 0.00000000e+000 0.00000000e+000]\n",
            " [1.84901489e-056 5.88115617e-034 2.72319730e-010 1.00000000e+000]\n",
            " [3.31632058e-033 1.00000000e+000 1.05215316e-026 1.04049005e-031]\n",
            " [1.84579026e-013 1.67142507e-010 9.99999501e-001 4.98930465e-007]\n",
            " [5.81387248e-053 1.00000000e+000 1.32904756e-058 3.15163837e-055]\n",
            " [6.01045416e-004 9.99398955e-001 1.32274894e-016 4.07826821e-014]\n",
            " [1.00000000e+000 3.71715554e-012 8.13292036e-016 1.35107073e-021]\n",
            " [8.00517800e-066 3.38066629e-019 7.72794739e-001 2.27205261e-001]\n",
            " [1.36556012e-054 7.55847421e-036 6.11308664e-034 1.00000000e+000]\n",
            " [1.00000000e+000 4.29016533e-031 3.00043229e-031 1.50170411e-031]\n",
            " [2.09737507e-049 4.53377118e-049 1.00000000e+000 5.03944757e-015]\n",
            " [1.00000000e+000 5.78801352e-015 8.01879898e-028 4.62112652e-018]\n",
            " [1.24577720e-016 5.90828155e-014 8.74407689e-004 9.99125592e-001]\n",
            " [1.50474854e-046 1.63038402e-044 1.00000000e+000 6.89021534e-011]\n",
            " [1.00000000e+000 1.93068304e-029 5.78341508e-040 3.46835859e-039]\n",
            " [9.89024651e-001 1.09753494e-002 4.80337917e-015 1.88114830e-022]\n",
            " [2.97175084e-063 1.00000000e+000 5.32115633e-041 7.89720270e-032]\n",
            " [2.23607136e-035 1.31361672e-028 1.00000000e+000 1.79290542e-013]\n",
            " [3.34219241e-130 6.87061345e-104 1.00000000e+000 1.15772271e-044]\n",
            " [3.34310340e-103 8.98358137e-080 1.00000000e+000 5.58148869e-065]\n",
            " [9.09503970e-050 1.00000000e+000 1.82705011e-041 4.17113982e-036]\n",
            " [1.00000000e+000 9.43998265e-116 1.82263149e-234 9.81242421e-233]\n",
            " [7.70524836e-037 1.00000000e+000 8.84808756e-051 1.69817822e-036]\n",
            " [5.87787224e-046 9.99999982e-001 2.63252491e-011 1.82058848e-008]\n",
            " [1.00000000e+000 2.41236688e-011 6.88940295e-016 1.20684917e-015]\n",
            " [1.84641553e-058 1.00000000e+000 1.40343725e-073 5.39778236e-064]\n",
            " [1.28438244e-052 2.81428760e-031 1.00000000e+000 3.89122663e-024]\n",
            " [2.72556996e-198 3.10974013e-163 1.00000000e+000 1.08741777e-065]\n",
            " [1.32108150e-078 3.98514531e-068 1.00000000e+000 5.69024527e-032]\n",
            " [7.10024820e-051 1.00000000e+000 3.67279148e-080 3.98326842e-076]\n",
            " [2.00481136e-096 9.66977171e-087 1.81221992e-053 1.00000000e+000]\n",
            " [0.00000000e+000 1.96768675e-294 1.00000000e+000 3.31736959e-088]\n",
            " [1.94369572e-120 1.00000000e+000 3.09749305e-206 1.47548836e-191]\n",
            " [6.92708251e-039 1.00000000e+000 6.32037083e-109 4.04907230e-092]\n",
            " [3.80007240e-016 8.36268564e-017 1.44572847e-004 9.99855427e-001]\n",
            " [4.69757028e-073 5.45014893e-055 3.05202826e-011 1.00000000e+000]\n",
            " [2.99666706e-098 4.15734924e-079 2.45871314e-036 1.00000000e+000]\n",
            " [3.18658773e-018 3.57411231e-020 4.81781366e-018 1.00000000e+000]\n",
            " [1.14216728e-038 1.63389283e-038 9.26989453e-001 7.30105475e-002]\n",
            " [8.65359304e-016 4.15304510e-011 9.99999450e-001 5.49514202e-007]\n",
            " [1.96801267e-016 8.21635533e-014 9.99998995e-001 1.00507256e-006]\n",
            " [4.52254479e-027 1.00000000e+000 7.81509292e-027 3.60161293e-024]\n",
            " [6.69776809e-037 1.19976553e-037 3.73173017e-011 1.00000000e+000]\n",
            " [1.00000000e+000 3.38532428e-017 6.96545254e-085 5.65224139e-091]\n",
            " [1.28359580e-038 1.00000000e+000 2.65728937e-043 1.72897269e-039]\n",
            " [9.93633715e-001 6.36628467e-003 1.13656805e-016 3.00524186e-011]\n",
            " [1.00000000e+000 1.27856367e-036 1.53221876e-055 2.89450535e-051]\n",
            " [1.00000000e+000 1.36605039e-036 5.62998109e-051 4.81729146e-044]\n",
            " [8.34779633e-031 3.19200065e-028 2.89917633e-022 1.00000000e+000]\n",
            " [1.00000000e+000 6.65923391e-022 1.64181091e-036 5.20941591e-032]\n",
            " [1.95846035e-062 1.00000000e+000 1.27492099e-076 4.09097778e-080]\n",
            " [4.86163657e-183 5.65832378e-152 1.09058549e-021 1.00000000e+000]\n",
            " [5.06020730e-286 5.35718281e-228 1.00000000e+000 1.61374451e-012]\n",
            " [1.00000000e+000 5.51607812e-060 7.04643897e-073 6.69178843e-062]\n",
            " [3.82504230e-039 1.00000000e+000 5.19614546e-050 3.04408492e-044]\n",
            " [2.08444355e-081 9.72928296e-068 7.19640022e-006 9.99992804e-001]\n",
            " [1.50774404e-003 9.98492256e-001 4.35531172e-028 6.21766724e-030]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 3.05058401e-040]\n",
            " [1.00000000e+000 2.22857785e-021 1.64244806e-023 6.86885093e-028]\n",
            " [1.00000000e+000 1.98009000e-036 1.25872204e-043 1.12223520e-039]\n",
            " [6.11258436e-064 1.00000000e+000 2.64822169e-074 1.20157036e-067]\n",
            " [8.09828892e-086 2.09891602e-068 1.00000000e+000 1.53051360e-024]\n",
            " [4.19733893e-109 1.70909670e-103 1.00000000e+000 1.94511762e-027]\n",
            " [5.69928858e-205 6.34915406e-142 6.81698646e-004 9.99318301e-001]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 5.03652291e-012]\n",
            " [2.58732945e-014 1.00000000e+000 1.13531044e-030 6.57403009e-019]\n",
            " [1.11233079e-011 1.00000000e+000 2.82642329e-023 1.36148211e-021]\n",
            " [1.00000000e+000 1.31539230e-011 1.15256001e-022 1.32299703e-021]\n",
            " [1.91161665e-062 1.00000000e+000 3.70257164e-066 2.07831710e-075]\n",
            " [1.00000000e+000 1.67008360e-011 1.90151637e-034 1.53526771e-069]\n",
            " [4.23167427e-079 1.00000000e+000 7.74959721e-090 4.79176354e-080]\n",
            " [1.00000000e+000 2.28263788e-024 7.97646417e-034 1.61286393e-032]\n",
            " [1.00000000e+000 2.37166577e-021 2.71241419e-044 9.39123788e-041]\n",
            " [1.00000000e+000 8.69236418e-038 8.87526860e-060 3.37184086e-059]\n",
            " [2.73142172e-041 1.00000000e+000 4.08808794e-041 2.04353497e-041]\n",
            " [9.58904831e-141 2.53194509e-121 9.99999794e-001 2.06197469e-007]\n",
            " [1.00000000e+000 8.58362318e-035 1.21539930e-054 8.75205483e-049]\n",
            " [2.32485976e-116 2.07392482e-098 7.45318866e-049 1.00000000e+000]\n",
            " [1.45259727e-165 3.54590495e-126 1.00000000e+000 5.11040832e-045]\n",
            " [2.09591830e-229 3.36280761e-219 1.00000000e+000 3.08791514e-066]\n",
            " [1.00000000e+000 2.88870743e-029 2.11907255e-032 6.58086756e-037]\n",
            " [1.00000000e+000 4.71152381e-035 1.29292251e-054 2.04983002e-047]\n",
            " [4.56395435e-021 1.06845629e-017 9.99742141e-001 2.57858648e-004]\n",
            " [1.41722858e-144 1.00000000e+000 1.85546908e-133 3.48683931e-123]\n",
            " [2.43199625e-093 6.83271416e-083 1.00000000e+000 1.66672336e-030]\n",
            " [1.11267837e-099 2.94805360e-067 1.74236067e-040 1.00000000e+000]\n",
            " [2.98225558e-086 2.06634142e-052 5.81671277e-017 1.00000000e+000]\n",
            " [7.97150128e-149 2.29615270e-117 1.00000000e+000 1.64078889e-033]\n",
            " [1.26973544e-072 1.00000000e+000 1.43072595e-098 5.68338532e-085]\n",
            " [1.00000000e+000 5.42838187e-017 9.64293937e-021 1.46393928e-017]\n",
            " [2.21305034e-043 1.00000000e+000 3.78427407e-043 3.86119691e-045]\n",
            " [2.28676710e-029 1.00000000e+000 2.27170711e-027 1.82344830e-026]\n",
            " [3.70315340e-133 5.60761998e-108 1.00000000e+000 1.80325562e-036]\n",
            " [1.00000000e+000 3.13826100e-010 1.77560633e-025 2.78167053e-018]\n",
            " [5.63148498e-038 5.57869248e-027 1.00000000e+000 9.14928324e-019]\n",
            " [6.80109470e-016 7.66747034e-015 1.00000000e+000 3.22778701e-010]\n",
            " [1.42118418e-269 1.19112528e-248 1.00000000e+000 3.52830293e-051]\n",
            " [3.47480489e-018 9.90294882e-015 9.99999990e-001 9.51331281e-009]\n",
            " [1.00000000e+000 4.56696412e-053 3.21617798e-067 2.30896637e-067]\n",
            " [1.50436326e-173 7.32022561e-135 1.00000000e+000 1.14986303e-035]\n",
            " [3.32609098e-048 4.09456333e-042 1.00000000e+000 8.46690261e-014]\n",
            " [3.71985789e-086 2.24894793e-082 2.78782404e-025 1.00000000e+000]\n",
            " [3.81371809e-055 1.00000000e+000 1.81997013e-056 1.47001569e-047]\n",
            " [2.14168596e-035 1.00000000e+000 8.01296836e-043 4.73817269e-033]\n",
            " [1.00000000e+000 8.15360613e-037 1.88256373e-099 2.49299376e-039]\n",
            " [6.66019805e-045 1.73900927e-035 1.06965132e-035 1.00000000e+000]\n",
            " [1.25997195e-065 1.86602777e-054 2.98505563e-036 1.00000000e+000]\n",
            " [1.00000000e+000 8.30435194e-025 3.59983293e-044 5.32144770e-040]\n",
            " [4.01909668e-078 1.90439639e-059 6.95315360e-041 1.00000000e+000]\n",
            " [9.70587879e-043 1.00000000e+000 3.29633087e-048 1.83938137e-045]\n",
            " [1.00000000e+000 3.08779601e-024 1.90571830e-031 1.23016304e-037]\n",
            " [0.00000000e+000 0.00000000e+000 1.00000000e+000 7.52188959e-139]\n",
            " [1.00000000e+000 6.42975126e-032 2.46005968e-055 5.23189024e-055]\n",
            " [1.44784734e-061 1.10960218e-057 1.04510625e-023 1.00000000e+000]\n",
            " [1.00000000e+000 2.91056947e-010 6.10931026e-013 5.87845468e-012]\n",
            " [1.94972552e-212 1.00000000e+000 2.91533330e-148 2.82373496e-152]\n",
            " [1.00000000e+000 1.39165344e-032 1.16059496e-056 3.65231643e-055]\n",
            " [1.10109968e-184 2.42591211e-126 1.00000000e+000 2.23524714e-024]\n",
            " [3.32315984e-237 6.13468431e-205 1.00000000e+000 4.24150886e-058]\n",
            " [1.00000000e+000 8.87148908e-048 9.96763488e-083 5.71445434e-074]\n",
            " [6.12100812e-027 1.10338152e-035 2.60193763e-030 1.00000000e+000]\n",
            " [2.30287416e-063 1.00000000e+000 4.00056310e-078 3.19144956e-066]\n",
            " [2.39847594e-007 9.99999760e-001 3.22210746e-017 9.49420251e-020]\n",
            " [1.00000000e+000 8.79972033e-035 1.02730581e-050 1.27382832e-027]\n",
            " [5.50023599e-029 3.92279495e-021 2.45720732e-019 1.00000000e+000]\n",
            " [1.67674320e-022 8.83806144e-019 9.99999930e-001 7.04233517e-008]\n",
            " [1.00000000e+000 1.48967556e-047 2.54205941e-063 9.59278365e-062]\n",
            " [9.99999744e-001 2.56167658e-007 4.98415997e-020 3.20770530e-015]\n",
            " [8.14146986e-047 1.00000000e+000 3.05559709e-064 1.84435136e-063]\n",
            " [9.99992480e-001 1.56958006e-009 4.24747591e-015 7.51801187e-006]\n",
            " [2.26472816e-016 1.84869228e-010 1.00000000e+000 1.23993978e-013]\n",
            " [1.00000000e+000 6.35527775e-056 2.16955613e-077 5.01321261e-085]\n",
            " [1.00000000e+000 2.57873405e-026 7.61831687e-030 9.16110341e-039]\n",
            " [1.00000000e+000 2.45895638e-038 1.37690632e-065 1.66164099e-044]\n",
            " [9.99999982e-001 1.76539187e-008 1.11436528e-026 7.53464170e-017]\n",
            " [4.36743271e-099 6.33793110e-073 2.09773079e-047 1.00000000e+000]\n",
            " [1.22509984e-021 1.00000000e+000 9.42985747e-035 5.18921067e-028]\n",
            " [7.91961383e-259 9.09285069e-198 1.00000000e+000 1.45734898e-103]\n",
            " [1.00000000e+000 1.54325341e-025 2.23779305e-043 2.84263182e-033]\n",
            " [2.60888986e-207 3.12458032e-124 2.57162135e-041 1.00000000e+000]\n",
            " [4.37043678e-231 3.91248305e-171 1.00000000e+000 1.16263367e-040]\n",
            " [5.35990390e-020 1.00000000e+000 1.07472061e-039 3.45029140e-027]\n",
            " [1.70029602e-042 1.00000000e+000 2.07089884e-056 2.37455298e-047]\n",
            " [4.49393930e-010 2.94708025e-009 2.80729972e-014 9.99999997e-001]\n",
            " [1.27124745e-047 1.89766000e-034 9.99999989e-001 1.10389295e-008]\n",
            " [1.00000000e+000 9.65108403e-028 5.40597754e-026 2.90293286e-024]\n",
            " [1.00000000e+000 5.27234694e-017 8.50006720e-090 3.95555094e-089]\n",
            " [4.18255959e-205 8.14580018e-158 1.00000000e+000 6.85852589e-071]\n",
            " [0.00000000e+000 9.84391437e-303 1.00000000e+000 1.25475500e-083]\n",
            " [4.32892773e-066 3.89821041e-064 3.80825360e-034 1.00000000e+000]\n",
            " [1.38760714e-020 1.00000000e+000 2.82103644e-034 1.15795883e-023]\n",
            " [3.03216747e-007 1.12314090e-007 2.48002357e-003 9.97519561e-001]\n",
            " [9.99999994e-001 8.81505717e-012 5.82827402e-009 3.29460361e-012]\n",
            " [1.99647235e-224 7.75890967e-207 1.00000000e+000 1.40186838e-042]\n",
            " [9.99999984e-001 1.59188587e-008 6.52707898e-037 4.63098432e-044]\n",
            " [8.79982030e-001 1.20017969e-001 1.16509210e-012 1.36287439e-009]\n",
            " [5.16302965e-010 1.11920391e-010 9.99999999e-001 1.78966340e-013]\n",
            " [1.14780362e-033 1.00000000e+000 2.50879623e-045 7.17585880e-048]\n",
            " [8.29176349e-149 4.15696707e-084 1.00000000e+000 4.26906770e-057]\n",
            " [8.80070422e-082 1.00000000e+000 7.59045054e-241 1.06964925e-268]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here. first we are testing the model using the test data y_test to make the prediction of the target variable.\n",
        "\n",
        "here we are using the pridict_prob() method with naive bayes model  that take input as the X_test and return the array of predicted probability for each possible classification label for each documents.\n",
        "\n",
        "here we are assigning the output of the predict_prob() intot he y_pred_prob which is the two dimensional array which is containing the predicted probabilities of the each articles in the test set for each documents set the classification labels.\n",
        "\n",
        "after that we are printing the predicted values and shows the probaility of the prediction values for each articles in the test set. we are evaluating the model using the test data and checking how well the model is in predicting the labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "enajeJc7d4Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4(b): Evaluate the Model**"
      ],
      "metadata": {
        "id": "-ewP6Q1lXAYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the metrics module from sklearn\n",
        "from sklearn import metrics\n",
        "\n",
        "# use the accuracy_score metric to calculate accuracy of the model\n",
        "# you evaluate a model by comparing its predictions against the known outputs of the test set\n",
        "accuracy = metrics.accuracy_score(y_test, predictions)"
      ],
      "metadata": {
        "id": "WdoFsndbXCs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are importing the sklearn  matrix which contains the different kind of functions for evaluating the performance of the machine learning model.\n",
        "\n",
        "Here we using the accuracy= metrics.accuracy_score(Y_test, predictions) for checking the accuracy of the model and check the performance of the model that how well its predicting using the testing data or we can say unseen data.\n",
        "\n",
        "\n",
        "here accuracy score take known output y_test and predicted output of the predictions in input and returns the accuracy of the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nw-Ww4Bwr9mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the confusion matrix metric to understand the predictive power of the model\n",
        "print(metrics.confusion_matrix(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMKRqx-VXEms",
        "outputId": "4e00eff5-dd59-41e7-ec87-76693ef4f674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[371  11   2   5]\n",
            " [ 11 377   5   1]\n",
            " [  5   4 379  10]\n",
            " [  5  11  49 186]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we are printing the confusion matrix using the y_test and using the model fit object prediction. confusion matrix is the table for summarizing the performance of the classification model  in the test data.\n",
        "\n",
        "here the confusion matrics provides the more understanding the performance of the model than the accuracy score. its use for calculate the different evaluation matrix like precision,recall and F1-score.this all are useful for checking the performace of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcMueNcDt0rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task-2(20 points)\n",
        "##Create a dataset of email samples and their corresponding labels. Convert the email samples into TF-IDF vectors and train a Naive Bayes classifier using this dataset. Compare the performance of this model with the model trained in the previous question."
      ],
      "metadata": {
        "id": "GniLXWl5P6tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset from Kaggle\n",
        "spam_df = pd.read_csv('/content/Email_spam.csv')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(spam_df['text'], spam_df['spam'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the email samples into TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier using the dataset\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate the performance of the model on the testing set\n",
        "y_pred = nb_classifier.predict(X_test_tfidf)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, pos_label=1))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred, pos_label=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ihYFUiVeL6",
        "outputId": "120097c5-bc84-4f2c-bacd-9ba52c539ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8926701570680629\n",
            "Precision: 1.0\n",
            "Recall: 0.5758620689655173\n",
            "F1 score: 0.7308533916849016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Classification :** naive bayes classifier is the algorithm for probability classification where this classification is predict the model use the probablistic way.\n",
        "\n",
        "**TF-IDF :** TF-IDF stands for term frequency - inverse dense frequency this is technique use for searching the meaning of the sentences and its cancel the bag of words which are not capable for the text classification for model read word in numbers.\n",
        "\n",
        "\n",
        "here, we are using the email dataset for classify the emails that they are spam or not spam. here we are loading the dataset using the pandas library for read the csv file.and we are here splits the training and testing the dataset and its convert the emails into the TF-IDF vectors using the TFidvectorizer from the sklearn.\n",
        "\n",
        "here we are training the model using the naive bayes classifiers using the multinomialNB from the sklearn, and evaluates the performance of the classifier using the test data using the different evaluation matrix from the sklearn.here for evaluation we are using the accuracy score, precision score, recall score and f1 score.\n",
        "\n",
        "here we are calculating the accuracy score of the model on the test data, which is proportion of correct prediction by the model.here it takes input as the Y_test and y_pred value as well as the position label =1.\n",
        "\n",
        "after that we are calculating the precison score using the parameter y_test, y_pred and pos_label =1 for test the model, which is proportion of the true positive prediction by model.\n",
        "\n",
        "Additionally, we are calculating the recall_score too using the parameters y_test,Y_pred and pos_label=1 for test the model, which is the proportion of the true positives from all the actual positive examples in the test data.\n",
        "\n",
        "after that we are calculating the f1 score using the parameter y_test, y_pred and pos_label=1, which is the harmonic mean of the precision and recall.\n",
        "\n",
        "here the evaluation matrics is provide the performance of the naive bayes classification using the email spam classifiers. here we are comparing the metrics, where we can identify the model performance on the email whether email is spam or not.here the accuracy of the model is 0.89.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vEI-pN3wxCX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3 (15 points)\n",
        "\n",
        "##How does the Naive Bayes classifier work in the context of text classification?What is the difference between bag-of-words and term frequency-inverse document frequency (TF-IDF) approaches in text classification?"
      ],
      "metadata": {
        "id": "22I-FcVJQwEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer here\n",
        "**Naive Bayes Classification:** this is the probabilistic model which is use the bayes theorm for classify the text depends on the probabilities of each word which is available in the each class.\n",
        "\n",
        "**Context of text classification:**\n",
        "Text classification is the process of categorise the text into different classes.Talking about that how the naive bayes work, let's assume that we have text and we want to classify them into two different classes name as \"spam\" and \"Not Spam\". here the naive bayes classification will calculate the probability of the each word. for instance that \"Deal\" word is comes in the spam class as 0.6 while in \"Not spam\" it comes only 0.1. after that here we are inputing the new text, now the  model will calculate the probability of the text to each class by multiplying the probability of each word in the text which are available in each class. at the last model assign the class with the high probability.\n",
        "\n",
        "**Bag-of-Words:**\n",
        "bag-of-word is use for presenting the text depends on the frequency of the words that appear in the documents. this method is creating the list of the all the words that will appear in the documents, and at the last its count that how many number of times that word is appear in the text.\n",
        "\n",
        "**TF-IDF:**\n",
        "TF-IDF stands for term frequency-inverse document frequency. This is the technique for information retrieval and machine learning to determine the significance of the word, phrases and string present in the document its compare to the other documents. its gives us the numeric value which represent that how many time this word appear in the document as well as count the unique words too. which is useful for identifying the useful and relevant term in the collections.\n",
        "\n",
        "**Difference between between bag-of-words and TF-IDF approach in text classification**\n",
        "here, we are going to discuss about the difference between bag-of-word and TF-IDF approaches in the text classification.\n",
        "\n",
        "Talking about the bag-of-words approach it represent the each text in to the words, and also its ignore the order of word as well as the context of the words. for instance, if the sentence is \"I like to eat pizza, pizzas are my favorites\" so here in the bag-of-words its represent such as {I,like,to,eat,pizza,are,my,favorites}. then each text is present as the vector where each of the element is represent the frequency of the each words.\n",
        "\n",
        "In contrast, the TF-IDF approach its not only take the frequency of the each word but also that word is common in whole text. the approach is the word its appear in the text frequently but rarely its use in the other documents which is more important to differentiate between classes.\n",
        "\n",
        "talking about how TF-IDF calculated, here TF(term frequency) which is represent the frequency of the word. its calculated based on the number of times the word appear in the text divided by the total number of the words.And Inverse document frequency is calculate based on the common word across the all document in the dataset. its basically calculate using the logarithm of the total number of texts in the dataset divided by the number of text that have that words. here TF-IDF is the product of the TF and IDF.\n",
        "\n",
        "while in TF-IDF approach, each text is present as a vector which is each element that represent the TF-IDF score for each of the words. this is mostly used in the text classification because its give the better performance compared to bag-of-words,when working with the large and diverse dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZuAaxIuRE_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note:\n",
        "For Tasks 4 and 5, you can use any of the in-built datasets like iris dataset, boston dataset, diabetes dataset etc. wherever you are asked to use your own dataset."
      ],
      "metadata": {
        "id": "yQKSikPqbtEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression\n",
        "\n",
        "Logistic regression is an example of a discriminative classifier and is commonly used in text classification, as a baseline in research, and as an MVP in real-world industry scenarios.\n"
      ],
      "metadata": {
        "id": "Q3XlbRd9eRcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task-4(20 points)\n",
        "###Tutorial: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "###Implement the Logistic Regression classifier in the link given above on a dataset of your choice. You can implement the example section in the tutorial link given above."
      ],
      "metadata": {
        "id": "2cPuIiyTeUwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3)\n",
        "\n",
        "# create a Logistic Regression classifier\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the classifier\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "Ba2FtMkT5x2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493e740b-0bc0-498d-d16d-9b2aa56c1235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9532163742690059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Classification:**\n",
        "This is the algorithm for natural language processing which is use for the classification, which means its use for the binary classification when the data is binary then this algorithm is use for classify. and the output is define as the 0 and 1.\n",
        "\n",
        "Here, we are using the logistic regression classification for solving the issue of binary data. here we are using the breast cancer dataset from the sklearn library which is use for predict the breast tumor is malignant or benign.\n",
        "\n",
        "here, we first split the dataset intot he training and testing using the train_test_split() function. here the training data us used to train the model while the testing data is used for evaluating the model or checking the performance of the model.\n",
        "\n",
        "Here, we are creating the classifier using the logisiticregression() function. here we are using the fit() method to train our model using the training data.\n",
        "\n",
        "After that we are using the predict() method to check the performance of the model. we are using the test set for evaluate the model.and also we are comparing the predictions with the true labels using the scale() method, which is return the calculate accuracy of the classifier.At the last we are now printing the accuracy score with breast cancer dataset is 0.97.\n",
        "\n",
        "All in all, here we are using the logistic regression for binary classify the breast cancer dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sH7IxYTdpSEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load the MNIST dataset\n",
        "mnist = fetch_openml(name='mnist_784')\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# create a Logistic Regression classifier\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg348AMFY9PX",
        "outputId": "df4a3daa-7cef-402e-994a-9e14436d5cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9196666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "here is the instance of the multi-class classification using the logistic regression.here we are using the MNIST dataset from the sklearn library for recognize the handwritten digits.\n",
        "\n",
        "Here, first we are loading the dataset using the fetch_openml() function.after that we are spliting the data into training and testing using the train_test_split() function.here training data is used to train the model while the testing data is used to test the model or evaluate the performance of the model.\n",
        "\n",
        "Alogistic regression classifier is here created using the logisticregression() function. also here we are using the fit() method to train the model using the training data.\n",
        "\n",
        "after that we are using the predict() method for that we are using the testing data. now this prediction compared to the true labels using the accuracy_score()function, which is calculates the accuracy of the model.\n",
        "\n",
        "at the last here we are printing the accuracy using the logistic regression model for MNIST dataset which is 0.91.\n",
        "\n",
        "All in all, here we are training and testing the multi-class classification model using the logistic regression classifier for MNIST dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xTwtY4pesgo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "clf.predict(X[:2, :])\n",
        "\n",
        "clf.predict_proba(X[:2, :])\n",
        "\n",
        "\n",
        "accuracy=clf.score(X, y)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdiDXZ0EaZFL",
        "outputId": "712fc009-04ce-421a-fdc9-6cac2290f057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9733333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are doing the binary and multi-class classification issues using the logistic regression model. here we are using the Iris dataset from the sklearn library to classify the Iris flower using its features.\n",
        "\n",
        "here first the Iris dataset is loaded using the load_iris function. this return the  input features as x and target labels as a y. the x variable have some measurement of the petals and sepals of the flowers, in contrast, y is having the corresponding species labels.\n",
        "\n",
        "here the classifier is created using the logisticregression() function.here we are using the fit() method to train the model on the entire dataset.and after that we are using the predict() method to make the prediction on the first two samples of the dataset.\n",
        "\n",
        "Here, we are using the predict_prob() method for calculating the probability of the each class for the first two samples.here this method is use for assess the confidence of the model for its predictions.\n",
        "\n",
        "here,we are calculating the accuracy_Score() method which is use to calculate the classifier performance for the whole dataset. here we using the score() method for classifier to calculate the accuracy. here its present the percentage of the correctly classify the instances of the dataset.\n",
        "\n",
        "all in all, here we are training and testing the logistic regression classifier on the MNIST dataset. the main aim is to accurately classify the Iris flowers with its features using the supervised learning approach. the accuracy score for that is 0.97.\n",
        "\n"
      ],
      "metadata": {
        "id": "VujGTlqYs96c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5 (20 points)\n",
        "###Tutorial:https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "###Implement Decision tree classifier on a dataset of your choice. Make use of the tutorial link given above."
      ],
      "metadata": {
        "id": "9s12vOm7embv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##your code here\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# create a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "FcIJT-PEeoJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161020cf-7a8b-4e93-94ff-892dc5fbbae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9239766081871345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision classifier:**\n",
        "Decision tree classification is the process of solving the classification and regression problems using the rules. here its split the data based on the values of the feature until the all data point will be group together. this is same as the flowchart , where each node present as a feature based split. that whole process starts with the root node and ends with the decision made at the leaves.this is use for both classification as well as the regression.\n",
        "\n",
        "Here, we are using the sklearn library to create the decision tree classifier for the breast cencer dataset.\n",
        "\n",
        "Here, we are first loading the dataset of the breast cancer using the load_breast_cancer() function from the sklearn library.here we are spliting the data into the training and testing dataset using the train_test_Split() function.\n",
        "here, now the we are creating decision tree classifier using the decisiontreeclassifier() function from the sklearn. here its train using the method fit(). after that we are using the predict() method to make the prediction using the testing data.\n",
        " at the last we are calculating the accuracy of the clssifier using the accuracy_Score() function. and here we are printing the accuracy score which is 0.92.\n",
        "\n",
        "The  main aim is to do that we are identifying that how to use the sklear library for make and evaluate the decision tree classification for the breast cancer dataset. this is one type of the supervised learning algorithm use for decision tree as well as the regression. here for training the decision tree classifier we are using the breast cancer data for predict whether the tumor is malignat or benign based on the features of the tumor.  the accuracy is calculated and classify the model whether its predict well or not.\n",
        "\n"
      ],
      "metadata": {
        "id": "zT0_JKOosxk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "iris = load_iris()\n",
        "cross_val_score(clf, iris.data, iris.target, cv=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm97K9lta7Ws",
        "outputId": "38e16c23-8c82-46e5-b3ba-0e58d6764220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
              "       0.86666667, 0.93333333, 1.        , 1.        , 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here , we are doing the cross validation using the iris dataset for the decision tree classifier, after that here we load the dataset using the load_iris() function from the sklearn. this classifier is set as the random state which is 0.\n",
        "\n",
        "here after that we are using the function cross_val_score() form sklearn which is used to perform the k-fold cross_validation, where we are setting the k=10. this is return the score of the array, where each score is the accuracy of the classifier on the different part of the dataset.\n",
        "\n",
        "the main aim is to cross validation is to evaluate the model that how well the classifier is performing in the new data or unseen data. here we split the data into the multiple part and train the classifier on different combination of the dataset parts. after that we are getting more accurate estimationof the classifier performance than the performance of the simple of classify model with the train and testing data.\n"
      ],
      "metadata": {
        "id": "00sw2ojQsygO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text classification using the three different algorithms naive bayes, decision trees and logistic regression**"
      ],
      "metadata": {
        "id": "xYRvsHdScGyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the 20 Newsgroups dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "# Convert the text data to TF-IDF vectors\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train = tfidf.fit_transform(newsgroups_train.data)\n",
        "X_test = tfidf.transform(newsgroups_test.data)\n",
        "\n",
        "# Train and test Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, newsgroups_train.target)\n",
        "nb_pred = nb.predict(X_test)\n",
        "nb_acc = accuracy_score(newsgroups_test.target, nb_pred)\n",
        "nb_prec = precision_score(newsgroups_test.target, nb_pred, average='weighted')\n",
        "nb_rec = recall_score(newsgroups_test.target, nb_pred, average='weighted')\n",
        "nb_f1 = f1_score(newsgroups_test.target, nb_pred, average='weighted')\n",
        "print(\"Naive Bayes:\")\n",
        "print(f\"\\tAccuracy: {nb_acc}\")\n",
        "print(f\"\\tPrecision: {nb_prec}\")\n",
        "print(f\"\\tRecall: {nb_rec}\")\n",
        "print(f\"\\tF1-score: {nb_f1}\")\n",
        "\n",
        "# Train and test Logistic Regression classifier\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, newsgroups_train.target)\n",
        "lr_pred = lr.predict(X_test)\n",
        "lr_acc = accuracy_score(newsgroups_test.target, lr_pred)\n",
        "lr_prec = precision_score(newsgroups_test.target, lr_pred, average='weighted')\n",
        "lr_rec = recall_score(newsgroups_test.target, lr_pred, average='weighted')\n",
        "lr_f1 = f1_score(newsgroups_test.target, lr_pred, average='weighted')\n",
        "print(\"Logistic Regression:\")\n",
        "print(f\"\\tAccuracy: {lr_acc}\")\n",
        "print(f\"\\tPrecision: {lr_prec}\")\n",
        "print(f\"\\tRecall: {lr_rec}\")\n",
        "print(f\"\\tF1-score: {lr_f1}\")\n",
        "\n",
        "# Train and test Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, newsgroups_train.target)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_acc = accuracy_score(newsgroups_test.target, dt_pred)\n",
        "dt_prec = precision_score(newsgroups_test.target, dt_pred, average='weighted')\n",
        "dt_rec = recall_score(newsgroups_test.target, dt_pred, average='weighted')\n",
        "dt_f1 = f1_score(newsgroups_test.target, dt_pred, average='weighted')\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"\\tAccuracy: {dt_acc}\")\n",
        "print(f\"\\tPrecision: {dt_prec}\")\n",
        "print(f\"\\tRecall: {dt_rec}\")\n",
        "print(f\"\\tF1-score: {dt_f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK2ZgIPlpR61",
        "outputId": "3dc437e6-b70b-42ca-ea25-5cf9eac7df65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes:\n",
            "\tAccuracy: 0.7738980350504514\n",
            "\tPrecision: 0.8218781741893993\n",
            "\tRecall: 0.7738980350504514\n",
            "\tF1-score: 0.7684457156894653\n",
            "Logistic Regression:\n",
            "\tAccuracy: 0.8274030801911842\n",
            "\tPrecision: 0.8306575949769146\n",
            "\tRecall: 0.8274030801911842\n",
            "\tF1-score: 0.8257218194818299\n",
            "Decision Tree:\n",
            "\tAccuracy: 0.555231014338821\n",
            "\tPrecision: 0.5591830480724167\n",
            "\tRecall: 0.555231014338821\n",
            "\tF1-score: 0.5556692497281566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we are performing the text classification using the 20 newsgroups dataset using the three different kind of classifier which is Naive bayes, Logistic regression and Decision tree.\n",
        "\n",
        "here we are using the 20 newsgroups dataset which contain the 20000 newsgroups posts, and we are parting them into equal part with 20 different newsgroups. here we are loading the dataset using the fetch_20newsgroups() function from the sklearn. we now split the dataset into the training and testing the data and convert the text data to TF-IDF vectors using the Tfidfvectorizer() function from the sklearn.\n",
        "\n",
        "here, we are training the three different classifier using the training data, naive bayes,logistic classification and decision tree. we are using the multinomialNB(), logisticregression() and decisiontreeclassifier() from sklearn to create the classifiers and use the fit() method to train the model.\n",
        "\n",
        "here after that we are predicting the model using the predict() method using the testing data for each classifier, and calculating the different evaluate the matrics such as accuracy, precision, recall and f1 score function from the sklearn. here along with that we are using the average=weighted  parameter to calculate the weighted average of the metrics across all the classes.\n",
        "\n",
        "at the last we are printing the evaluation matrics of the each classifier such as naive bayes, logistic regression, decision tree and the accuracy score are 0.77,0.82,0.55 respectively.\n"
      ],
      "metadata": {
        "id": "ex5yDAjEuXa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task -6(10 points)\n",
        "##Compare your results of Naive Bayes, Logistic regression and Decision Tree. Which one do you think is the best text classifier?"
      ],
      "metadata": {
        "id": "nDkAFiKPe-2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer here\n",
        "**Naive bayes:**\n",
        "this is the probabilistic model which is use the bayes theorm for classify the text depends on the probabilities of each word which is available in the each class.naive bayes is the probabilistic algorithm which is use the conditional probability.\n",
        "**Logistic regression:**\n",
        "This is the algorithm for natural language processing which is use for the classification, which means its use for the binary classification when the data is binary then this algorithm is use for classify. and the output is define as the 0 and 1. logistic regression model is the linear model where the event occured based on the independent variables.\n",
        "**Decision tree:**\n",
        "Decision tree classification is the process of solving the classification and regression problems using the rules. here its split the data based on the values of the feature until the all data point will be group together. this is same as the flowchart , where each node present as a feature based split. that whole process starts with the root node and ends with the decision made at the leaves.this is use for both classification as well as the regression.\n",
        "\n",
        "\n",
        "**Comparing the result of the different classifiers**\n",
        "the effectiveness of the classifier based on the specific dataset. however that logistic regression and naive bayes is used for the text classification while decision tree commonly use for classification for structured data.\n",
        "\n",
        "here in the example above we are using the 20newsgroups dataset to classify and the accuracy score, precision, recall and f1 score as follows\n",
        "**Naive Bayes:**\n",
        "\tAccuracy: 0.77\n",
        "\tPrecision: 0.82\n",
        "\tRecall: 0.77\n",
        "\tF1-score: 0.76\n",
        "**Logistic Regression:**\n",
        "\tAccuracy: 0.82\n",
        "\tPrecision: 0.83\n",
        "\tRecall: 0.82\n",
        "\tF1-score: 0.82\n",
        "**Decision Tree:**\n",
        "\tAccuracy: 0.55\n",
        "\tPrecision: 0.55\n",
        "\tRecall: 0.55\n",
        "\tF1-score: 0.55\n",
        "\n",
        "Focusing on this results for the performance of the classifiers and its shows that naive bayes and logistic regression work well with the 20newsgroups dataset for the text classification. while, decision tree model perform poor compared to the naive bayes and logistic regression with a lower accuracy_score, precision,recall,f1score. that's why its concluded that naive bayes and logistic regression are the better performance model for the news group dataset.\n",
        "\n",
        "talking about the algorithm performance for text classification is totally based on the different dataset. here focusing on the result of the classifiers logistic regression is working best with the 20newsgroups dataset.and evaluating the model performance score is also best for doing the text classification. the best performer overall with the highest accuracy, precision, recall and f1 score values. however the performance of the naive bayes and decison tree is quite low compared to logisitic  regression.\n",
        "\n",
        "the main part is that performance of the classifier is totally based on the specific dataset and problem is beign solved, so its always the good idea to perform multiple classifier to check which model is working perfectly or better in performance.\n",
        "\n",
        "\n",
        "All in all, logistic regression model is best for text classification using overall, accuracy score, precision, recall and f1 score. In contrast decision tree and naive bayes is performing low compared to logisitic regression algorithm."
      ],
      "metadata": {
        "id": "qybaYfPmiCkF"
      }
    }
  ]
}